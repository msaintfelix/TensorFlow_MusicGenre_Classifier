{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music Genre Classifier With TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this project is to classify 30 sec wav files by genre using a TensorFlow CNN model. The GTZAN dataset can be found here:\n",
    "\n",
    "https://www.kaggle.com/andradaolteanu/gtzan-dataset-music-genre-classification\n",
    "\n",
    "To classify audio samples, we will preprocess them by calculating their MFCC, which is a temporal representation of the energy for each perceived frequency band. In this case, we are choosing 13 bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "from keras.models import load_model\n",
    "\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'random', #grid\n",
    "    'metric': {\n",
    "      'name': 'val_acc',\n",
    "      'goal': 'maximize'   \n",
    "    },\n",
    "    'parameters': {\n",
    "        'epochs': {\n",
    "            'values': [20, 30]\n",
    "        },\n",
    "        'batch_size': {\n",
    "            'values': [32, 48]\n",
    "        },\n",
    "        'dropout': {\n",
    "            'values': [0.2, 0.3, 0.4]\n",
    "        },\n",
    "        'conv_layer_size': {\n",
    "            'values': [32, 64, 128]\n",
    "        },\n",
    "        'hidden_layer_size': {\n",
    "            'values': [64, 128]\n",
    "        },\n",
    "        'learning_rate': {\n",
    "            'values': [0.0005, 0.001, 0.005]\n",
    "        },\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: auytih7y\n",
      "Sweep URL: https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, entity=\"msaintfelix\", project=\"Genre-Classifier-Optimization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset location\n",
    "SOURCE_PATH = 'Dataset/genres_original/'\n",
    "LOCAL_MODEL_DIR = 'Model/'\n",
    "\n",
    "# Path to labels and processed data file, json format.\n",
    "JSON_PATH = 'data.json'\n",
    "\n",
    "# Sampling rate.\n",
    "sr = 22050\n",
    "\n",
    "# Let's make sure all files have the same amount of samples, pick a duration right under 30 seconds.\n",
    "TOTAL_SAMPLES = 29 * sr\n",
    "\n",
    "# The dataset contains 999 files. Let's make it bigger. \n",
    "# X amount of slices => X times more training examples.\n",
    "NUM_SLICES = 10\n",
    "SAMPLES_PER_SLICE = int(TOTAL_SAMPLES / NUM_SLICES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(source_path, json_path):\n",
    "\n",
    "    # Let's create a dictionary of labels and processed data.\n",
    "    mydict = {\n",
    "        \"labels\": [],\n",
    "        \"mfcc\": []\n",
    "        }\n",
    "\n",
    "    # Let's browse each file, slice it and generate the 13 band mfcc for each slice.\n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(source_path)):\n",
    "\n",
    "        for file in filenames:\n",
    "            song, sr = librosa.load(os.path.join(dirpath, file), duration=29)\n",
    "\n",
    "            for s in range(NUM_SLICES):\n",
    "                start_sample = SAMPLES_PER_SLICE * s\n",
    "                end_sample = start_sample + SAMPLES_PER_SLICE\n",
    "                mfcc = librosa.feature.mfcc(y=song[start_sample:end_sample], sr=sr, n_mfcc=13)\n",
    "                mfcc = mfcc.T\n",
    "                mydict[\"labels\"].append(i-1)\n",
    "                mydict[\"mfcc\"].append(mfcc.tolist())\n",
    "\n",
    "    # Let's write the dictionary in a json file.    \n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(mydict, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(json_path):\n",
    "\n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "    # Let's load our data into numpy arrays for TensorFlow compatibility.\n",
    "    X = np.array(data[\"mfcc\"])\n",
    "    y = np.array(data[\"labels\"])\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_datasets(inputs, targets, split_size):\n",
    "    \n",
    "    # Creating a validation set and a test set with fixed random_state\n",
    "    inputs_train, inputs_val, targets_train, targets_val = train_test_split(inputs, targets, test_size=split_size, random_state=42)\n",
    "    inputs_train, inputs_test, targets_train, targets_test = train_test_split(inputs_train, targets_train, test_size=split_size, random_state=42)\n",
    "    \n",
    "    # Our CNN model expects 3D input shape.\n",
    "    inputs_train = inputs_train[..., np.newaxis]\n",
    "    inputs_val = inputs_val[..., np.newaxis]\n",
    "    inputs_test = inputs_test[..., np.newaxis]\n",
    "    \n",
    "    return inputs_train, inputs_val, inputs_test, targets_train, targets_val, targets_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    # Default values for hyper-parameters we're going to sweep over\n",
    "    config_defaults = {\n",
    "        'epochs': 20,\n",
    "        'batch_size': 32,\n",
    "        'learning_rate': 1e-3,\n",
    "        'dropout': 0.3,\n",
    "        'hidden_layer_size': 64,\n",
    "        'conv_layer_size': 32\n",
    "        }\n",
    "    \n",
    "    genre_dict = {\n",
    "        0 : \"blues\",\n",
    "        1 : \"classical\",\n",
    "        2 : \"country\",\n",
    "        3 : \"disco\",\n",
    "        4 : \"hiphop\",\n",
    "        5 : \"jazz\",\n",
    "        6 : \"metal\",\n",
    "        7 : \"pop\",\n",
    "        8 : \"reggae\",\n",
    "        9 : \"rock\",\n",
    "        }\n",
    "        \n",
    "    # Initialize a new wandb run\n",
    "    run = wandb.init(config=config_defaults)\n",
    "    \n",
    "    # Config is a variable that holds and saves hyperparameters and inputs\n",
    "    config = wandb.config\n",
    "\n",
    "    #preprocess_data(source_path=SOURCE_PATH, json_path=JSON_PATH)\n",
    "    \n",
    "    inputs, targets = load_data(json_path=JSON_PATH)     \n",
    "    Xtrain, Xval, Xtest, ytrain, yval, ytest = prepare_datasets(inputs, targets, 0.2)\n",
    "\n",
    "    input_shape = (Xtrain.shape[1], Xtrain.shape[2], 1)\n",
    "    \n",
    "    model = tf.keras.models.Sequential([ \n",
    "        tf.keras.layers.Conv2D(config.conv_layer_size, (3,3), activation='relu', input_shape=input_shape),\n",
    "        tf.keras.layers.MaxPooling2D((3,3), strides=(2,2), padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(config.conv_layer_size, (3,3), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((3,3), strides=(2,2), padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(config.conv_layer_size, (2,2), activation='relu'),\n",
    "        tf.keras.layers.MaxPooling2D((3,3), strides=(2,2), padding='same'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(config.dropout),\n",
    "        \n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dense(config.hidden_layer_size, activation='relu'), \n",
    "        tf.keras.layers.Dense(len(np.unique(targets)), activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Selection of the optimizer, loss type and metrics for performance evaluation.\n",
    "    model.compile(optimizer = tf.keras.optimizers.RMSprop(lr=config.learning_rate),\n",
    "                     loss='sparse_categorical_crossentropy',\n",
    "                     metrics = ['acc']\n",
    "                     )\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    # Training the model\n",
    "    history = model.fit(Xtrain, ytrain,\n",
    "                        validation_data=(Xval, yval),\n",
    "                        epochs=config.epochs,\n",
    "                        batch_size=config.batch_size,\n",
    "                        callbacks=[WandbCallback()]\n",
    "                        )\n",
    "    \n",
    "    # Store trained model artifacts\n",
    "    model_artifact_name = \"CNN_Genre_Classifier_\" + run.id\n",
    "    model_artifact = wandb.Artifact(model_artifact_name, type='model')\n",
    "    model.save('Model/my_model.h5')\n",
    "    model_artifact.add_dir(LOCAL_MODEL_DIR)\n",
    "    run.log_artifact(model_artifact)\n",
    "    \n",
    "    # log the confusion matrix for validation data\n",
    "    pred = model.predict(Xval)\n",
    "    predictions = pred.argmax(axis=1)\n",
    "    wandb.log({\"conf_mat\" : wandb.plot.confusion_matrix(\n",
    "                            probs=None,\n",
    "                            preds=predictions.tolist(), \n",
    "                            y_true=yval.tolist(),\n",
    "                            class_names=genre_dict)\n",
    "              })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 81846d9n with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmsaintfelix\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220901_232621-81846d9n</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/81846d9n\" target=\"_blank\">misty-sweep-1</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               245888    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 463,242\n",
      "Trainable params: 462,474\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /Users/msf/anaconda3/lib/python3.8/site-packages/tensorflow/python/ops/nn_ops.py:4893: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 40s 194ms/step - loss: 2.2066 - acc: 0.3795 - val_loss: 2.1529 - val_acc: 0.4565\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220901_232621-81846d9n/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220901_232621-81846d9n/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 1.2731 - acc: 0.5803 - val_loss: 1.3160 - val_acc: 0.6286\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220901_232621-81846d9n/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220901_232621-81846d9n/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 0.9894 - acc: 0.6629 - val_loss: 1.1857 - val_acc: 0.6366\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220901_232621-81846d9n/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220901_232621-81846d9n/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 0.8085 - acc: 0.7289 - val_loss: 1.0030 - val_acc: 0.6857\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220901_232621-81846d9n/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220901_232621-81846d9n/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "200/200 [==============================] - 35s 177ms/step - loss: 0.6344 - acc: 0.7789 - val_loss: 1.0597 - val_acc: 0.6967\n",
      "Epoch 6/30\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 0.5409 - acc: 0.8146 - val_loss: 0.8290 - val_acc: 0.7653\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220901_232621-81846d9n/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220901_232621-81846d9n/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 0.4948 - acc: 0.8333 - val_loss: 1.1613 - val_acc: 0.6902\n",
      "Epoch 8/30\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 0.4308 - acc: 0.8560 - val_loss: 0.9788 - val_acc: 0.7047\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 0.3825 - acc: 0.8728 - val_loss: 0.6997 - val_acc: 0.7798\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220901_232621-81846d9n/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220901_232621-81846d9n/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 0.2936 - acc: 0.8976 - val_loss: 0.7446 - val_acc: 0.7903\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 0.3042 - acc: 0.9038 - val_loss: 0.6798 - val_acc: 0.7938\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220901_232621-81846d9n/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220901_232621-81846d9n/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 0.2636 - acc: 0.9146 - val_loss: 0.8887 - val_acc: 0.7528\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 37s 187ms/step - loss: 0.2581 - acc: 0.9128 - val_loss: 0.9144 - val_acc: 0.7412\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 34s 171ms/step - loss: 0.2264 - acc: 0.9254 - val_loss: 0.8251 - val_acc: 0.8033\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 0.2037 - acc: 0.9281 - val_loss: 1.0099 - val_acc: 0.7758\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 34s 171ms/step - loss: 0.1977 - acc: 0.9337 - val_loss: 0.8259 - val_acc: 0.7913\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 0.1714 - acc: 0.9420 - val_loss: 1.2168 - val_acc: 0.7227\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 42s 212ms/step - loss: 0.1791 - acc: 0.9470 - val_loss: 0.8211 - val_acc: 0.8113\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 36s 183ms/step - loss: 0.1734 - acc: 0.9418 - val_loss: 1.0253 - val_acc: 0.7668\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.1319 - acc: 0.9566 - val_loss: 0.9939 - val_acc: 0.7898\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.1365 - acc: 0.9548 - val_loss: 1.0920 - val_acc: 0.7923\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1282 - acc: 0.9543 - val_loss: 0.8951 - val_acc: 0.8103\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 31s 155ms/step - loss: 0.1464 - acc: 0.9570 - val_loss: 0.9950 - val_acc: 0.8103\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 31s 154ms/step - loss: 0.1425 - acc: 0.9585 - val_loss: 1.0716 - val_acc: 0.7923\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 31s 155ms/step - loss: 0.1354 - acc: 0.9596 - val_loss: 1.0255 - val_acc: 0.8073\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 31s 157ms/step - loss: 0.1160 - acc: 0.9619 - val_loss: 1.8356 - val_acc: 0.7097\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 31s 155ms/step - loss: 0.1324 - acc: 0.9584 - val_loss: 0.9673 - val_acc: 0.8103\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 31s 155ms/step - loss: 0.1234 - acc: 0.9610 - val_loss: 0.8596 - val_acc: 0.8293\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 31s 155ms/step - loss: 0.1185 - acc: 0.9606 - val_loss: 1.1356 - val_acc: 0.7948\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 31s 154ms/step - loss: 0.1152 - acc: 0.9660 - val_loss: 0.9215 - val_acc: 0.8153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='34.152 MB of 34.152 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇▇████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▅▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▄▅▆▇▅▆▇▇▇▇▆█▇▇▆█▇▇▇██▇█▆██▇█</td></tr><tr><td>val_loss</td><td>█▄▃▃▃▂▃▂▁▁▁▂▂▂▃▂▄▂▃▂▃▂▂▃▃▆▂▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03946</td></tr><tr><td>acc</td><td>0.9634</td></tr><tr><td>best_epoch</td><td>10</td></tr><tr><td>best_val_loss</td><td>0.67985</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.11774</td></tr><tr><td>val_acc</td><td>0.81532</td></tr><tr><td>val_loss</td><td>0.92146</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">misty-sweep-1</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/81846d9n\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/81846d9n</a><br/>Synced 6 W&B file(s), 2 media file(s), 23 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220901_232621-81846d9n/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3vzp9ium with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220901_234450-3vzp9ium</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/3vzp9ium\" target=\"_blank\">fresh-sweep-2</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               245888    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 463,242\n",
      "Trainable params: 462,474\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 31s 153ms/step - loss: 1.9917 - acc: 0.3945 - val_loss: 2.0425 - val_acc: 0.5165\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220901_234450-3vzp9ium/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220901_234450-3vzp9ium/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 31s 155ms/step - loss: 1.2158 - acc: 0.5909 - val_loss: 1.3883 - val_acc: 0.5881\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220901_234450-3vzp9ium/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220901_234450-3vzp9ium/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 31s 153ms/step - loss: 0.8963 - acc: 0.7036 - val_loss: 1.2762 - val_acc: 0.6446\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220901_234450-3vzp9ium/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220901_234450-3vzp9ium/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 0.7436 - acc: 0.7525 - val_loss: 1.0703 - val_acc: 0.6957\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220901_234450-3vzp9ium/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220901_234450-3vzp9ium/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 0.5954 - acc: 0.7932 - val_loss: 1.0125 - val_acc: 0.7162\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220901_234450-3vzp9ium/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220901_234450-3vzp9ium/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 0.4795 - acc: 0.8391 - val_loss: 1.3063 - val_acc: 0.6687\n",
      "Epoch 7/30\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 0.4240 - acc: 0.8539 - val_loss: 0.9351 - val_acc: 0.7407\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220901_234450-3vzp9ium/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220901_234450-3vzp9ium/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 0.3785 - acc: 0.8779 - val_loss: 1.1821 - val_acc: 0.6922\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 0.2851 - acc: 0.9074 - val_loss: 1.0764 - val_acc: 0.7472\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - 38s 186ms/step - loss: 0.2673 - acc: 0.9106 - val_loss: 0.8246 - val_acc: 0.7863\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220901_234450-3vzp9ium/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220901_234450-3vzp9ium/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 0.2303 - acc: 0.9213 - val_loss: 0.8053 - val_acc: 0.7863\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220901_234450-3vzp9ium/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220901_234450-3vzp9ium/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 0.2071 - acc: 0.9289 - val_loss: 0.9874 - val_acc: 0.7703\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 0.1852 - acc: 0.9398 - val_loss: 1.1337 - val_acc: 0.7653\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 33s 167ms/step - loss: 0.1778 - acc: 0.9418 - val_loss: 1.1190 - val_acc: 0.7813\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 0.1406 - acc: 0.9555 - val_loss: 0.8896 - val_acc: 0.7883\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 0.1579 - acc: 0.9446 - val_loss: 1.0370 - val_acc: 0.7948\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 0.1467 - acc: 0.9504 - val_loss: 1.3359 - val_acc: 0.7798\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 0.1396 - acc: 0.9559 - val_loss: 1.4584 - val_acc: 0.7467\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 0.1269 - acc: 0.9562 - val_loss: 0.9441 - val_acc: 0.7893\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 33s 165ms/step - loss: 0.1177 - acc: 0.9622 - val_loss: 1.2093 - val_acc: 0.7973\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 0.1271 - acc: 0.9589 - val_loss: 1.2418 - val_acc: 0.7452\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 0.1123 - acc: 0.9684 - val_loss: 0.9873 - val_acc: 0.7943\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 0.1103 - acc: 0.9705 - val_loss: 1.1401 - val_acc: 0.7743\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 33s 166ms/step - loss: 0.0962 - acc: 0.9656 - val_loss: 1.0437 - val_acc: 0.7958\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 0.1174 - acc: 0.9624 - val_loss: 1.0716 - val_acc: 0.8033\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 33s 166ms/step - loss: 0.0800 - acc: 0.9768 - val_loss: 1.2105 - val_acc: 0.7748\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 33s 165ms/step - loss: 0.1179 - acc: 0.9619 - val_loss: 0.9934 - val_acc: 0.8318\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 33s 165ms/step - loss: 0.0858 - acc: 0.9742 - val_loss: 0.9601 - val_acc: 0.8293\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 33s 165ms/step - loss: 0.0869 - acc: 0.9717 - val_loss: 1.1447 - val_acc: 0.8013\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 34s 168ms/step - loss: 0.0861 - acc: 0.9744 - val_loss: 1.1825 - val_acc: 0.7973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='38.001 MB of 38.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▆▆▆▇▇▇▇▇▇█████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▅▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▄▅▅▄▆▅▆▇▇▇▇▇▇▇▇▆▇▇▆▇▇▇▇▇██▇▇</td></tr><tr><td>val_loss</td><td>█▄▄▂▂▄▂▃▃▁▁▂▃▃▁▂▄▅▂▃▃▂▃▂▃▃▂▂▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03946</td></tr><tr><td>acc</td><td>0.97356</td></tr><tr><td>best_epoch</td><td>10</td></tr><tr><td>best_val_loss</td><td>0.80527</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.08328</td></tr><tr><td>val_acc</td><td>0.7973</td></tr><tr><td>val_loss</td><td>1.18252</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fresh-sweep-2</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/3vzp9ium\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/3vzp9ium</a><br/>Synced 6 W&B file(s), 2 media file(s), 26 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220901_234450-3vzp9ium/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9qbtu5ep with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_000330-9qbtu5ep</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/9qbtu5ep\" target=\"_blank\">good-sweep-3</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                122944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 339,658\n",
      "Trainable params: 338,890\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 33s 160ms/step - loss: 1.9729 - acc: 0.3835 - val_loss: 2.7953 - val_acc: 0.3949\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_000330-9qbtu5ep/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_000330-9qbtu5ep/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 1.1387 - acc: 0.6048 - val_loss: 1.8502 - val_acc: 0.5370\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_000330-9qbtu5ep/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_000330-9qbtu5ep/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.9167 - acc: 0.6830 - val_loss: 1.1524 - val_acc: 0.6351\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_000330-9qbtu5ep/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_000330-9qbtu5ep/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.7112 - acc: 0.7509 - val_loss: 1.3298 - val_acc: 0.6136\n",
      "Epoch 5/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.6149 - acc: 0.7912 - val_loss: 1.0131 - val_acc: 0.6902\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_000330-9qbtu5ep/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_000330-9qbtu5ep/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.5208 - acc: 0.8192 - val_loss: 0.9225 - val_acc: 0.7272\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_000330-9qbtu5ep/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_000330-9qbtu5ep/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.4273 - acc: 0.8514 - val_loss: 1.1109 - val_acc: 0.7142\n",
      "Epoch 8/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.3948 - acc: 0.8699 - val_loss: 0.7539 - val_acc: 0.7718\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_000330-9qbtu5ep/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_000330-9qbtu5ep/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.3244 - acc: 0.8869 - val_loss: 0.7504 - val_acc: 0.7673\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_000330-9qbtu5ep/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_000330-9qbtu5ep/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.2869 - acc: 0.9012 - val_loss: 0.6607 - val_acc: 0.8103\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_000330-9qbtu5ep/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_000330-9qbtu5ep/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 0.2427 - acc: 0.9215 - val_loss: 0.7353 - val_acc: 0.7933\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2248 - acc: 0.9247 - val_loss: 0.8617 - val_acc: 0.7843\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.2089 - acc: 0.9338 - val_loss: 0.9159 - val_acc: 0.7623\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.1896 - acc: 0.9360 - val_loss: 0.9938 - val_acc: 0.7883\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.1777 - acc: 0.9363 - val_loss: 1.0720 - val_acc: 0.7568\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.1711 - acc: 0.9424 - val_loss: 1.0257 - val_acc: 0.7663\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 0.1565 - acc: 0.9473 - val_loss: 0.8222 - val_acc: 0.8003\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.1393 - acc: 0.9531 - val_loss: 1.0610 - val_acc: 0.7663\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.1503 - acc: 0.9491 - val_loss: 1.3241 - val_acc: 0.7427\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.1489 - acc: 0.9554 - val_loss: 1.5428 - val_acc: 0.7017\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 30s 152ms/step - loss: 0.1348 - acc: 0.9569 - val_loss: 0.9377 - val_acc: 0.8168\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1300 - acc: 0.9604 - val_loss: 1.0735 - val_acc: 0.7893\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1137 - acc: 0.9631 - val_loss: 0.8371 - val_acc: 0.8188\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1213 - acc: 0.9610 - val_loss: 1.2287 - val_acc: 0.7673\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.1074 - acc: 0.9634 - val_loss: 1.1350 - val_acc: 0.7963\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.0962 - acc: 0.9690 - val_loss: 1.1191 - val_acc: 0.7983\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.1065 - acc: 0.9617 - val_loss: 1.0135 - val_acc: 0.8093\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 30s 152ms/step - loss: 0.0751 - acc: 0.9753 - val_loss: 1.0606 - val_acc: 0.7898\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 31s 153ms/step - loss: 0.1113 - acc: 0.9638 - val_loss: 0.8988 - val_acc: 0.8193\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.1016 - acc: 0.9684 - val_loss: 1.0864 - val_acc: 0.7903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='28.571 MB of 28.573 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.9999…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▆▆▆▇▇▇▇▇▇█▇███████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▅▄▃▃▃▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▅▅▆▆▆▇▇██▇▇▇▇▇█▇▇▆███▇██████</td></tr><tr><td>val_loss</td><td>█▅▃▃▂▂▂▁▁▁▁▂▂▂▂▂▂▂▃▄▂▂▂▃▃▃▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03933</td></tr><tr><td>acc</td><td>0.9659</td></tr><tr><td>best_epoch</td><td>9</td></tr><tr><td>best_val_loss</td><td>0.6607</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.11203</td></tr><tr><td>val_acc</td><td>0.79029</td></tr><tr><td>val_loss</td><td>1.08639</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">good-sweep-3</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/9qbtu5ep\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/9qbtu5ep</a><br/>Synced 6 W&B file(s), 2 media file(s), 26 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_000330-9qbtu5ep/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gmipcyxx with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_002013-gmipcyxx</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/gmipcyxx\" target=\"_blank\">comic-sweep-4</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                122944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 339,658\n",
      "Trainable params: 338,890\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 33s 159ms/step - loss: 2.0253 - acc: 0.3766 - val_loss: 2.1563 - val_acc: 0.4499\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_002013-gmipcyxx/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_002013-gmipcyxx/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 1.2827 - acc: 0.5803 - val_loss: 1.3086 - val_acc: 0.5836\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_002013-gmipcyxx/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_002013-gmipcyxx/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 1.0454 - acc: 0.6452 - val_loss: 1.0780 - val_acc: 0.6607\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_002013-gmipcyxx/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_002013-gmipcyxx/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.8359 - acc: 0.7237 - val_loss: 0.8326 - val_acc: 0.7092\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_002013-gmipcyxx/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_002013-gmipcyxx/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.7133 - acc: 0.7500 - val_loss: 0.8940 - val_acc: 0.7362\n",
      "Epoch 6/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.6054 - acc: 0.7883 - val_loss: 0.8963 - val_acc: 0.7017\n",
      "Epoch 7/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.5381 - acc: 0.8084 - val_loss: 0.9507 - val_acc: 0.6967\n",
      "Epoch 8/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.4603 - acc: 0.8479 - val_loss: 0.8495 - val_acc: 0.7392\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.3986 - acc: 0.8659 - val_loss: 0.8524 - val_acc: 0.7658\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.3672 - acc: 0.8722 - val_loss: 1.0858 - val_acc: 0.7162\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.3175 - acc: 0.8854 - val_loss: 0.8117 - val_acc: 0.7678\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_002013-gmipcyxx/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_002013-gmipcyxx/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.3409 - acc: 0.8872 - val_loss: 1.0400 - val_acc: 0.7072\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.2777 - acc: 0.9057 - val_loss: 0.7727 - val_acc: 0.8013\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_002013-gmipcyxx/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_002013-gmipcyxx/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2468 - acc: 0.9125 - val_loss: 0.8098 - val_acc: 0.7943\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2458 - acc: 0.9165 - val_loss: 0.9024 - val_acc: 0.7803\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2077 - acc: 0.9276 - val_loss: 0.8635 - val_acc: 0.7818\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.2128 - acc: 0.9294 - val_loss: 0.7317 - val_acc: 0.7983\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_002013-gmipcyxx/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_002013-gmipcyxx/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.2056 - acc: 0.9319 - val_loss: 0.9001 - val_acc: 0.7863\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1611 - acc: 0.9453 - val_loss: 1.0785 - val_acc: 0.7798\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.1749 - acc: 0.9436 - val_loss: 1.0436 - val_acc: 0.7558\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.1493 - acc: 0.9495 - val_loss: 0.8578 - val_acc: 0.8093\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1620 - acc: 0.9463 - val_loss: 0.9807 - val_acc: 0.8063\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.1534 - acc: 0.9519 - val_loss: 0.8155 - val_acc: 0.7993\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.1466 - acc: 0.9513 - val_loss: 1.2267 - val_acc: 0.7753\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.1505 - acc: 0.9506 - val_loss: 0.9830 - val_acc: 0.7698\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 31s 157ms/step - loss: 0.1377 - acc: 0.9546 - val_loss: 1.0790 - val_acc: 0.8038\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1420 - acc: 0.9540 - val_loss: 0.7727 - val_acc: 0.8183\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1117 - acc: 0.9636 - val_loss: 0.7708 - val_acc: 0.8123\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1320 - acc: 0.9563 - val_loss: 1.0004 - val_acc: 0.7778\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.1230 - acc: 0.9588 - val_loss: 0.8217 - val_acc: 0.8063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='25.668 MB of 25.670 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.9999…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▅▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▅▆▆▆▆▆▇▆▇▆██▇▇█▇▇▇███▇▇███▇█</td></tr><tr><td>val_loss</td><td>█▄▃▁▂▂▂▂▂▃▁▃▁▁▂▂▁▂▃▃▂▂▁▃▂▃▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03933</td></tr><tr><td>acc</td><td>0.95902</td></tr><tr><td>best_epoch</td><td>16</td></tr><tr><td>best_val_loss</td><td>0.73168</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.1275</td></tr><tr><td>val_acc</td><td>0.80631</td></tr><tr><td>val_loss</td><td>0.82167</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">comic-sweep-4</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/gmipcyxx\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/gmipcyxx</a><br/>Synced 6 W&B file(s), 2 media file(s), 23 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_002013-gmipcyxx/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: s2e7rh7t with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_003645-s2e7rh7t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/s2e7rh7t\" target=\"_blank\">gentle-sweep-5</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                122944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 339,658\n",
      "Trainable params: 338,890\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 1.9355 - acc: 0.3860 - val_loss: 3.0586 - val_acc: 0.3899\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_003645-s2e7rh7t/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_003645-s2e7rh7t/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 1.1872 - acc: 0.5962 - val_loss: 1.3574 - val_acc: 0.5866\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_003645-s2e7rh7t/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_003645-s2e7rh7t/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.9353 - acc: 0.6869 - val_loss: 0.9763 - val_acc: 0.6592\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_003645-s2e7rh7t/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_003645-s2e7rh7t/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "200/200 [==============================] - 31s 153ms/step - loss: 0.7411 - acc: 0.7438 - val_loss: 1.5166 - val_acc: 0.6046\n",
      "Epoch 5/30\n",
      "200/200 [==============================] - 31s 155ms/step - loss: 0.5956 - acc: 0.7992 - val_loss: 1.0108 - val_acc: 0.6867\n",
      "Epoch 6/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.4976 - acc: 0.8238 - val_loss: 0.9103 - val_acc: 0.7322\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_003645-s2e7rh7t/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_003645-s2e7rh7t/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "200/200 [==============================] - 33s 165ms/step - loss: 0.4019 - acc: 0.8566 - val_loss: 0.6904 - val_acc: 0.7823\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_003645-s2e7rh7t/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_003645-s2e7rh7t/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 0.3752 - acc: 0.8653 - val_loss: 0.8497 - val_acc: 0.7482\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 0.3109 - acc: 0.8910 - val_loss: 0.8164 - val_acc: 0.7793\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 0.2933 - acc: 0.9020 - val_loss: 0.8984 - val_acc: 0.7658\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 0.2532 - acc: 0.9060 - val_loss: 1.0249 - val_acc: 0.7272\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 0.2369 - acc: 0.9186 - val_loss: 0.7592 - val_acc: 0.7983\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 33s 166ms/step - loss: 0.1931 - acc: 0.9288 - val_loss: 0.7658 - val_acc: 0.7978\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 0.1732 - acc: 0.9425 - val_loss: 1.3926 - val_acc: 0.7077\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 0.1623 - acc: 0.9444 - val_loss: 0.7970 - val_acc: 0.7878\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 0.1768 - acc: 0.9485 - val_loss: 0.8031 - val_acc: 0.7918\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 0.1506 - acc: 0.9479 - val_loss: 0.8993 - val_acc: 0.7863\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 30s 152ms/step - loss: 0.1553 - acc: 0.9526 - val_loss: 0.8880 - val_acc: 0.7943\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 31s 153ms/step - loss: 0.1455 - acc: 0.9505 - val_loss: 0.9925 - val_acc: 0.7828\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 30s 152ms/step - loss: 0.1281 - acc: 0.9613 - val_loss: 1.0194 - val_acc: 0.7753\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1319 - acc: 0.9544 - val_loss: 0.9184 - val_acc: 0.8118\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 31s 153ms/step - loss: 0.1036 - acc: 0.9668 - val_loss: 1.0513 - val_acc: 0.7833\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 31s 155ms/step - loss: 0.1303 - acc: 0.9597 - val_loss: 0.8745 - val_acc: 0.7978\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 31s 154ms/step - loss: 0.1009 - acc: 0.9658 - val_loss: 1.1357 - val_acc: 0.7833\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1085 - acc: 0.9689 - val_loss: 0.9051 - val_acc: 0.8158\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1117 - acc: 0.9636 - val_loss: 0.9302 - val_acc: 0.8043\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.0928 - acc: 0.9711 - val_loss: 0.9289 - val_acc: 0.8148\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 30s 152ms/step - loss: 0.0895 - acc: 0.9699 - val_loss: 1.2312 - val_acc: 0.7938\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 31s 155ms/step - loss: 0.0934 - acc: 0.9689 - val_loss: 0.9556 - val_acc: 0.8118\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 31s 154ms/step - loss: 0.0902 - acc: 0.9723 - val_loss: 1.1856 - val_acc: 0.7918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='19.856 MB of 19.858 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.9998…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▅▆▆▇▇▇▇▇▇█████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▅▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▅▅▆▇▇▇▇▇▇██▆████▇▇█▇█▇██████</td></tr><tr><td>val_loss</td><td>█▃▂▃▂▂▁▁▁▂▂▁▁▃▁▁▂▂▂▂▂▂▂▂▂▂▂▃▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03933</td></tr><tr><td>acc</td><td>0.96965</td></tr><tr><td>best_epoch</td><td>6</td></tr><tr><td>best_val_loss</td><td>0.6904</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.10353</td></tr><tr><td>val_acc</td><td>0.79179</td></tr><tr><td>val_loss</td><td>1.18561</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">gentle-sweep-5</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/s2e7rh7t\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/s2e7rh7t</a><br/>Synced 6 W&B file(s), 2 media file(s), 17 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_003645-s2e7rh7t/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: z0saw5tz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_005321-z0saw5tz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/z0saw5tz\" target=\"_blank\">zesty-sweep-6</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                122944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 339,658\n",
      "Trainable params: 338,890\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 34s 163ms/step - loss: 2.0110 - acc: 0.3764 - val_loss: 2.0850 - val_acc: 0.4374\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_005321-z0saw5tz/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_005321-z0saw5tz/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 1.1953 - acc: 0.5958 - val_loss: 2.1393 - val_acc: 0.4600\n",
      "Epoch 3/30\n",
      "200/200 [==============================] - 32s 163ms/step - loss: 0.9124 - acc: 0.6898 - val_loss: 1.1096 - val_acc: 0.6642\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_005321-z0saw5tz/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_005321-z0saw5tz/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.7396 - acc: 0.7403 - val_loss: 1.0364 - val_acc: 0.6717\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_005321-z0saw5tz/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_005321-z0saw5tz/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.6260 - acc: 0.7757 - val_loss: 0.9118 - val_acc: 0.7012\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_005321-z0saw5tz/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_005321-z0saw5tz/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.5166 - acc: 0.8190 - val_loss: 0.8732 - val_acc: 0.7297\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_005321-z0saw5tz/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_005321-z0saw5tz/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 0.4285 - acc: 0.8551 - val_loss: 0.8555 - val_acc: 0.7573\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_005321-z0saw5tz/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_005321-z0saw5tz/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.4186 - acc: 0.8575 - val_loss: 0.9410 - val_acc: 0.7452\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.3517 - acc: 0.8779 - val_loss: 0.8118 - val_acc: 0.7708\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_005321-z0saw5tz/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_005321-z0saw5tz/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.3072 - acc: 0.8937 - val_loss: 0.9793 - val_acc: 0.7362\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.2760 - acc: 0.9094 - val_loss: 0.8371 - val_acc: 0.7743\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 31s 157ms/step - loss: 0.2536 - acc: 0.9144 - val_loss: 0.9824 - val_acc: 0.7508\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 31s 154ms/step - loss: 0.2362 - acc: 0.9233 - val_loss: 1.1107 - val_acc: 0.7412\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 30s 152ms/step - loss: 0.2048 - acc: 0.9267 - val_loss: 0.7429 - val_acc: 0.8018\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_005321-z0saw5tz/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_005321-z0saw5tz/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 0.1865 - acc: 0.9368 - val_loss: 1.0094 - val_acc: 0.7683\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 0.1816 - acc: 0.9327 - val_loss: 0.8480 - val_acc: 0.7908\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.1477 - acc: 0.9524 - val_loss: 0.8446 - val_acc: 0.7863\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.1613 - acc: 0.9456 - val_loss: 0.9994 - val_acc: 0.7798\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.1374 - acc: 0.9528 - val_loss: 1.0952 - val_acc: 0.7653\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.1384 - acc: 0.9496 - val_loss: 0.8789 - val_acc: 0.7948\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.1210 - acc: 0.9572 - val_loss: 1.1024 - val_acc: 0.7738\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.1337 - acc: 0.9590 - val_loss: 1.2046 - val_acc: 0.7668\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.1312 - acc: 0.9605 - val_loss: 1.2511 - val_acc: 0.7718\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.1119 - acc: 0.9644 - val_loss: 1.0815 - val_acc: 0.7878\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.1104 - acc: 0.9659 - val_loss: 0.9212 - val_acc: 0.8078\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.0977 - acc: 0.9692 - val_loss: 1.0688 - val_acc: 0.7863\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.1331 - acc: 0.9576 - val_loss: 1.0815 - val_acc: 0.8033\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 34s 172ms/step - loss: 0.0937 - acc: 0.9687 - val_loss: 1.0067 - val_acc: 0.8013\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 34s 172ms/step - loss: 0.1020 - acc: 0.9706 - val_loss: 1.0616 - val_acc: 0.8013\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 34s 170ms/step - loss: 0.0977 - acc: 0.9683 - val_loss: 1.1576 - val_acc: 0.7923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='28.574 MB of 28.576 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.9999…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇▇████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▅▅▆▇▇▇▇▇▇▇▇█▇██▇▇█▇▇▇███████</td></tr><tr><td>val_loss</td><td>██▃▂▂▂▂▂▁▂▁▂▃▁▂▂▂▂▃▂▃▃▄▃▂▃▃▂▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03933</td></tr><tr><td>acc</td><td>0.967</td></tr><tr><td>best_epoch</td><td>13</td></tr><tr><td>best_val_loss</td><td>0.74289</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.10747</td></tr><tr><td>val_acc</td><td>0.79229</td></tr><tr><td>val_loss</td><td>1.15755</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">zesty-sweep-6</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/z0saw5tz\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/z0saw5tz</a><br/>Synced 6 W&B file(s), 2 media file(s), 26 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_005321-z0saw5tz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 5ja9ciza with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_011030-5ja9ciza</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/5ja9ciza\" target=\"_blank\">morning-sweep-7</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                122944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 339,658\n",
      "Trainable params: 338,890\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 35s 170ms/step - loss: 2.0763 - acc: 0.3630 - val_loss: 2.0521 - val_acc: 0.3954\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_011030-5ja9ciza/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_011030-5ja9ciza/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 1.2686 - acc: 0.5694 - val_loss: 1.2917 - val_acc: 0.6031\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_011030-5ja9ciza/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_011030-5ja9ciza/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.9832 - acc: 0.6602 - val_loss: 1.0488 - val_acc: 0.6622\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_011030-5ja9ciza/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_011030-5ja9ciza/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "200/200 [==============================] - 31s 157ms/step - loss: 0.7981 - acc: 0.7223 - val_loss: 1.1137 - val_acc: 0.6662\n",
      "Epoch 5/30\n",
      "200/200 [==============================] - 31s 155ms/step - loss: 0.7076 - acc: 0.7547 - val_loss: 1.1815 - val_acc: 0.6857\n",
      "Epoch 6/30\n",
      "200/200 [==============================] - 31s 153ms/step - loss: 0.6001 - acc: 0.7939 - val_loss: 0.7998 - val_acc: 0.7437\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_011030-5ja9ciza/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_011030-5ja9ciza/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.5288 - acc: 0.8129 - val_loss: 0.8068 - val_acc: 0.7452\n",
      "Epoch 8/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.4704 - acc: 0.8419 - val_loss: 0.9443 - val_acc: 0.7282\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.4247 - acc: 0.8477 - val_loss: 0.7136 - val_acc: 0.7898\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_011030-5ja9ciza/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_011030-5ja9ciza/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.3524 - acc: 0.8820 - val_loss: 0.8612 - val_acc: 0.7588\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.3519 - acc: 0.8819 - val_loss: 0.7608 - val_acc: 0.7638\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.2985 - acc: 0.8966 - val_loss: 0.9315 - val_acc: 0.7452\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2755 - acc: 0.8990 - val_loss: 0.7183 - val_acc: 0.7918\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2760 - acc: 0.9073 - val_loss: 0.9542 - val_acc: 0.7683\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.2329 - acc: 0.9199 - val_loss: 0.8001 - val_acc: 0.7938\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2279 - acc: 0.9287 - val_loss: 1.4356 - val_acc: 0.7012\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2192 - acc: 0.9286 - val_loss: 0.9411 - val_acc: 0.7553\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 0.1861 - acc: 0.9390 - val_loss: 0.7339 - val_acc: 0.8148\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 34s 170ms/step - loss: 0.2163 - acc: 0.9302 - val_loss: 0.8674 - val_acc: 0.7833\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 34s 169ms/step - loss: 0.1792 - acc: 0.9398 - val_loss: 1.0401 - val_acc: 0.7523\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 0.1590 - acc: 0.9462 - val_loss: 0.8748 - val_acc: 0.7738\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 31s 153ms/step - loss: 0.1523 - acc: 0.9509 - val_loss: 0.9649 - val_acc: 0.7833\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.1578 - acc: 0.9517 - val_loss: 0.8230 - val_acc: 0.8003\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.1565 - acc: 0.9502 - val_loss: 1.0598 - val_acc: 0.7903\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.1534 - acc: 0.9490 - val_loss: 0.9355 - val_acc: 0.8078\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.1616 - acc: 0.9467 - val_loss: 1.1572 - val_acc: 0.7753\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.1392 - acc: 0.9517 - val_loss: 0.9811 - val_acc: 0.7853\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 31s 153ms/step - loss: 0.1356 - acc: 0.9539 - val_loss: 0.9646 - val_acc: 0.8003\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 31s 153ms/step - loss: 0.1656 - acc: 0.9532 - val_loss: 1.0183 - val_acc: 0.8133\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.1146 - acc: 0.9666 - val_loss: 1.3110 - val_acc: 0.7713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='19.858 MB of 19.858 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇▇▇███████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▅▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▅▆▆▇▇▇█▇▇▇█▇█▆▇█▇▇▇▇███▇███▇</td></tr><tr><td>val_loss</td><td>█▄▃▃▃▁▁▂▁▂▁▂▁▂▁▅▂▁▂▃▂▂▂▃▂▃▂▂▃▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03933</td></tr><tr><td>acc</td><td>0.95808</td></tr><tr><td>best_epoch</td><td>8</td></tr><tr><td>best_val_loss</td><td>0.71358</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.14475</td></tr><tr><td>val_acc</td><td>0.77127</td></tr><tr><td>val_loss</td><td>1.31103</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">morning-sweep-7</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/5ja9ciza\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/5ja9ciza</a><br/>Synced 6 W&B file(s), 2 media file(s), 17 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_011030-5ja9ciza/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bpr0ot7i with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_012705-bpr0ot7i</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/bpr0ot7i\" target=\"_blank\">royal-sweep-8</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                122944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 339,658\n",
      "Trainable params: 338,890\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 32s 155ms/step - loss: 2.0697 - acc: 0.3784 - val_loss: 2.0784 - val_acc: 0.4515\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_012705-bpr0ot7i/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_012705-bpr0ot7i/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 31s 156ms/step - loss: 1.2557 - acc: 0.5724 - val_loss: 1.2793 - val_acc: 0.5986\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_012705-bpr0ot7i/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_012705-bpr0ot7i/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 31s 157ms/step - loss: 0.9438 - acc: 0.6791 - val_loss: 1.0359 - val_acc: 0.6522\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_012705-bpr0ot7i/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_012705-bpr0ot7i/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.8294 - acc: 0.7166 - val_loss: 0.9672 - val_acc: 0.6932\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_012705-bpr0ot7i/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_012705-bpr0ot7i/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.6727 - acc: 0.7735 - val_loss: 1.0076 - val_acc: 0.6877\n",
      "Epoch 6/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.6040 - acc: 0.7950 - val_loss: 1.2096 - val_acc: 0.6572\n",
      "Epoch 7/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.5100 - acc: 0.8209 - val_loss: 0.7287 - val_acc: 0.7663\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_012705-bpr0ot7i/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_012705-bpr0ot7i/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.4227 - acc: 0.8597 - val_loss: 0.7715 - val_acc: 0.7563\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.3819 - acc: 0.8734 - val_loss: 0.8030 - val_acc: 0.7372\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.3648 - acc: 0.8776 - val_loss: 0.7140 - val_acc: 0.7898\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_012705-bpr0ot7i/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_012705-bpr0ot7i/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.3021 - acc: 0.8974 - val_loss: 0.7630 - val_acc: 0.7848\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.2792 - acc: 0.8998 - val_loss: 0.8391 - val_acc: 0.7798\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 31s 157ms/step - loss: 0.2482 - acc: 0.9080 - val_loss: 0.8307 - val_acc: 0.7713\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.2382 - acc: 0.9173 - val_loss: 0.8064 - val_acc: 0.7938\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.2075 - acc: 0.9287 - val_loss: 0.8231 - val_acc: 0.7988\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.2324 - acc: 0.9176 - val_loss: 0.8259 - val_acc: 0.7798\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1873 - acc: 0.9359 - val_loss: 0.7690 - val_acc: 0.7883\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1906 - acc: 0.9424 - val_loss: 0.8174 - val_acc: 0.7978\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1730 - acc: 0.9448 - val_loss: 0.8511 - val_acc: 0.7948\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1572 - acc: 0.9456 - val_loss: 0.8560 - val_acc: 0.8048\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1437 - acc: 0.9534 - val_loss: 0.9218 - val_acc: 0.7863\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1618 - acc: 0.9452 - val_loss: 0.9011 - val_acc: 0.8038\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1461 - acc: 0.9547 - val_loss: 0.8600 - val_acc: 0.7878\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1611 - acc: 0.9480 - val_loss: 0.8300 - val_acc: 0.8043\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.1473 - acc: 0.9562 - val_loss: 1.2570 - val_acc: 0.7508\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1444 - acc: 0.9549 - val_loss: 0.8166 - val_acc: 0.8433\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1157 - acc: 0.9616 - val_loss: 0.8082 - val_acc: 0.8168\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1131 - acc: 0.9654 - val_loss: 1.0102 - val_acc: 0.8093\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 30s 152ms/step - loss: 0.1269 - acc: 0.9620 - val_loss: 0.9672 - val_acc: 0.8188\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1400 - acc: 0.9607 - val_loss: 0.8681 - val_acc: 0.8128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='22.762 MB of 22.764 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.9998…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇▇█▇██████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▅▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▅▅▅▅▇▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇▆██▇█▇</td></tr><tr><td>val_loss</td><td>█▄▃▂▃▄▁▁▁▁▁▂▂▁▂▂▁▂▂▂▂▂▂▂▄▂▁▃▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03933</td></tr><tr><td>acc</td><td>0.95745</td></tr><tr><td>best_epoch</td><td>9</td></tr><tr><td>best_val_loss</td><td>0.71397</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.14289</td></tr><tr><td>val_acc</td><td>0.81281</td></tr><tr><td>val_loss</td><td>0.86809</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">royal-sweep-8</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/bpr0ot7i\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/bpr0ot7i</a><br/>Synced 6 W&B file(s), 2 media file(s), 20 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_012705-bpr0ot7i/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7a59kr1w with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_014312-7a59kr1w</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/7a59kr1w\" target=\"_blank\">electric-sweep-9</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                122944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 339,658\n",
      "Trainable params: 338,890\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 2.0004 - acc: 0.3827 - val_loss: 1.7998 - val_acc: 0.4855\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_014312-7a59kr1w/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_014312-7a59kr1w/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 1.2695 - acc: 0.5771 - val_loss: 1.7253 - val_acc: 0.4830\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_014312-7a59kr1w/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_014312-7a59kr1w/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.9494 - acc: 0.6765 - val_loss: 1.6129 - val_acc: 0.5766\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_014312-7a59kr1w/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_014312-7a59kr1w/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.8046 - acc: 0.7295 - val_loss: 1.2026 - val_acc: 0.6607\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_014312-7a59kr1w/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_014312-7a59kr1w/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.6800 - acc: 0.7782 - val_loss: 1.3391 - val_acc: 0.6146\n",
      "Epoch 6/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.5785 - acc: 0.7971 - val_loss: 0.8506 - val_acc: 0.7427\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_014312-7a59kr1w/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_014312-7a59kr1w/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.5024 - acc: 0.8298 - val_loss: 0.9884 - val_acc: 0.6977\n",
      "Epoch 8/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.4663 - acc: 0.8485 - val_loss: 0.8599 - val_acc: 0.7322\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.4202 - acc: 0.8567 - val_loss: 0.9567 - val_acc: 0.7217\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.3954 - acc: 0.8658 - val_loss: 1.1296 - val_acc: 0.7392\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.3310 - acc: 0.8879 - val_loss: 0.8596 - val_acc: 0.7548\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.2974 - acc: 0.8983 - val_loss: 1.1926 - val_acc: 0.7187\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2952 - acc: 0.9047 - val_loss: 0.8533 - val_acc: 0.7753\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2663 - acc: 0.9109 - val_loss: 0.8660 - val_acc: 0.7843\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2431 - acc: 0.9180 - val_loss: 0.8754 - val_acc: 0.7703\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.2308 - acc: 0.9193 - val_loss: 1.0087 - val_acc: 0.7653\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2051 - acc: 0.9334 - val_loss: 1.1049 - val_acc: 0.7563\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.2054 - acc: 0.9365 - val_loss: 0.7914 - val_acc: 0.7993\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_014312-7a59kr1w/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_014312-7a59kr1w/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30\n",
      "200/200 [==============================] - 31s 156ms/step - loss: 0.2003 - acc: 0.9368 - val_loss: 1.0199 - val_acc: 0.7923\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1488 - acc: 0.9484 - val_loss: 0.8115 - val_acc: 0.8048\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1839 - acc: 0.9390 - val_loss: 0.8846 - val_acc: 0.7828\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1611 - acc: 0.9461 - val_loss: 0.9043 - val_acc: 0.7863\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1519 - acc: 0.9504 - val_loss: 0.9332 - val_acc: 0.8028\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1763 - acc: 0.9423 - val_loss: 0.8412 - val_acc: 0.7858\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1343 - acc: 0.9556 - val_loss: 1.4945 - val_acc: 0.7172\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1623 - acc: 0.9487 - val_loss: 1.0306 - val_acc: 0.7893\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.1311 - acc: 0.9593 - val_loss: 1.1102 - val_acc: 0.7838\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1135 - acc: 0.9617 - val_loss: 0.7488 - val_acc: 0.8288\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_014312-7a59kr1w/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_014312-7a59kr1w/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1355 - acc: 0.9602 - val_loss: 1.3220 - val_acc: 0.7553\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1218 - acc: 0.9639 - val_loss: 1.1232 - val_acc: 0.8093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='25.668 MB of 25.670 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.9999…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▅▄▄▃▃▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▃▅▄▆▅▆▆▆▇▆▇▇▇▇▇▇▇█▇▇▇▇▆▇▇█▇█</td></tr><tr><td>val_loss</td><td>██▇▄▅▂▃▂▂▄▂▄▂▂▂▃▃▁▃▁▂▂▂▂▆▃▃▁▅▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03933</td></tr><tr><td>acc</td><td>0.95964</td></tr><tr><td>best_epoch</td><td>27</td></tr><tr><td>best_val_loss</td><td>0.7488</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.13473</td></tr><tr><td>val_acc</td><td>0.80931</td></tr><tr><td>val_loss</td><td>1.12322</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">electric-sweep-9</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/7a59kr1w\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/7a59kr1w</a><br/>Synced 6 W&B file(s), 2 media file(s), 23 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_014312-7a59kr1w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: brv0tlz0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_015940-brv0tlz0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/brv0tlz0\" target=\"_blank\">glorious-sweep-10</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                122944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 339,658\n",
      "Trainable params: 338,890\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 33s 159ms/step - loss: 2.0999 - acc: 0.3656 - val_loss: 1.9260 - val_acc: 0.4184\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_015940-brv0tlz0/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_015940-brv0tlz0/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 1.2295 - acc: 0.5783 - val_loss: 1.0432 - val_acc: 0.6657\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_015940-brv0tlz0/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_015940-brv0tlz0/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.9102 - acc: 0.6845 - val_loss: 1.2116 - val_acc: 0.6371\n",
      "Epoch 4/30\n",
      "200/200 [==============================] - 30s 152ms/step - loss: 0.7442 - acc: 0.7430 - val_loss: 0.9675 - val_acc: 0.6987\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_015940-brv0tlz0/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_015940-brv0tlz0/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 0.6137 - acc: 0.7922 - val_loss: 0.8699 - val_acc: 0.7297\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_015940-brv0tlz0/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_015940-brv0tlz0/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 0.5148 - acc: 0.8154 - val_loss: 0.8857 - val_acc: 0.7157\n",
      "Epoch 7/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.4637 - acc: 0.8419 - val_loss: 1.2832 - val_acc: 0.6732\n",
      "Epoch 8/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.3932 - acc: 0.8622 - val_loss: 0.8515 - val_acc: 0.7337\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_015940-brv0tlz0/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_015940-brv0tlz0/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "200/200 [==============================] - 31s 155ms/step - loss: 0.3254 - acc: 0.8934 - val_loss: 1.0642 - val_acc: 0.7152\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.2973 - acc: 0.8995 - val_loss: 0.8093 - val_acc: 0.7688\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_015940-brv0tlz0/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_015940-brv0tlz0/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2322 - acc: 0.9192 - val_loss: 0.8264 - val_acc: 0.7768\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.2096 - acc: 0.9282 - val_loss: 0.9697 - val_acc: 0.7613\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 31s 153ms/step - loss: 0.2247 - acc: 0.9258 - val_loss: 0.8468 - val_acc: 0.7698\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.2075 - acc: 0.9309 - val_loss: 1.1796 - val_acc: 0.7102\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 30s 152ms/step - loss: 0.1787 - acc: 0.9393 - val_loss: 0.8934 - val_acc: 0.7798\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.1799 - acc: 0.9405 - val_loss: 0.8861 - val_acc: 0.7963\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.1729 - acc: 0.9419 - val_loss: 0.9677 - val_acc: 0.7833\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1497 - acc: 0.9463 - val_loss: 0.9063 - val_acc: 0.7853\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.1557 - acc: 0.9501 - val_loss: 0.9566 - val_acc: 0.7618\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.1174 - acc: 0.9601 - val_loss: 1.6106 - val_acc: 0.6962\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.1350 - acc: 0.9575 - val_loss: 0.7946 - val_acc: 0.8223\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_015940-brv0tlz0/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_015940-brv0tlz0/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1130 - acc: 0.9621 - val_loss: 1.0187 - val_acc: 0.7958\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1270 - acc: 0.9567 - val_loss: 0.9433 - val_acc: 0.7943\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1288 - acc: 0.9626 - val_loss: 1.0862 - val_acc: 0.7673\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1139 - acc: 0.9618 - val_loss: 0.9787 - val_acc: 0.7848\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.1072 - acc: 0.9631 - val_loss: 0.9308 - val_acc: 0.8128\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.1250 - acc: 0.9612 - val_loss: 0.9669 - val_acc: 0.7848\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.0949 - acc: 0.9657 - val_loss: 0.9971 - val_acc: 0.7948\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1028 - acc: 0.9660 - val_loss: 1.1414 - val_acc: 0.7728\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.0886 - acc: 0.9716 - val_loss: 0.8454 - val_acc: 0.8163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='25.668 MB of 25.670 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.9999…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇▇████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▅▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▅▅▆▆▆▅▆▆▇▇▇▇▆▇█▇▇▇▆███▇▇█▇█▇█</td></tr><tr><td>val_loss</td><td>█▃▄▂▁▂▄▁▃▁▁▂▁▃▂▂▂▂▂▆▁▂▂▃▂▂▂▂▃▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03933</td></tr><tr><td>acc</td><td>0.96997</td></tr><tr><td>best_epoch</td><td>20</td></tr><tr><td>best_val_loss</td><td>0.79464</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.10282</td></tr><tr><td>val_acc</td><td>0.81632</td></tr><tr><td>val_loss</td><td>0.84538</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">glorious-sweep-10</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/brv0tlz0\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/brv0tlz0</a><br/>Synced 6 W&B file(s), 2 media file(s), 23 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_015940-brv0tlz0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: kl1gdwk0 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_021604-kl1gdwk0</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/kl1gdwk0\" target=\"_blank\">comfy-sweep-11</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               245888    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 463,242\n",
      "Trainable params: 462,474\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 2.1235 - acc: 0.3813 - val_loss: 2.4883 - val_acc: 0.4164\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_021604-kl1gdwk0/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_021604-kl1gdwk0/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 1.2121 - acc: 0.6057 - val_loss: 1.3637 - val_acc: 0.5916\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_021604-kl1gdwk0/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_021604-kl1gdwk0/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.9069 - acc: 0.6912 - val_loss: 1.0325 - val_acc: 0.6557\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_021604-kl1gdwk0/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_021604-kl1gdwk0/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.7581 - acc: 0.7358 - val_loss: 1.1611 - val_acc: 0.6742\n",
      "Epoch 5/30\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.6048 - acc: 0.7941 - val_loss: 1.0974 - val_acc: 0.6817\n",
      "Epoch 6/30\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.5178 - acc: 0.8239 - val_loss: 1.2227 - val_acc: 0.6396\n",
      "Epoch 7/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.4418 - acc: 0.8484 - val_loss: 1.0591 - val_acc: 0.7147\n",
      "Epoch 8/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.3788 - acc: 0.8712 - val_loss: 0.9319 - val_acc: 0.7497\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_021604-kl1gdwk0/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_021604-kl1gdwk0/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.3011 - acc: 0.8999 - val_loss: 0.7990 - val_acc: 0.7708\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_021604-kl1gdwk0/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_021604-kl1gdwk0/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.2509 - acc: 0.9176 - val_loss: 0.8742 - val_acc: 0.7558\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.2405 - acc: 0.9234 - val_loss: 0.8885 - val_acc: 0.7683\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.2063 - acc: 0.9303 - val_loss: 0.7783 - val_acc: 0.8048\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_021604-kl1gdwk0/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_021604-kl1gdwk0/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2043 - acc: 0.9312 - val_loss: 0.9181 - val_acc: 0.7698\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1792 - acc: 0.9377 - val_loss: 1.0184 - val_acc: 0.7603\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1745 - acc: 0.9414 - val_loss: 0.7919 - val_acc: 0.7968\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.1661 - acc: 0.9479 - val_loss: 0.8547 - val_acc: 0.7978\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1476 - acc: 0.9523 - val_loss: 0.9208 - val_acc: 0.7913\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1525 - acc: 0.9531 - val_loss: 0.8685 - val_acc: 0.7948\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.1375 - acc: 0.9564 - val_loss: 0.9142 - val_acc: 0.8088\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1041 - acc: 0.9623 - val_loss: 0.8615 - val_acc: 0.8058\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.0983 - acc: 0.9676 - val_loss: 0.9773 - val_acc: 0.8013\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.0955 - acc: 0.9684 - val_loss: 1.4680 - val_acc: 0.7352\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1098 - acc: 0.9656 - val_loss: 1.3150 - val_acc: 0.7848\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1101 - acc: 0.9672 - val_loss: 1.0282 - val_acc: 0.8113\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1222 - acc: 0.9599 - val_loss: 1.0713 - val_acc: 0.7908\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1110 - acc: 0.9640 - val_loss: 1.4043 - val_acc: 0.7618\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.0782 - acc: 0.9771 - val_loss: 1.3255 - val_acc: 0.7748\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.0920 - acc: 0.9702 - val_loss: 0.9749 - val_acc: 0.8218\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.0869 - acc: 0.9733 - val_loss: 1.1942 - val_acc: 0.7928\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.0965 - acc: 0.9683 - val_loss: 1.1297 - val_acc: 0.7993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='30.304 MB of 30.307 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.9999…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▆▆▆▇▇▇▇▇▇█████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▅▄▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▅▅▆▅▆▇▇▇▇█▇▇██▇████▇▇█▇▇▇█▇█</td></tr><tr><td>val_loss</td><td>█▃▂▃▂▃▂▂▁▁▁▁▂▂▁▁▂▁▂▁▂▄▃▂▂▄▃▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03946</td></tr><tr><td>acc</td><td>0.96793</td></tr><tr><td>best_epoch</td><td>11</td></tr><tr><td>best_val_loss</td><td>0.77828</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.10325</td></tr><tr><td>val_acc</td><td>0.7993</td></tr><tr><td>val_loss</td><td>1.12971</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">comfy-sweep-11</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/kl1gdwk0\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/kl1gdwk0</a><br/>Synced 6 W&B file(s), 2 media file(s), 20 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_021604-kl1gdwk0/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: gyii31s2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_023237-gyii31s2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/gyii31s2\" target=\"_blank\">radiant-sweep-12</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               245888    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 463,242\n",
      "Trainable params: 462,474\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 32s 155ms/step - loss: 2.1141 - acc: 0.3909 - val_loss: 3.6699 - val_acc: 0.4004\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_023237-gyii31s2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_023237-gyii31s2/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 1.2951 - acc: 0.5684 - val_loss: 1.3377 - val_acc: 0.5666\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_023237-gyii31s2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_023237-gyii31s2/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 33s 165ms/step - loss: 0.9849 - acc: 0.6667 - val_loss: 1.1248 - val_acc: 0.6481\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_023237-gyii31s2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_023237-gyii31s2/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.7760 - acc: 0.7379 - val_loss: 1.2049 - val_acc: 0.6547\n",
      "Epoch 5/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.6613 - acc: 0.7750 - val_loss: 1.0389 - val_acc: 0.6827\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_023237-gyii31s2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_023237-gyii31s2/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.5746 - acc: 0.8069 - val_loss: 0.9040 - val_acc: 0.7347\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_023237-gyii31s2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_023237-gyii31s2/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.4879 - acc: 0.8287 - val_loss: 1.0888 - val_acc: 0.6932\n",
      "Epoch 8/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.4169 - acc: 0.8594 - val_loss: 1.3671 - val_acc: 0.6612\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.3918 - acc: 0.8745 - val_loss: 0.8128 - val_acc: 0.7688\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_023237-gyii31s2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_023237-gyii31s2/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.3248 - acc: 0.8879 - val_loss: 0.8010 - val_acc: 0.7733\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_023237-gyii31s2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_023237-gyii31s2/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "200/200 [==============================] - 30s 152ms/step - loss: 0.3115 - acc: 0.8933 - val_loss: 1.2325 - val_acc: 0.6882\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.2937 - acc: 0.9020 - val_loss: 0.7930 - val_acc: 0.7933\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_023237-gyii31s2/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_023237-gyii31s2/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.2561 - acc: 0.9146 - val_loss: 1.0587 - val_acc: 0.7518\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.2406 - acc: 0.9182 - val_loss: 0.9865 - val_acc: 0.7472\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.2107 - acc: 0.9245 - val_loss: 0.8058 - val_acc: 0.7858\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2035 - acc: 0.9400 - val_loss: 0.8205 - val_acc: 0.7968\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.2090 - acc: 0.9362 - val_loss: 0.8303 - val_acc: 0.8158\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1774 - acc: 0.9427 - val_loss: 1.0780 - val_acc: 0.7703\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1673 - acc: 0.9466 - val_loss: 0.8492 - val_acc: 0.8023\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1573 - acc: 0.9543 - val_loss: 0.8801 - val_acc: 0.8148\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 0.1427 - acc: 0.9544 - val_loss: 0.8310 - val_acc: 0.8158\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 0.1445 - acc: 0.9510 - val_loss: 0.8295 - val_acc: 0.8263\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1127 - acc: 0.9605 - val_loss: 0.8390 - val_acc: 0.7998\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1266 - acc: 0.9595 - val_loss: 1.1495 - val_acc: 0.7758\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 0.1080 - acc: 0.9658 - val_loss: 0.9703 - val_acc: 0.7993\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1211 - acc: 0.9578 - val_loss: 1.3201 - val_acc: 0.7698\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.1031 - acc: 0.9682 - val_loss: 0.9942 - val_acc: 0.8068\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.1333 - acc: 0.9586 - val_loss: 1.0749 - val_acc: 0.7848\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0887 - acc: 0.9711 - val_loss: 0.9808 - val_acc: 0.8168\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.1039 - acc: 0.9664 - val_loss: 1.1120 - val_acc: 0.7998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='38.002 MB of 38.005 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.9999…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▅▆▆▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▅▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▅▅▆▆▆▅▇▇▆▇▇▇▇██▇█████▇█▇█▇██</td></tr><tr><td>val_loss</td><td>█▂▂▂▂▁▂▂▁▁▂▁▂▁▁▁▁▂▁▁▁▁▁▂▁▂▁▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03946</td></tr><tr><td>acc</td><td>0.96402</td></tr><tr><td>best_epoch</td><td>11</td></tr><tr><td>best_val_loss</td><td>0.79304</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.10799</td></tr><tr><td>val_acc</td><td>0.7998</td></tr><tr><td>val_loss</td><td>1.11196</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">radiant-sweep-12</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/gyii31s2\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/gyii31s2</a><br/>Synced 6 W&B file(s), 2 media file(s), 26 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_023237-gyii31s2/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ge81tiou with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_024906-ge81tiou</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/ge81tiou\" target=\"_blank\">expert-sweep-13</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               245888    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 463,242\n",
      "Trainable params: 462,474\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 32s 157ms/step - loss: 2.1610 - acc: 0.3712 - val_loss: 2.1693 - val_acc: 0.4695\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_024906-ge81tiou/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_024906-ge81tiou/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 1.2732 - acc: 0.5888 - val_loss: 1.5001 - val_acc: 0.5601\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_024906-ge81tiou/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_024906-ge81tiou/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 30s 152ms/step - loss: 0.9887 - acc: 0.6705 - val_loss: 1.1858 - val_acc: 0.6547\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_024906-ge81tiou/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_024906-ge81tiou/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.7665 - acc: 0.7379 - val_loss: 0.9844 - val_acc: 0.6972\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_024906-ge81tiou/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_024906-ge81tiou/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.6393 - acc: 0.7813 - val_loss: 0.9135 - val_acc: 0.7292\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_024906-ge81tiou/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_024906-ge81tiou/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.5374 - acc: 0.8096 - val_loss: 0.9586 - val_acc: 0.7207\n",
      "Epoch 7/30\n",
      "200/200 [==============================] - 31s 157ms/step - loss: 0.4744 - acc: 0.8345 - val_loss: 0.9294 - val_acc: 0.7307\n",
      "Epoch 8/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.4210 - acc: 0.8475 - val_loss: 0.8674 - val_acc: 0.7583\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_024906-ge81tiou/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_024906-ge81tiou/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.3578 - acc: 0.8806 - val_loss: 0.8631 - val_acc: 0.7548\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_024906-ge81tiou/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_024906-ge81tiou/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.3335 - acc: 0.8833 - val_loss: 0.8374 - val_acc: 0.7753\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_024906-ge81tiou/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_024906-ge81tiou/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.2808 - acc: 0.9059 - val_loss: 0.8250 - val_acc: 0.7818\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_024906-ge81tiou/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_024906-ge81tiou/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.2899 - acc: 0.9076 - val_loss: 0.8819 - val_acc: 0.7648\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.2131 - acc: 0.9250 - val_loss: 1.3007 - val_acc: 0.6847\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 31s 157ms/step - loss: 0.2032 - acc: 0.9363 - val_loss: 0.9030 - val_acc: 0.7883\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 0.1793 - acc: 0.9423 - val_loss: 1.3999 - val_acc: 0.6932\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.1602 - acc: 0.9478 - val_loss: 0.9144 - val_acc: 0.7898\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.1842 - acc: 0.9371 - val_loss: 0.9858 - val_acc: 0.7728\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.1776 - acc: 0.9412 - val_loss: 0.8853 - val_acc: 0.7903\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.1400 - acc: 0.9511 - val_loss: 1.0719 - val_acc: 0.7888\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.1619 - acc: 0.9477 - val_loss: 0.9757 - val_acc: 0.7973\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 0.1231 - acc: 0.9624 - val_loss: 0.8854 - val_acc: 0.8078\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1385 - acc: 0.9557 - val_loss: 1.0161 - val_acc: 0.7973\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1177 - acc: 0.9634 - val_loss: 1.1270 - val_acc: 0.7863\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1326 - acc: 0.9626 - val_loss: 1.0941 - val_acc: 0.7863\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1281 - acc: 0.9630 - val_loss: 1.1969 - val_acc: 0.7848\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.1432 - acc: 0.9558 - val_loss: 0.9898 - val_acc: 0.8058\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1041 - acc: 0.9685 - val_loss: 1.0701 - val_acc: 0.7918\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1320 - acc: 0.9569 - val_loss: 1.0173 - val_acc: 0.8128\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1036 - acc: 0.9686 - val_loss: 0.9202 - val_acc: 0.8043\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1088 - acc: 0.9629 - val_loss: 1.2361 - val_acc: 0.7823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='41.854 MB of 41.854 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇▇████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▅▆▆▆▆▇▇▇▇▇▅█▆█▇█████▇▇▇████▇</td></tr><tr><td>val_loss</td><td>█▅▃▂▁▂▂▁▁▁▁▁▃▁▄▁▂▁▂▂▁▂▃▂▃▂▂▂▁▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03946</td></tr><tr><td>acc</td><td>0.96262</td></tr><tr><td>best_epoch</td><td>10</td></tr><tr><td>best_val_loss</td><td>0.82503</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.11269</td></tr><tr><td>val_acc</td><td>0.78228</td></tr><tr><td>val_loss</td><td>1.23615</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">expert-sweep-13</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/ge81tiou\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/ge81tiou</a><br/>Synced 6 W&B file(s), 2 media file(s), 29 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_024906-ge81tiou/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: b4dvmyb1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_030551-b4dvmyb1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/b4dvmyb1\" target=\"_blank\">stoic-sweep-14</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                122944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 339,658\n",
      "Trainable params: 338,890\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 32s 156ms/step - loss: 1.8905 - acc: 0.4002 - val_loss: 3.1129 - val_acc: 0.3524\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_030551-b4dvmyb1/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_030551-b4dvmyb1/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 31s 157ms/step - loss: 1.1771 - acc: 0.5968 - val_loss: 1.8023 - val_acc: 0.5140\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_030551-b4dvmyb1/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_030551-b4dvmyb1/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.8776 - acc: 0.7029 - val_loss: 1.2274 - val_acc: 0.6026\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_030551-b4dvmyb1/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_030551-b4dvmyb1/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.7128 - acc: 0.7517 - val_loss: 0.7976 - val_acc: 0.7452\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_030551-b4dvmyb1/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_030551-b4dvmyb1/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.5703 - acc: 0.8001 - val_loss: 0.8914 - val_acc: 0.7242\n",
      "Epoch 6/30\n",
      "200/200 [==============================] - 31s 157ms/step - loss: 0.5034 - acc: 0.8277 - val_loss: 0.8985 - val_acc: 0.7367\n",
      "Epoch 7/30\n",
      "200/200 [==============================] - 31s 156ms/step - loss: 0.4448 - acc: 0.8565 - val_loss: 0.9615 - val_acc: 0.7127\n",
      "Epoch 8/30\n",
      "200/200 [==============================] - 31s 157ms/step - loss: 0.3652 - acc: 0.8694 - val_loss: 1.1164 - val_acc: 0.7172\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 31s 157ms/step - loss: 0.3339 - acc: 0.8880 - val_loss: 0.7819 - val_acc: 0.7803\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_030551-b4dvmyb1/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_030551-b4dvmyb1/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "200/200 [==============================] - 31s 157ms/step - loss: 0.2748 - acc: 0.9092 - val_loss: 0.8042 - val_acc: 0.7823\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.2479 - acc: 0.9198 - val_loss: 0.7433 - val_acc: 0.7873\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_030551-b4dvmyb1/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_030551-b4dvmyb1/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.2217 - acc: 0.9252 - val_loss: 0.8591 - val_acc: 0.7648\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 31s 157ms/step - loss: 0.2071 - acc: 0.9248 - val_loss: 0.8114 - val_acc: 0.7973\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 31s 157ms/step - loss: 0.1981 - acc: 0.9310 - val_loss: 0.9981 - val_acc: 0.7523\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 31s 155ms/step - loss: 0.1710 - acc: 0.9407 - val_loss: 0.7447 - val_acc: 0.8183\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 29s 148ms/step - loss: 0.1677 - acc: 0.9424 - val_loss: 0.8850 - val_acc: 0.7713\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 0.1558 - acc: 0.9483 - val_loss: 0.9806 - val_acc: 0.7553\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.1408 - acc: 0.9537 - val_loss: 0.7965 - val_acc: 0.7943\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 0.1176 - acc: 0.9615 - val_loss: 0.8797 - val_acc: 0.8048\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 0.1169 - acc: 0.9592 - val_loss: 0.8552 - val_acc: 0.7988\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 0.1235 - acc: 0.9598 - val_loss: 0.9811 - val_acc: 0.7923\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.1229 - acc: 0.9607 - val_loss: 0.9436 - val_acc: 0.7998\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1201 - acc: 0.9615 - val_loss: 0.8748 - val_acc: 0.8118\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 0.1185 - acc: 0.9577 - val_loss: 0.9160 - val_acc: 0.8033\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 0.1272 - acc: 0.9608 - val_loss: 0.7982 - val_acc: 0.8058\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 0.1117 - acc: 0.9634 - val_loss: 0.8227 - val_acc: 0.8198\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0954 - acc: 0.9708 - val_loss: 0.8674 - val_acc: 0.8218\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.0921 - acc: 0.9709 - val_loss: 0.8594 - val_acc: 0.8273\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0974 - acc: 0.9724 - val_loss: 0.8818 - val_acc: 0.8198\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.0917 - acc: 0.9678 - val_loss: 1.0941 - val_acc: 0.8028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='22.762 MB of 22.764 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.9998…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▆▆▆▇▇▇▇▇▇▇████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▅▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▅▇▆▇▆▆▇▇▇▇█▇█▇▇███▇█████████</td></tr><tr><td>val_loss</td><td>█▄▂▁▁▁▂▂▁▁▁▁▁▂▁▁▂▁▁▁▂▂▁▂▁▁▁▁▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03933</td></tr><tr><td>acc</td><td>0.96887</td></tr><tr><td>best_epoch</td><td>10</td></tr><tr><td>best_val_loss</td><td>0.74326</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.09277</td></tr><tr><td>val_acc</td><td>0.8028</td></tr><tr><td>val_loss</td><td>1.09408</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">stoic-sweep-14</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/b4dvmyb1\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/b4dvmyb1</a><br/>Synced 6 W&B file(s), 2 media file(s), 20 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_030551-b4dvmyb1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: bjmvbhxq with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_032159-bjmvbhxq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/bjmvbhxq\" target=\"_blank\">polar-sweep-15</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                122944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 339,658\n",
      "Trainable params: 338,890\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 32s 155ms/step - loss: 2.0064 - acc: 0.3810 - val_loss: 2.0152 - val_acc: 0.4349\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_032159-bjmvbhxq/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_032159-bjmvbhxq/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 1.2741 - acc: 0.5592 - val_loss: 1.3901 - val_acc: 0.5581\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_032159-bjmvbhxq/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_032159-bjmvbhxq/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.9742 - acc: 0.6736 - val_loss: 1.0241 - val_acc: 0.6572\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_032159-bjmvbhxq/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_032159-bjmvbhxq/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 0.7684 - acc: 0.7391 - val_loss: 1.1321 - val_acc: 0.6927\n",
      "Epoch 5/30\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 0.6781 - acc: 0.7622 - val_loss: 0.7986 - val_acc: 0.7182\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_032159-bjmvbhxq/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_032159-bjmvbhxq/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.6116 - acc: 0.7842 - val_loss: 0.9238 - val_acc: 0.7047\n",
      "Epoch 7/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.5227 - acc: 0.8210 - val_loss: 0.9923 - val_acc: 0.7062\n",
      "Epoch 8/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.4470 - acc: 0.8427 - val_loss: 1.1132 - val_acc: 0.6872\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.3952 - acc: 0.8565 - val_loss: 0.8174 - val_acc: 0.7723\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.3353 - acc: 0.8807 - val_loss: 0.8942 - val_acc: 0.7452\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.3167 - acc: 0.8955 - val_loss: 0.7050 - val_acc: 0.7978\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_032159-bjmvbhxq/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_032159-bjmvbhxq/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.2792 - acc: 0.9036 - val_loss: 0.7871 - val_acc: 0.7668\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2984 - acc: 0.8982 - val_loss: 0.7464 - val_acc: 0.8058\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2460 - acc: 0.9187 - val_loss: 0.7496 - val_acc: 0.8068\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.2525 - acc: 0.9173 - val_loss: 0.8223 - val_acc: 0.7868\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 30s 152ms/step - loss: 0.1987 - acc: 0.9320 - val_loss: 1.0213 - val_acc: 0.7648\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.2087 - acc: 0.9334 - val_loss: 0.8307 - val_acc: 0.7948\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.1819 - acc: 0.9350 - val_loss: 0.7256 - val_acc: 0.8083\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 30s 152ms/step - loss: 0.1849 - acc: 0.9407 - val_loss: 0.7758 - val_acc: 0.8168\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1537 - acc: 0.9466 - val_loss: 0.8360 - val_acc: 0.8088\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1582 - acc: 0.9452 - val_loss: 0.7080 - val_acc: 0.8313\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1444 - acc: 0.9570 - val_loss: 1.1867 - val_acc: 0.7588\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 31s 155ms/step - loss: 0.1438 - acc: 0.9516 - val_loss: 0.9011 - val_acc: 0.7928\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1442 - acc: 0.9503 - val_loss: 1.5103 - val_acc: 0.7397\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1453 - acc: 0.9547 - val_loss: 1.0418 - val_acc: 0.8048\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1244 - acc: 0.9570 - val_loss: 0.8737 - val_acc: 0.7963\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.1181 - acc: 0.9652 - val_loss: 0.9204 - val_acc: 0.8063\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1155 - acc: 0.9612 - val_loss: 0.7287 - val_acc: 0.8348\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 30s 152ms/step - loss: 0.1243 - acc: 0.9582 - val_loss: 0.9087 - val_acc: 0.8173\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.1088 - acc: 0.9650 - val_loss: 0.8054 - val_acc: 0.8178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='19.858 MB of 19.858 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▅▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▅▆▆▆▆▅▇▆▇▇▇█▇▇▇████▇▇▆▇▇████</td></tr><tr><td>val_loss</td><td>█▅▃▃▁▂▃▃▂▂▁▁▁▁▂▃▂▁▁▂▁▄▂▅▃▂▂▁▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03933</td></tr><tr><td>acc</td><td>0.95902</td></tr><tr><td>best_epoch</td><td>10</td></tr><tr><td>best_val_loss</td><td>0.70503</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.12973</td></tr><tr><td>val_acc</td><td>0.81782</td></tr><tr><td>val_loss</td><td>0.80542</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">polar-sweep-15</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/bjmvbhxq\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/bjmvbhxq</a><br/>Synced 6 W&B file(s), 2 media file(s), 17 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_032159-bjmvbhxq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wy3nkzwo with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_033820-wy3nkzwo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/wy3nkzwo\" target=\"_blank\">solar-sweep-16</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               245888    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 463,242\n",
      "Trainable params: 462,474\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 33s 160ms/step - loss: 2.1149 - acc: 0.3830 - val_loss: 2.1781 - val_acc: 0.4124\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_033820-wy3nkzwo/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_033820-wy3nkzwo/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 1.3047 - acc: 0.5756 - val_loss: 1.1957 - val_acc: 0.6146\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_033820-wy3nkzwo/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_033820-wy3nkzwo/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.9923 - acc: 0.6562 - val_loss: 1.0184 - val_acc: 0.6827\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_033820-wy3nkzwo/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_033820-wy3nkzwo/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.7981 - acc: 0.7291 - val_loss: 1.0683 - val_acc: 0.6812\n",
      "Epoch 5/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.6600 - acc: 0.7709 - val_loss: 1.3144 - val_acc: 0.6812\n",
      "Epoch 6/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.5561 - acc: 0.8183 - val_loss: 0.8668 - val_acc: 0.7327\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_033820-wy3nkzwo/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_033820-wy3nkzwo/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 0.5022 - acc: 0.8194 - val_loss: 1.1631 - val_acc: 0.6762\n",
      "Epoch 8/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.4109 - acc: 0.8548 - val_loss: 0.7946 - val_acc: 0.7668\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_033820-wy3nkzwo/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_033820-wy3nkzwo/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.3899 - acc: 0.8750 - val_loss: 1.2565 - val_acc: 0.6727\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.3099 - acc: 0.8942 - val_loss: 2.3136 - val_acc: 0.5676\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.3063 - acc: 0.8921 - val_loss: 0.8185 - val_acc: 0.7588\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.2789 - acc: 0.9087 - val_loss: 0.6881 - val_acc: 0.8068\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_033820-wy3nkzwo/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_033820-wy3nkzwo/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2306 - acc: 0.9197 - val_loss: 0.8977 - val_acc: 0.7853\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.2278 - acc: 0.9268 - val_loss: 1.0752 - val_acc: 0.7783\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1916 - acc: 0.9354 - val_loss: 0.7974 - val_acc: 0.7928\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.1841 - acc: 0.9381 - val_loss: 0.8304 - val_acc: 0.7888\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 31s 155ms/step - loss: 0.1666 - acc: 0.9475 - val_loss: 0.9521 - val_acc: 0.7698\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.1667 - acc: 0.9396 - val_loss: 0.9360 - val_acc: 0.7858\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.1599 - acc: 0.9466 - val_loss: 0.7692 - val_acc: 0.8178\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 30s 152ms/step - loss: 0.1484 - acc: 0.9533 - val_loss: 0.9118 - val_acc: 0.8063\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.1511 - acc: 0.9499 - val_loss: 1.0966 - val_acc: 0.7573\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 30s 152ms/step - loss: 0.1278 - acc: 0.9631 - val_loss: 0.9805 - val_acc: 0.8108\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.1384 - acc: 0.9579 - val_loss: 1.0352 - val_acc: 0.8023\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.1213 - acc: 0.9618 - val_loss: 1.0586 - val_acc: 0.7783\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 30s 152ms/step - loss: 0.1450 - acc: 0.9552 - val_loss: 1.0392 - val_acc: 0.7678\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 30s 152ms/step - loss: 0.1134 - acc: 0.9618 - val_loss: 1.0758 - val_acc: 0.8093\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.1037 - acc: 0.9644 - val_loss: 0.9620 - val_acc: 0.8063\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 31s 154ms/step - loss: 0.1170 - acc: 0.9604 - val_loss: 0.9148 - val_acc: 0.8138\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 30s 152ms/step - loss: 0.1110 - acc: 0.9664 - val_loss: 0.9004 - val_acc: 0.8153\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.1162 - acc: 0.9640 - val_loss: 0.9848 - val_acc: 0.8058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='30.304 MB of 30.307 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.9999…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇▇▇███████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▅▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▆▆▆▇▆▇▅▄▇█▇▇█▇▇▇██▇██▇▇█████</td></tr><tr><td>val_loss</td><td>▇▃▂▃▄▂▃▁▃█▂▁▂▃▁▂▂▂▁▂▃▂▂▃▃▃▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03946</td></tr><tr><td>acc</td><td>0.96496</td></tr><tr><td>best_epoch</td><td>11</td></tr><tr><td>best_val_loss</td><td>0.68809</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.11004</td></tr><tr><td>val_acc</td><td>0.80581</td></tr><tr><td>val_loss</td><td>0.98477</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">solar-sweep-16</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/wy3nkzwo\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/wy3nkzwo</a><br/>Synced 6 W&B file(s), 2 media file(s), 20 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_033820-wy3nkzwo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: aqi3fv8v with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_035450-aqi3fv8v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/aqi3fv8v\" target=\"_blank\">classic-sweep-17</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               245888    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 463,242\n",
      "Trainable params: 462,474\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 32s 157ms/step - loss: 2.0973 - acc: 0.3939 - val_loss: 2.7960 - val_acc: 0.4149\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_035450-aqi3fv8v/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_035450-aqi3fv8v/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 1.2679 - acc: 0.5967 - val_loss: 1.7664 - val_acc: 0.5671\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_035450-aqi3fv8v/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_035450-aqi3fv8v/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 1.0180 - acc: 0.6620 - val_loss: 0.9535 - val_acc: 0.6887\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_035450-aqi3fv8v/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_035450-aqi3fv8v/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.7622 - acc: 0.7505 - val_loss: 0.9425 - val_acc: 0.7017\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_035450-aqi3fv8v/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_035450-aqi3fv8v/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.6182 - acc: 0.7948 - val_loss: 0.8086 - val_acc: 0.7337\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_035450-aqi3fv8v/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_035450-aqi3fv8v/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.5221 - acc: 0.8153 - val_loss: 0.8012 - val_acc: 0.7733\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_035450-aqi3fv8v/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_035450-aqi3fv8v/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.4491 - acc: 0.8429 - val_loss: 0.9142 - val_acc: 0.7603\n",
      "Epoch 8/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.3761 - acc: 0.8703 - val_loss: 0.8573 - val_acc: 0.7558\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 31s 157ms/step - loss: 0.3543 - acc: 0.8823 - val_loss: 0.9332 - val_acc: 0.7703\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.3410 - acc: 0.8844 - val_loss: 0.8508 - val_acc: 0.7578\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.2594 - acc: 0.9151 - val_loss: 0.8764 - val_acc: 0.7633\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.2590 - acc: 0.9124 - val_loss: 0.8724 - val_acc: 0.7733\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2587 - acc: 0.9143 - val_loss: 1.1689 - val_acc: 0.7477\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2265 - acc: 0.9271 - val_loss: 0.8336 - val_acc: 0.7798\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.1923 - acc: 0.9362 - val_loss: 1.0013 - val_acc: 0.7743\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1891 - acc: 0.9387 - val_loss: 0.7344 - val_acc: 0.8193\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_035450-aqi3fv8v/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_035450-aqi3fv8v/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1866 - acc: 0.9392 - val_loss: 0.8022 - val_acc: 0.8023\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1631 - acc: 0.9446 - val_loss: 0.9362 - val_acc: 0.7863\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.1557 - acc: 0.9471 - val_loss: 0.8375 - val_acc: 0.8003\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 31s 156ms/step - loss: 0.1416 - acc: 0.9545 - val_loss: 1.0959 - val_acc: 0.7487\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1507 - acc: 0.9542 - val_loss: 0.7790 - val_acc: 0.8223\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.1271 - acc: 0.9542 - val_loss: 0.9333 - val_acc: 0.8113\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 29s 148ms/step - loss: 0.1273 - acc: 0.9584 - val_loss: 0.9348 - val_acc: 0.7813\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1269 - acc: 0.9597 - val_loss: 0.9979 - val_acc: 0.8108\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 29s 147ms/step - loss: 0.1161 - acc: 0.9630 - val_loss: 0.8752 - val_acc: 0.8158\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1030 - acc: 0.9670 - val_loss: 0.9069 - val_acc: 0.8018\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.1190 - acc: 0.9604 - val_loss: 0.8177 - val_acc: 0.8228\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.0898 - acc: 0.9690 - val_loss: 0.8034 - val_acc: 0.8223\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.1194 - acc: 0.9639 - val_loss: 1.0415 - val_acc: 0.7938\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.1167 - acc: 0.9657 - val_loss: 1.1754 - val_acc: 0.7933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='34.156 MB of 34.156 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▅▆▆▇▇▇▇▇▇▇████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▅▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▆▆▆▇▇▇▇▇▇▇▇▇▇██▇█▇██▇██████▇</td></tr><tr><td>val_loss</td><td>█▅▂▂▁▁▂▁▂▁▁▁▂▁▂▁▁▂▁▂▁▂▂▂▁▂▁▁▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03946</td></tr><tr><td>acc</td><td>0.96308</td></tr><tr><td>best_epoch</td><td>15</td></tr><tr><td>best_val_loss</td><td>0.73443</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.11726</td></tr><tr><td>val_acc</td><td>0.79329</td></tr><tr><td>val_loss</td><td>1.17538</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">classic-sweep-17</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/aqi3fv8v\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/aqi3fv8v</a><br/>Synced 6 W&B file(s), 2 media file(s), 23 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_035450-aqi3fv8v/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: l8xix3s9 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_041118-l8xix3s9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/l8xix3s9\" target=\"_blank\">snowy-sweep-18</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                122944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 339,658\n",
      "Trainable params: 338,890\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 32s 156ms/step - loss: 2.0411 - acc: 0.3809 - val_loss: 1.9037 - val_acc: 0.4955\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_041118-l8xix3s9/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_041118-l8xix3s9/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 1.2482 - acc: 0.5949 - val_loss: 1.8219 - val_acc: 0.5365\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_041118-l8xix3s9/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_041118-l8xix3s9/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.9486 - acc: 0.6798 - val_loss: 1.0707 - val_acc: 0.6441\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_041118-l8xix3s9/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_041118-l8xix3s9/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.7917 - acc: 0.7289 - val_loss: 1.1539 - val_acc: 0.6446\n",
      "Epoch 5/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.6630 - acc: 0.7733 - val_loss: 0.8106 - val_acc: 0.7397\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_041118-l8xix3s9/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_041118-l8xix3s9/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 0.5843 - acc: 0.8054 - val_loss: 0.8069 - val_acc: 0.7457\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_041118-l8xix3s9/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_041118-l8xix3s9/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.4922 - acc: 0.8267 - val_loss: 0.8282 - val_acc: 0.7497\n",
      "Epoch 8/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.4521 - acc: 0.8441 - val_loss: 1.0353 - val_acc: 0.7007\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.3954 - acc: 0.8637 - val_loss: 0.7659 - val_acc: 0.7693\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_041118-l8xix3s9/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_041118-l8xix3s9/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.3705 - acc: 0.8716 - val_loss: 0.9330 - val_acc: 0.7583\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.3450 - acc: 0.8853 - val_loss: 0.8156 - val_acc: 0.7663\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.2997 - acc: 0.9029 - val_loss: 1.1001 - val_acc: 0.7533\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.2698 - acc: 0.9029 - val_loss: 0.9046 - val_acc: 0.7798\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.2464 - acc: 0.9117 - val_loss: 0.8745 - val_acc: 0.7738\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.2318 - acc: 0.9173 - val_loss: 0.6708 - val_acc: 0.8088\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_041118-l8xix3s9/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_041118-l8xix3s9/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.2331 - acc: 0.9147 - val_loss: 0.7397 - val_acc: 0.8053\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.1981 - acc: 0.9320 - val_loss: 1.3097 - val_acc: 0.7417\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.2024 - acc: 0.9340 - val_loss: 0.9171 - val_acc: 0.7823\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1968 - acc: 0.9347 - val_loss: 0.8416 - val_acc: 0.8078\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.1713 - acc: 0.9466 - val_loss: 0.8536 - val_acc: 0.8068\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1704 - acc: 0.9475 - val_loss: 1.3239 - val_acc: 0.7427\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1751 - acc: 0.9461 - val_loss: 0.9450 - val_acc: 0.7918\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1654 - acc: 0.9477 - val_loss: 0.8087 - val_acc: 0.8158\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1508 - acc: 0.9503 - val_loss: 0.8385 - val_acc: 0.8158\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1284 - acc: 0.9583 - val_loss: 0.8348 - val_acc: 0.8123\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1415 - acc: 0.9574 - val_loss: 1.0000 - val_acc: 0.8233\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1318 - acc: 0.9567 - val_loss: 0.8154 - val_acc: 0.8158\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.1220 - acc: 0.9609 - val_loss: 0.8882 - val_acc: 0.8158\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.1500 - acc: 0.9536 - val_loss: 1.0439 - val_acc: 0.7918\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1119 - acc: 0.9660 - val_loss: 1.0764 - val_acc: 0.7808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='25.668 MB of 25.670 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.9999…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▅▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▂▄▄▆▆▆▅▇▇▇▇▇▇██▆▇██▆▇██████▇▇</td></tr><tr><td>val_loss</td><td>██▃▄▂▂▂▃▂▂▂▃▂▂▁▁▅▂▂▂▅▃▂▂▂▃▂▂▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03933</td></tr><tr><td>acc</td><td>0.96215</td></tr><tr><td>best_epoch</td><td>14</td></tr><tr><td>best_val_loss</td><td>0.67075</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.12668</td></tr><tr><td>val_acc</td><td>0.78078</td></tr><tr><td>val_loss</td><td>1.07636</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">snowy-sweep-18</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/l8xix3s9\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/l8xix3s9</a><br/>Synced 6 W&B file(s), 2 media file(s), 23 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_041118-l8xix3s9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: fc70w98r with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_042802-fc70w98r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/fc70w98r\" target=\"_blank\">worldly-sweep-19</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                122944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 339,658\n",
      "Trainable params: 338,890\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 32s 156ms/step - loss: 2.1198 - acc: 0.3716 - val_loss: 1.9454 - val_acc: 0.4434\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_042802-fc70w98r/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_042802-fc70w98r/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 31s 157ms/step - loss: 1.2975 - acc: 0.5684 - val_loss: 1.3971 - val_acc: 0.5736\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_042802-fc70w98r/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_042802-fc70w98r/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 31s 157ms/step - loss: 0.9554 - acc: 0.6746 - val_loss: 1.1492 - val_acc: 0.6416\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_042802-fc70w98r/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_042802-fc70w98r/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.8174 - acc: 0.7255 - val_loss: 1.2293 - val_acc: 0.6486\n",
      "Epoch 5/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.6667 - acc: 0.7721 - val_loss: 1.3176 - val_acc: 0.6071\n",
      "Epoch 6/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.5910 - acc: 0.7940 - val_loss: 0.8879 - val_acc: 0.7287\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_042802-fc70w98r/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_042802-fc70w98r/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.5129 - acc: 0.8245 - val_loss: 0.7691 - val_acc: 0.7603\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_042802-fc70w98r/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_042802-fc70w98r/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.4664 - acc: 0.8327 - val_loss: 0.9592 - val_acc: 0.7112\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.4103 - acc: 0.8606 - val_loss: 0.8515 - val_acc: 0.7452\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - 31s 158ms/step - loss: 0.3576 - acc: 0.8725 - val_loss: 0.8325 - val_acc: 0.7708\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.3216 - acc: 0.8838 - val_loss: 0.7697 - val_acc: 0.7728\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.2907 - acc: 0.9054 - val_loss: 0.9775 - val_acc: 0.7322\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2671 - acc: 0.9084 - val_loss: 0.8967 - val_acc: 0.7728\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2358 - acc: 0.9208 - val_loss: 0.7552 - val_acc: 0.7918\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_042802-fc70w98r/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_042802-fc70w98r/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.2305 - acc: 0.9199 - val_loss: 0.9897 - val_acc: 0.7793\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.2216 - acc: 0.9225 - val_loss: 1.0260 - val_acc: 0.7518\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1842 - acc: 0.9381 - val_loss: 0.8356 - val_acc: 0.8033\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1978 - acc: 0.9339 - val_loss: 0.9070 - val_acc: 0.7688\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2003 - acc: 0.9349 - val_loss: 0.8941 - val_acc: 0.7978\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1727 - acc: 0.9409 - val_loss: 0.9685 - val_acc: 0.7653\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1552 - acc: 0.9447 - val_loss: 0.8078 - val_acc: 0.7923\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1620 - acc: 0.9507 - val_loss: 1.0789 - val_acc: 0.7888\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1703 - acc: 0.9449 - val_loss: 0.9068 - val_acc: 0.8088\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1540 - acc: 0.9496 - val_loss: 0.8189 - val_acc: 0.8173\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.1502 - acc: 0.9477 - val_loss: 1.0176 - val_acc: 0.7778\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.1508 - acc: 0.9519 - val_loss: 0.8961 - val_acc: 0.8118\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1281 - acc: 0.9591 - val_loss: 0.8188 - val_acc: 0.8238\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1448 - acc: 0.9514 - val_loss: 1.0177 - val_acc: 0.7903\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.1282 - acc: 0.9583 - val_loss: 0.8627 - val_acc: 0.8168\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1232 - acc: 0.9625 - val_loss: 1.1811 - val_acc: 0.7738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='22.762 MB of 22.764 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.9998…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▄▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▅▅▄▆▇▆▇▇▇▆▇▇▇▇█▇█▇▇▇██▇██▇█▇</td></tr><tr><td>val_loss</td><td>█▅▃▄▄▂▁▂▂▁▁▂▂▁▂▃▁▂▂▂▁▃▂▁▃▂▁▃▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03933</td></tr><tr><td>acc</td><td>0.96058</td></tr><tr><td>best_epoch</td><td>13</td></tr><tr><td>best_val_loss</td><td>0.75522</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.14073</td></tr><tr><td>val_acc</td><td>0.77377</td></tr><tr><td>val_loss</td><td>1.18107</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">worldly-sweep-19</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/fc70w98r\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/fc70w98r</a><br/>Synced 6 W&B file(s), 2 media file(s), 20 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_042802-fc70w98r/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: wvkisd6z with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_044432-wvkisd6z</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/wvkisd6z\" target=\"_blank\">bright-sweep-20</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                122944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 339,658\n",
      "Trainable params: 338,890\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 33s 162ms/step - loss: 1.9775 - acc: 0.3757 - val_loss: 1.9233 - val_acc: 0.4580\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_044432-wvkisd6z/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_044432-wvkisd6z/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 1.2350 - acc: 0.5886 - val_loss: 1.5109 - val_acc: 0.5591\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_044432-wvkisd6z/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_044432-wvkisd6z/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.9166 - acc: 0.6793 - val_loss: 1.1548 - val_acc: 0.6647\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_044432-wvkisd6z/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_044432-wvkisd6z/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.8063 - acc: 0.7244 - val_loss: 1.3144 - val_acc: 0.6121\n",
      "Epoch 5/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.6084 - acc: 0.7873 - val_loss: 0.8851 - val_acc: 0.7232\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_044432-wvkisd6z/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_044432-wvkisd6z/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.4947 - acc: 0.8298 - val_loss: 1.1610 - val_acc: 0.6847\n",
      "Epoch 7/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.4476 - acc: 0.8514 - val_loss: 0.8210 - val_acc: 0.7708\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_044432-wvkisd6z/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_044432-wvkisd6z/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.3857 - acc: 0.8704 - val_loss: 0.8777 - val_acc: 0.7558\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.3558 - acc: 0.8749 - val_loss: 0.7573 - val_acc: 0.7798\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_044432-wvkisd6z/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_044432-wvkisd6z/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.3189 - acc: 0.8949 - val_loss: 1.5509 - val_acc: 0.6577\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.2731 - acc: 0.9036 - val_loss: 1.1203 - val_acc: 0.7092\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2520 - acc: 0.9110 - val_loss: 0.8191 - val_acc: 0.7808\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.2247 - acc: 0.9198 - val_loss: 0.7297 - val_acc: 0.8153\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_044432-wvkisd6z/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_044432-wvkisd6z/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "200/200 [==============================] - 31s 154ms/step - loss: 0.2026 - acc: 0.9296 - val_loss: 0.9019 - val_acc: 0.7783\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.2145 - acc: 0.9285 - val_loss: 0.9576 - val_acc: 0.7618\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1917 - acc: 0.9392 - val_loss: 0.9629 - val_acc: 0.7778\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1683 - acc: 0.9436 - val_loss: 0.9824 - val_acc: 0.7708\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1755 - acc: 0.9396 - val_loss: 0.7745 - val_acc: 0.8228\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.1351 - acc: 0.9534 - val_loss: 0.7997 - val_acc: 0.8018\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1358 - acc: 0.9600 - val_loss: 1.0868 - val_acc: 0.7708\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1511 - acc: 0.9470 - val_loss: 0.8127 - val_acc: 0.8083\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1327 - acc: 0.9519 - val_loss: 0.7900 - val_acc: 0.8073\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1054 - acc: 0.9671 - val_loss: 0.9735 - val_acc: 0.8008\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1053 - acc: 0.9641 - val_loss: 1.1351 - val_acc: 0.7868\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.1248 - acc: 0.9560 - val_loss: 1.2850 - val_acc: 0.7593\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1082 - acc: 0.9657 - val_loss: 1.0271 - val_acc: 0.8248\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1096 - acc: 0.9636 - val_loss: 0.9029 - val_acc: 0.8173\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1036 - acc: 0.9657 - val_loss: 1.0705 - val_acc: 0.8148\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.1115 - acc: 0.9626 - val_loss: 0.8818 - val_acc: 0.8243\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.0858 - acc: 0.9760 - val_loss: 1.1814 - val_acc: 0.7993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='25.668 MB of 25.670 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.9999…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▆▆▆▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▅▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▅▄▆▅▇▇▇▅▆▇█▇▇▇▇██▇███▇▇█████</td></tr><tr><td>val_loss</td><td>█▆▃▄▂▄▂▂▁▆▃▂▁▂▂▂▂▁▁▃▁▁▂▃▄▃▂▃▂▄</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03933</td></tr><tr><td>acc</td><td>0.97106</td></tr><tr><td>best_epoch</td><td>12</td></tr><tr><td>best_val_loss</td><td>0.72968</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.09835</td></tr><tr><td>val_acc</td><td>0.7993</td></tr><tr><td>val_loss</td><td>1.18136</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">bright-sweep-20</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/wvkisd6z\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/wvkisd6z</a><br/>Synced 6 W&B file(s), 2 media file(s), 23 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_044432-wvkisd6z/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: le8hb70u with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_050043-le8hb70u</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/le8hb70u\" target=\"_blank\">zany-sweep-21</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                122944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 339,658\n",
      "Trainable params: 338,890\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 2.1327 - acc: 0.3490 - val_loss: 2.0710 - val_acc: 0.4369\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_050043-le8hb70u/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_050043-le8hb70u/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 1.3089 - acc: 0.5661 - val_loss: 1.5107 - val_acc: 0.5556\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_050043-le8hb70u/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_050043-le8hb70u/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 0.9737 - acc: 0.6680 - val_loss: 0.9616 - val_acc: 0.6932\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_050043-le8hb70u/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_050043-le8hb70u/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.8101 - acc: 0.7212 - val_loss: 1.0315 - val_acc: 0.6867\n",
      "Epoch 5/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.6875 - acc: 0.7661 - val_loss: 1.0680 - val_acc: 0.6722\n",
      "Epoch 6/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.5974 - acc: 0.7957 - val_loss: 1.1016 - val_acc: 0.6727\n",
      "Epoch 7/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.4833 - acc: 0.8287 - val_loss: 1.0693 - val_acc: 0.6937\n",
      "Epoch 8/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.4415 - acc: 0.8540 - val_loss: 0.8448 - val_acc: 0.7563\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_050043-le8hb70u/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_050043-le8hb70u/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.3734 - acc: 0.8712 - val_loss: 0.9498 - val_acc: 0.7092\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.4027 - acc: 0.8648 - val_loss: 0.9889 - val_acc: 0.7508\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.3307 - acc: 0.8856 - val_loss: 0.7648 - val_acc: 0.7738\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_050043-le8hb70u/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_050043-le8hb70u/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.2872 - acc: 0.8953 - val_loss: 0.7411 - val_acc: 0.8048\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_050043-le8hb70u/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_050043-le8hb70u/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30\n",
      "200/200 [==============================] - 33s 165ms/step - loss: 0.2680 - acc: 0.9040 - val_loss: 0.7481 - val_acc: 0.8038\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 33s 167ms/step - loss: 0.2695 - acc: 0.9031 - val_loss: 0.7693 - val_acc: 0.8118\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.2541 - acc: 0.9135 - val_loss: 0.8499 - val_acc: 0.7883\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2454 - acc: 0.9268 - val_loss: 0.9510 - val_acc: 0.7863\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1956 - acc: 0.9321 - val_loss: 0.7297 - val_acc: 0.7988\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_050043-le8hb70u/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_050043-le8hb70u/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2013 - acc: 0.9383 - val_loss: 0.9496 - val_acc: 0.7718\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1925 - acc: 0.9368 - val_loss: 0.9582 - val_acc: 0.7678\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1543 - acc: 0.9472 - val_loss: 0.8603 - val_acc: 0.8083\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 0.1528 - acc: 0.9509 - val_loss: 0.7822 - val_acc: 0.8063\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1520 - acc: 0.9515 - val_loss: 0.8020 - val_acc: 0.8183\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1585 - acc: 0.9500 - val_loss: 0.8437 - val_acc: 0.7998\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1535 - acc: 0.9484 - val_loss: 0.8472 - val_acc: 0.8053\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1200 - acc: 0.9584 - val_loss: 0.9727 - val_acc: 0.8033\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1351 - acc: 0.9564 - val_loss: 0.9715 - val_acc: 0.8013\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1330 - acc: 0.9537 - val_loss: 0.8423 - val_acc: 0.8063\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1214 - acc: 0.9606 - val_loss: 0.9100 - val_acc: 0.7998\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1186 - acc: 0.9593 - val_loss: 1.0376 - val_acc: 0.8193\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1394 - acc: 0.9586 - val_loss: 0.8710 - val_acc: 0.8248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='25.670 MB of 25.670 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇▇▇███████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▅▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▆▆▅▅▆▇▆▇▇███▇▇█▇▇███████████</td></tr><tr><td>val_loss</td><td>█▅▂▃▃▃▃▂▂▂▁▁▁▁▂▂▁▂▂▂▁▁▂▂▂▂▂▂▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03933</td></tr><tr><td>acc</td><td>0.9598</td></tr><tr><td>best_epoch</td><td>16</td></tr><tr><td>best_val_loss</td><td>0.72969</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.1338</td></tr><tr><td>val_acc</td><td>0.82482</td></tr><tr><td>val_loss</td><td>0.87105</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">zany-sweep-21</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/le8hb70u\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/le8hb70u</a><br/>Synced 6 W&B file(s), 2 media file(s), 23 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_050043-le8hb70u/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: nnu2wros with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_051733-nnu2wros</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/nnu2wros\" target=\"_blank\">fluent-sweep-22</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               245888    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 463,242\n",
      "Trainable params: 462,474\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 32s 157ms/step - loss: 2.0625 - acc: 0.3805 - val_loss: 2.4133 - val_acc: 0.4645\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_051733-nnu2wros/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_051733-nnu2wros/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 1.2442 - acc: 0.5878 - val_loss: 1.3240 - val_acc: 0.5896\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_051733-nnu2wros/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_051733-nnu2wros/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 31s 157ms/step - loss: 0.8761 - acc: 0.7038 - val_loss: 1.8439 - val_acc: 0.5445\n",
      "Epoch 4/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.7303 - acc: 0.7471 - val_loss: 1.0845 - val_acc: 0.6802\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_051733-nnu2wros/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_051733-nnu2wros/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.5938 - acc: 0.7972 - val_loss: 1.2251 - val_acc: 0.6522\n",
      "Epoch 6/30\n",
      "200/200 [==============================] - 31s 157ms/step - loss: 0.5102 - acc: 0.8249 - val_loss: 1.0761 - val_acc: 0.6822\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_051733-nnu2wros/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_051733-nnu2wros/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.4392 - acc: 0.8522 - val_loss: 0.8602 - val_acc: 0.7583\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_051733-nnu2wros/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_051733-nnu2wros/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.3424 - acc: 0.8795 - val_loss: 0.7582 - val_acc: 0.7673\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_051733-nnu2wros/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_051733-nnu2wros/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.3357 - acc: 0.8943 - val_loss: 0.8985 - val_acc: 0.7753\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.2715 - acc: 0.9093 - val_loss: 0.8629 - val_acc: 0.7523\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2389 - acc: 0.9301 - val_loss: 0.8699 - val_acc: 0.7803\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.2192 - acc: 0.9284 - val_loss: 0.8213 - val_acc: 0.7928\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.1760 - acc: 0.9452 - val_loss: 0.8512 - val_acc: 0.7768\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1893 - acc: 0.9403 - val_loss: 0.9876 - val_acc: 0.7718\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 0.1817 - acc: 0.9406 - val_loss: 0.8240 - val_acc: 0.8018\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1553 - acc: 0.9481 - val_loss: 1.1218 - val_acc: 0.7503\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.1642 - acc: 0.9471 - val_loss: 0.9515 - val_acc: 0.7908\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1329 - acc: 0.9531 - val_loss: 1.0440 - val_acc: 0.7658\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.1088 - acc: 0.9685 - val_loss: 1.3659 - val_acc: 0.7412\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.1236 - acc: 0.9623 - val_loss: 0.8713 - val_acc: 0.7918\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.1100 - acc: 0.9656 - val_loss: 1.2086 - val_acc: 0.7733\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.1083 - acc: 0.9646 - val_loss: 1.0273 - val_acc: 0.8078\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 31s 156ms/step - loss: 0.1238 - acc: 0.9618 - val_loss: 1.1957 - val_acc: 0.7868\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.1069 - acc: 0.9643 - val_loss: 0.8792 - val_acc: 0.8168\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.1098 - acc: 0.9697 - val_loss: 0.9136 - val_acc: 0.8098\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0937 - acc: 0.9681 - val_loss: 1.1016 - val_acc: 0.7863\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.0904 - acc: 0.9710 - val_loss: 1.1049 - val_acc: 0.8103\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1112 - acc: 0.9650 - val_loss: 1.0873 - val_acc: 0.7988\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.0807 - acc: 0.9743 - val_loss: 1.0268 - val_acc: 0.8228\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.0956 - acc: 0.9700 - val_loss: 1.2355 - val_acc: 0.7823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='30.304 MB of 30.307 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.9999…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▆▆▆▇▇▇▇▇▇█████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▄▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▃▅▅▅▇▇▇▇▇▇▇▇█▇▇▇▆▇▇█▇██▇███▇</td></tr><tr><td>val_loss</td><td>█▃▆▂▃▂▁▁▂▁▁▁▁▂▁▃▂▂▄▁▃▂▃▂▂▂▂▂▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03946</td></tr><tr><td>acc</td><td>0.96965</td></tr><tr><td>best_epoch</td><td>7</td></tr><tr><td>best_val_loss</td><td>0.75822</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.09619</td></tr><tr><td>val_acc</td><td>0.78228</td></tr><tr><td>val_loss</td><td>1.23548</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">fluent-sweep-22</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/nnu2wros\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/nnu2wros</a><br/>Synced 6 W&B file(s), 2 media file(s), 20 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_051733-nnu2wros/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mtr4ph8y with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_053404-mtr4ph8y</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/mtr4ph8y\" target=\"_blank\">amber-sweep-23</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                122944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 339,658\n",
      "Trainable params: 338,890\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 32s 157ms/step - loss: 2.0115 - acc: 0.3910 - val_loss: 2.4948 - val_acc: 0.4014\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_053404-mtr4ph8y/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_053404-mtr4ph8y/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 1.1524 - acc: 0.6004 - val_loss: 1.2020 - val_acc: 0.6126\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_053404-mtr4ph8y/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_053404-mtr4ph8y/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.8747 - acc: 0.6936 - val_loss: 1.1285 - val_acc: 0.6311\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_053404-mtr4ph8y/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_053404-mtr4ph8y/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.7250 - acc: 0.7491 - val_loss: 1.4311 - val_acc: 0.5661\n",
      "Epoch 5/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.6253 - acc: 0.7955 - val_loss: 0.7881 - val_acc: 0.7538\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_053404-mtr4ph8y/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_053404-mtr4ph8y/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.5336 - acc: 0.8192 - val_loss: 0.8157 - val_acc: 0.7558\n",
      "Epoch 7/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.4491 - acc: 0.8483 - val_loss: 0.8560 - val_acc: 0.7508\n",
      "Epoch 8/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.3748 - acc: 0.8716 - val_loss: 1.0224 - val_acc: 0.7167\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.3434 - acc: 0.8797 - val_loss: 0.8167 - val_acc: 0.7748\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.3085 - acc: 0.8936 - val_loss: 1.2047 - val_acc: 0.6622\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2772 - acc: 0.9067 - val_loss: 0.8984 - val_acc: 0.7533\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.2448 - acc: 0.9170 - val_loss: 1.0099 - val_acc: 0.7613\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2279 - acc: 0.9233 - val_loss: 1.0404 - val_acc: 0.7487\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2066 - acc: 0.9271 - val_loss: 0.9056 - val_acc: 0.7923\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.1918 - acc: 0.9344 - val_loss: 0.7864 - val_acc: 0.7903\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_053404-mtr4ph8y/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_053404-mtr4ph8y/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1667 - acc: 0.9435 - val_loss: 0.9557 - val_acc: 0.7783\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.1638 - acc: 0.9451 - val_loss: 0.7063 - val_acc: 0.8203\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_053404-mtr4ph8y/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_053404-mtr4ph8y/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1368 - acc: 0.9543 - val_loss: 1.0561 - val_acc: 0.7613\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.1353 - acc: 0.9579 - val_loss: 0.7821 - val_acc: 0.7973\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.1403 - acc: 0.9493 - val_loss: 0.9233 - val_acc: 0.7933\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 31s 155ms/step - loss: 0.1243 - acc: 0.9574 - val_loss: 1.0318 - val_acc: 0.7783\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1361 - acc: 0.9569 - val_loss: 0.9160 - val_acc: 0.7933\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1196 - acc: 0.9622 - val_loss: 0.8719 - val_acc: 0.8153\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1398 - acc: 0.9583 - val_loss: 1.0951 - val_acc: 0.7848\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1206 - acc: 0.9590 - val_loss: 0.7553 - val_acc: 0.8158\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1042 - acc: 0.9669 - val_loss: 1.0743 - val_acc: 0.7638\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1105 - acc: 0.9649 - val_loss: 0.9964 - val_acc: 0.7978\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1043 - acc: 0.9678 - val_loss: 0.9507 - val_acc: 0.7998\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1153 - acc: 0.9665 - val_loss: 1.0117 - val_acc: 0.8078\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.0829 - acc: 0.9737 - val_loss: 1.2019 - val_acc: 0.7993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='22.762 MB of 22.764 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.9998…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▅▆▆▇▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▅▅▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▅▅▄▇▇▇▆▇▅▇▇▇█▇▇█▇██▇██▇█▇████</td></tr><tr><td>val_loss</td><td>█▃▃▄▁▁▂▂▁▃▂▂▂▂▁▂▁▂▁▂▂▂▂▃▁▂▂▂▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03933</td></tr><tr><td>acc</td><td>0.97247</td></tr><tr><td>best_epoch</td><td>16</td></tr><tr><td>best_val_loss</td><td>0.70628</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.0906</td></tr><tr><td>val_acc</td><td>0.7993</td></tr><tr><td>val_loss</td><td>1.20188</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">amber-sweep-23</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/mtr4ph8y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/mtr4ph8y</a><br/>Synced 6 W&B file(s), 2 media file(s), 20 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_053404-mtr4ph8y/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: tceiwf6c with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_055035-tceiwf6c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/tceiwf6c\" target=\"_blank\">ruby-sweep-24</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                122944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 339,658\n",
      "Trainable params: 338,890\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 31s 153ms/step - loss: 2.0871 - acc: 0.3709 - val_loss: 2.3113 - val_acc: 0.4204\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_055035-tceiwf6c/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_055035-tceiwf6c/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 1.2524 - acc: 0.5654 - val_loss: 1.0392 - val_acc: 0.6301\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_055035-tceiwf6c/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_055035-tceiwf6c/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.9441 - acc: 0.6763 - val_loss: 1.1795 - val_acc: 0.6451\n",
      "Epoch 4/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.8344 - acc: 0.7104 - val_loss: 0.9620 - val_acc: 0.6882\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_055035-tceiwf6c/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_055035-tceiwf6c/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.6845 - acc: 0.7633 - val_loss: 0.9741 - val_acc: 0.7052\n",
      "Epoch 6/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.5973 - acc: 0.7909 - val_loss: 0.7576 - val_acc: 0.7693\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_055035-tceiwf6c/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_055035-tceiwf6c/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.5248 - acc: 0.8241 - val_loss: 0.9108 - val_acc: 0.7372\n",
      "Epoch 8/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.4922 - acc: 0.8400 - val_loss: 0.8609 - val_acc: 0.7553\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.4284 - acc: 0.8509 - val_loss: 0.8752 - val_acc: 0.7422\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.3619 - acc: 0.8724 - val_loss: 1.0194 - val_acc: 0.7302\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.3304 - acc: 0.8834 - val_loss: 0.7671 - val_acc: 0.7778\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.2952 - acc: 0.8924 - val_loss: 0.9621 - val_acc: 0.7518\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.2926 - acc: 0.9021 - val_loss: 0.8520 - val_acc: 0.7823\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.2797 - acc: 0.9039 - val_loss: 0.8455 - val_acc: 0.7878\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.2509 - acc: 0.9120 - val_loss: 0.9316 - val_acc: 0.7778\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.2284 - acc: 0.9222 - val_loss: 0.9898 - val_acc: 0.7778\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.2082 - acc: 0.9269 - val_loss: 0.9632 - val_acc: 0.7728\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1897 - acc: 0.9368 - val_loss: 0.8672 - val_acc: 0.7948\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 30s 152ms/step - loss: 0.1972 - acc: 0.9301 - val_loss: 0.8808 - val_acc: 0.7903\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1732 - acc: 0.9411 - val_loss: 1.0813 - val_acc: 0.7723\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1755 - acc: 0.9433 - val_loss: 0.7967 - val_acc: 0.8178\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.1706 - acc: 0.9418 - val_loss: 0.8200 - val_acc: 0.8168\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1550 - acc: 0.9498 - val_loss: 0.8853 - val_acc: 0.7848\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1514 - acc: 0.9518 - val_loss: 0.8264 - val_acc: 0.8083\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1338 - acc: 0.9562 - val_loss: 0.8284 - val_acc: 0.8213\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1579 - acc: 0.9470 - val_loss: 1.0144 - val_acc: 0.8063\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1430 - acc: 0.9543 - val_loss: 0.9776 - val_acc: 0.7978\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1484 - acc: 0.9511 - val_loss: 0.8971 - val_acc: 0.8028\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1239 - acc: 0.9591 - val_loss: 0.8813 - val_acc: 0.7953\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1299 - acc: 0.9577 - val_loss: 0.9036 - val_acc: 0.8138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='16.949 MB of 16.952 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.9998…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▅▆▆▆▆▇▇▇▇▇▇▇██████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▅▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▅▅▆▆▇▇▇▇▆▇▇▇▇▇▇▇█▇▇██▇███████</td></tr><tr><td>val_loss</td><td>█▂▃▂▂▁▂▁▂▂▁▂▁▁▂▂▂▁▂▂▁▁▂▁▁▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03933</td></tr><tr><td>acc</td><td>0.95808</td></tr><tr><td>best_epoch</td><td>5</td></tr><tr><td>best_val_loss</td><td>0.75759</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.13379</td></tr><tr><td>val_acc</td><td>0.81381</td></tr><tr><td>val_loss</td><td>0.90361</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">ruby-sweep-24</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/tceiwf6c\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/tceiwf6c</a><br/>Synced 6 W&B file(s), 2 media file(s), 14 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_055035-tceiwf6c/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: w35gkjew with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_060627-w35gkjew</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/w35gkjew\" target=\"_blank\">vocal-sweep-25</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               245888    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 463,242\n",
      "Trainable params: 462,474\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 2.1138 - acc: 0.3882 - val_loss: 2.3919 - val_acc: 0.4169\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_060627-w35gkjew/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_060627-w35gkjew/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 1.2763 - acc: 0.5790 - val_loss: 1.3730 - val_acc: 0.5871\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_060627-w35gkjew/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_060627-w35gkjew/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 1.0081 - acc: 0.6680 - val_loss: 1.0395 - val_acc: 0.6712\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_060627-w35gkjew/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_060627-w35gkjew/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.8021 - acc: 0.7367 - val_loss: 1.1605 - val_acc: 0.6456\n",
      "Epoch 5/30\n",
      "200/200 [==============================] - 33s 167ms/step - loss: 0.6702 - acc: 0.7709 - val_loss: 1.1227 - val_acc: 0.7052\n",
      "Epoch 6/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.6211 - acc: 0.7960 - val_loss: 0.9611 - val_acc: 0.7237\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_060627-w35gkjew/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_060627-w35gkjew/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.4785 - acc: 0.8330 - val_loss: 1.2471 - val_acc: 0.6557\n",
      "Epoch 8/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.4182 - acc: 0.8583 - val_loss: 0.8205 - val_acc: 0.7798\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_060627-w35gkjew/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_060627-w35gkjew/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.3838 - acc: 0.8699 - val_loss: 0.8854 - val_acc: 0.7598\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.3518 - acc: 0.8802 - val_loss: 0.8772 - val_acc: 0.7598\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2950 - acc: 0.8960 - val_loss: 0.9930 - val_acc: 0.7372\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.2557 - acc: 0.9113 - val_loss: 0.9400 - val_acc: 0.7708\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2649 - acc: 0.9096 - val_loss: 0.9488 - val_acc: 0.7653\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.2369 - acc: 0.9213 - val_loss: 0.7270 - val_acc: 0.8123\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_060627-w35gkjew/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_060627-w35gkjew/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.2121 - acc: 0.9302 - val_loss: 1.1970 - val_acc: 0.7513\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2173 - acc: 0.9287 - val_loss: 0.8881 - val_acc: 0.7893\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1775 - acc: 0.9415 - val_loss: 1.2081 - val_acc: 0.7492\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1720 - acc: 0.9423 - val_loss: 0.8148 - val_acc: 0.7958\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1710 - acc: 0.9428 - val_loss: 0.8706 - val_acc: 0.7923\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1438 - acc: 0.9542 - val_loss: 1.3704 - val_acc: 0.7187\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1267 - acc: 0.9578 - val_loss: 1.1874 - val_acc: 0.7658\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1573 - acc: 0.9525 - val_loss: 0.7731 - val_acc: 0.8113\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.1126 - acc: 0.9617 - val_loss: 1.0518 - val_acc: 0.7883\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.1397 - acc: 0.9548 - val_loss: 1.0598 - val_acc: 0.7783\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.1294 - acc: 0.9558 - val_loss: 0.9130 - val_acc: 0.8108\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.1130 - acc: 0.9622 - val_loss: 1.0500 - val_acc: 0.7948\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1103 - acc: 0.9648 - val_loss: 1.0045 - val_acc: 0.8013\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1029 - acc: 0.9664 - val_loss: 1.0869 - val_acc: 0.7838\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.1198 - acc: 0.9660 - val_loss: 1.0241 - val_acc: 0.8038\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.1172 - acc: 0.9642 - val_loss: 1.0475 - val_acc: 0.8098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='30.307 MB of 30.307 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▅▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▆▅▆▆▅▇▇▇▇▇▇█▇█▇██▆▇██▇███▇██</td></tr><tr><td>val_loss</td><td>█▄▂▃▃▂▃▁▂▂▂▂▂▁▃▂▃▁▂▄▃▁▂▂▂▂▂▃▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03946</td></tr><tr><td>acc</td><td>0.96574</td></tr><tr><td>best_epoch</td><td>13</td></tr><tr><td>best_val_loss</td><td>0.72702</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.11308</td></tr><tr><td>val_acc</td><td>0.80981</td></tr><tr><td>val_loss</td><td>1.0475</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">vocal-sweep-25</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/w35gkjew\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/w35gkjew</a><br/>Synced 6 W&B file(s), 2 media file(s), 20 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_060627-w35gkjew/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9brqu51f with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_062316-9brqu51f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/9brqu51f\" target=\"_blank\">rich-sweep-26</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                122944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 339,658\n",
      "Trainable params: 338,890\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 34s 167ms/step - loss: 1.9896 - acc: 0.3846 - val_loss: 2.2851 - val_acc: 0.4099\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_062316-9brqu51f/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_062316-9brqu51f/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 33s 165ms/step - loss: 1.2164 - acc: 0.5949 - val_loss: 1.3938 - val_acc: 0.5786\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_062316-9brqu51f/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_062316-9brqu51f/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 34s 168ms/step - loss: 0.8748 - acc: 0.6913 - val_loss: 1.5148 - val_acc: 0.5666\n",
      "Epoch 4/30\n",
      "200/200 [==============================] - 33s 167ms/step - loss: 0.7369 - acc: 0.7505 - val_loss: 1.0017 - val_acc: 0.6552\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_062316-9brqu51f/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_062316-9brqu51f/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "200/200 [==============================] - 34s 168ms/step - loss: 0.6002 - acc: 0.7944 - val_loss: 0.9605 - val_acc: 0.7042\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_062316-9brqu51f/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_062316-9brqu51f/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.5177 - acc: 0.8281 - val_loss: 1.0844 - val_acc: 0.6862\n",
      "Epoch 7/30\n",
      "200/200 [==============================] - 31s 157ms/step - loss: 0.4294 - acc: 0.8487 - val_loss: 0.7791 - val_acc: 0.7497\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_062316-9brqu51f/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_062316-9brqu51f/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "200/200 [==============================] - 33s 165ms/step - loss: 0.3722 - acc: 0.8743 - val_loss: 0.9956 - val_acc: 0.7347\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.3101 - acc: 0.8907 - val_loss: 0.7861 - val_acc: 0.7768\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.2993 - acc: 0.8996 - val_loss: 0.9268 - val_acc: 0.7563\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.2638 - acc: 0.9125 - val_loss: 0.6947 - val_acc: 0.8073\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_062316-9brqu51f/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_062316-9brqu51f/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2373 - acc: 0.9193 - val_loss: 1.1946 - val_acc: 0.7027\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2280 - acc: 0.9223 - val_loss: 1.1285 - val_acc: 0.7518\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 31s 156ms/step - loss: 0.1843 - acc: 0.9377 - val_loss: 0.8242 - val_acc: 0.7878\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1709 - acc: 0.9396 - val_loss: 0.7458 - val_acc: 0.8113\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 30s 152ms/step - loss: 0.1590 - acc: 0.9439 - val_loss: 0.8283 - val_acc: 0.7963\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1906 - acc: 0.9406 - val_loss: 0.9329 - val_acc: 0.7913\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1310 - acc: 0.9555 - val_loss: 1.0643 - val_acc: 0.7578\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1424 - acc: 0.9549 - val_loss: 0.7591 - val_acc: 0.8138\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 31s 153ms/step - loss: 0.1123 - acc: 0.9643 - val_loss: 1.0317 - val_acc: 0.7693\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1291 - acc: 0.9576 - val_loss: 1.1005 - val_acc: 0.7427\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1282 - acc: 0.9553 - val_loss: 1.0656 - val_acc: 0.7648\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1141 - acc: 0.9599 - val_loss: 1.1460 - val_acc: 0.7808\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1240 - acc: 0.9615 - val_loss: 0.9571 - val_acc: 0.8073\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1001 - acc: 0.9678 - val_loss: 0.9256 - val_acc: 0.7938\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 30s 152ms/step - loss: 0.1065 - acc: 0.9642 - val_loss: 1.2686 - val_acc: 0.7648\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.1075 - acc: 0.9675 - val_loss: 0.8676 - val_acc: 0.8193\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.0979 - acc: 0.9676 - val_loss: 1.2557 - val_acc: 0.7938\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.0767 - acc: 0.9744 - val_loss: 0.8979 - val_acc: 0.8223\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.0833 - acc: 0.9741 - val_loss: 1.0896 - val_acc: 0.8128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='22.762 MB of 22.764 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.9998…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▅▆▆▇▇▇▇▇▇▇████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▄▅▆▆▇▇▇▇█▆▇▇██▇▇█▇▇▇▇██▇████</td></tr><tr><td>val_loss</td><td>█▄▅▂▂▃▁▂▁▂▁▃▃▂▁▂▂▃▁▂▃▃▃▂▂▄▂▃▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03933</td></tr><tr><td>acc</td><td>0.9684</td></tr><tr><td>best_epoch</td><td>10</td></tr><tr><td>best_val_loss</td><td>0.69468</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.10601</td></tr><tr><td>val_acc</td><td>0.81281</td></tr><tr><td>val_loss</td><td>1.08959</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">rich-sweep-26</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/9brqu51f\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/9brqu51f</a><br/>Synced 6 W&B file(s), 2 media file(s), 20 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_062316-9brqu51f/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9m09cmw1 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_063937-9m09cmw1</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/9m09cmw1\" target=\"_blank\">spring-sweep-27</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                122944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 339,658\n",
      "Trainable params: 338,890\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 2.0350 - acc: 0.3748 - val_loss: 2.4556 - val_acc: 0.3934\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_063937-9m09cmw1/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_063937-9m09cmw1/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 34s 170ms/step - loss: 1.1563 - acc: 0.6008 - val_loss: 1.3931 - val_acc: 0.5506\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_063937-9m09cmw1/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_063937-9m09cmw1/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 34s 168ms/step - loss: 0.9318 - acc: 0.6767 - val_loss: 1.2180 - val_acc: 0.6532\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_063937-9m09cmw1/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_063937-9m09cmw1/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "200/200 [==============================] - 34s 168ms/step - loss: 0.7180 - acc: 0.7455 - val_loss: 1.0985 - val_acc: 0.6712\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_063937-9m09cmw1/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_063937-9m09cmw1/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "200/200 [==============================] - 34s 169ms/step - loss: 0.5989 - acc: 0.7930 - val_loss: 0.9469 - val_acc: 0.7182\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_063937-9m09cmw1/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_063937-9m09cmw1/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "200/200 [==============================] - 34s 169ms/step - loss: 0.4931 - acc: 0.8276 - val_loss: 0.9509 - val_acc: 0.7277\n",
      "Epoch 7/30\n",
      "200/200 [==============================] - 33s 168ms/step - loss: 0.4311 - acc: 0.8521 - val_loss: 0.7611 - val_acc: 0.7773\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_063937-9m09cmw1/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_063937-9m09cmw1/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.3775 - acc: 0.8687 - val_loss: 0.8027 - val_acc: 0.7462\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.3262 - acc: 0.8830 - val_loss: 1.1604 - val_acc: 0.6897\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - 31s 157ms/step - loss: 0.2973 - acc: 0.9035 - val_loss: 0.8631 - val_acc: 0.7508\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.2449 - acc: 0.9187 - val_loss: 0.8739 - val_acc: 0.7688\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.2486 - acc: 0.9176 - val_loss: 0.8541 - val_acc: 0.7603\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.2108 - acc: 0.9281 - val_loss: 0.8215 - val_acc: 0.7813\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1862 - acc: 0.9366 - val_loss: 0.7884 - val_acc: 0.7923\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1957 - acc: 0.9303 - val_loss: 0.8167 - val_acc: 0.7723\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1776 - acc: 0.9470 - val_loss: 0.9035 - val_acc: 0.7868\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1560 - acc: 0.9460 - val_loss: 0.7877 - val_acc: 0.8023\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1607 - acc: 0.9487 - val_loss: 0.8012 - val_acc: 0.8058\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1487 - acc: 0.9502 - val_loss: 0.7401 - val_acc: 0.8238\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_063937-9m09cmw1/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_063937-9m09cmw1/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1435 - acc: 0.9538 - val_loss: 0.8581 - val_acc: 0.8103\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1417 - acc: 0.9514 - val_loss: 0.9001 - val_acc: 0.7893\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1242 - acc: 0.9596 - val_loss: 1.0553 - val_acc: 0.7883\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.1071 - acc: 0.9646 - val_loss: 0.9244 - val_acc: 0.7883\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1123 - acc: 0.9630 - val_loss: 0.8927 - val_acc: 0.8063\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.0999 - acc: 0.9696 - val_loss: 0.9069 - val_acc: 0.8163\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1011 - acc: 0.9654 - val_loss: 0.9802 - val_acc: 0.7978\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.1009 - acc: 0.9698 - val_loss: 0.8884 - val_acc: 0.8033\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1009 - acc: 0.9652 - val_loss: 1.3226 - val_acc: 0.7492\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.0941 - acc: 0.9663 - val_loss: 0.8397 - val_acc: 0.8193\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.1025 - acc: 0.9708 - val_loss: 0.9346 - val_acc: 0.8073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='25.668 MB of 25.670 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.9999…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▅▆▆▇▇▇▇▇▇█▇███████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▅▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▅▆▆▆▇▇▆▇▇▇▇▇▇▇████▇▇▇████▇██</td></tr><tr><td>val_loss</td><td>█▄▃▂▂▂▁▁▃▂▂▁▁▁▁▂▁▁▁▁▂▂▂▂▂▂▂▃▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03933</td></tr><tr><td>acc</td><td>0.96934</td></tr><tr><td>best_epoch</td><td>18</td></tr><tr><td>best_val_loss</td><td>0.74007</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.10128</td></tr><tr><td>val_acc</td><td>0.80731</td></tr><tr><td>val_loss</td><td>0.93465</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">spring-sweep-27</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/9m09cmw1\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/9m09cmw1</a><br/>Synced 6 W&B file(s), 2 media file(s), 23 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_063937-9m09cmw1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ewbqnn8o with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_065618-ewbqnn8o</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/ewbqnn8o\" target=\"_blank\">denim-sweep-28</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                122944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 339,658\n",
      "Trainable params: 338,890\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 34s 168ms/step - loss: 2.0329 - acc: 0.3730 - val_loss: 2.0327 - val_acc: 0.5005\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_065618-ewbqnn8o/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_065618-ewbqnn8o/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 1.3164 - acc: 0.5403 - val_loss: 1.4694 - val_acc: 0.4875\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_065618-ewbqnn8o/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_065618-ewbqnn8o/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 31s 154ms/step - loss: 1.0055 - acc: 0.6486 - val_loss: 1.0677 - val_acc: 0.6366\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_065618-ewbqnn8o/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_065618-ewbqnn8o/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.8261 - acc: 0.7129 - val_loss: 0.8836 - val_acc: 0.7032\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_065618-ewbqnn8o/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_065618-ewbqnn8o/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.7039 - acc: 0.7618 - val_loss: 0.8247 - val_acc: 0.7302\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_065618-ewbqnn8o/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_065618-ewbqnn8o/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.5850 - acc: 0.7988 - val_loss: 0.7749 - val_acc: 0.7497\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_065618-ewbqnn8o/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_065618-ewbqnn8o/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.5343 - acc: 0.8166 - val_loss: 0.8406 - val_acc: 0.7307\n",
      "Epoch 8/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.4549 - acc: 0.8496 - val_loss: 0.8588 - val_acc: 0.7643\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.3982 - acc: 0.8565 - val_loss: 0.8078 - val_acc: 0.7563\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.3717 - acc: 0.8675 - val_loss: 0.8324 - val_acc: 0.7583\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.3289 - acc: 0.8903 - val_loss: 1.3395 - val_acc: 0.6632\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.3089 - acc: 0.8951 - val_loss: 0.8989 - val_acc: 0.7432\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2734 - acc: 0.9047 - val_loss: 0.7886 - val_acc: 0.7768\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2455 - acc: 0.9125 - val_loss: 0.7049 - val_acc: 0.8048\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_065618-ewbqnn8o/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_065618-ewbqnn8o/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.2280 - acc: 0.9253 - val_loss: 0.7281 - val_acc: 0.7998\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.2163 - acc: 0.9254 - val_loss: 0.8010 - val_acc: 0.7938\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.2067 - acc: 0.9290 - val_loss: 0.9733 - val_acc: 0.7573\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1814 - acc: 0.9357 - val_loss: 0.8487 - val_acc: 0.7823\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1586 - acc: 0.9477 - val_loss: 0.8118 - val_acc: 0.7898\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.1647 - acc: 0.9423 - val_loss: 0.8796 - val_acc: 0.7843\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.1849 - acc: 0.9421 - val_loss: 0.7795 - val_acc: 0.8188\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 0.1617 - acc: 0.9472 - val_loss: 0.8433 - val_acc: 0.8078\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1497 - acc: 0.9484 - val_loss: 0.8255 - val_acc: 0.7953\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1603 - acc: 0.9466 - val_loss: 1.0649 - val_acc: 0.7738\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1525 - acc: 0.9515 - val_loss: 0.6580 - val_acc: 0.8418\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_065618-ewbqnn8o/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_065618-ewbqnn8o/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30\n",
      "200/200 [==============================] - 31s 157ms/step - loss: 0.1173 - acc: 0.9612 - val_loss: 0.8235 - val_acc: 0.8078\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1354 - acc: 0.9578 - val_loss: 0.8446 - val_acc: 0.8118\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.1114 - acc: 0.9637 - val_loss: 0.9667 - val_acc: 0.7863\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1259 - acc: 0.9622 - val_loss: 1.1583 - val_acc: 0.7828\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.1366 - acc: 0.9540 - val_loss: 0.8367 - val_acc: 0.8078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='28.574 MB of 28.576 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.9999…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇▇█▇██████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▅▄▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▁▄▅▆▆▆▆▆▆▄▆▇▇▇▇▆▇▇▇█▇▇▇█▇▇▇▇▇</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▂▂▂▂▂▄▂▂▁▁▂▃▂▂▂▂▂▂▃▁▂▂▃▄▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03933</td></tr><tr><td>acc</td><td>0.95839</td></tr><tr><td>best_epoch</td><td>24</td></tr><tr><td>best_val_loss</td><td>0.65802</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.12912</td></tr><tr><td>val_acc</td><td>0.80781</td></tr><tr><td>val_loss</td><td>0.83672</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">denim-sweep-28</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/ewbqnn8o\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/ewbqnn8o</a><br/>Synced 6 W&B file(s), 2 media file(s), 26 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_065618-ewbqnn8o/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: pij0x2kl with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_071302-pij0x2kl</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/pij0x2kl\" target=\"_blank\">bumbling-sweep-29</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               245888    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 463,242\n",
      "Trainable params: 462,474\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 2.1456 - acc: 0.3889 - val_loss: 2.7274 - val_acc: 0.3413\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_071302-pij0x2kl/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_071302-pij0x2kl/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 1.1917 - acc: 0.6028 - val_loss: 1.5814 - val_acc: 0.5420\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_071302-pij0x2kl/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_071302-pij0x2kl/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.8449 - acc: 0.7080 - val_loss: 1.0392 - val_acc: 0.6732\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_071302-pij0x2kl/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_071302-pij0x2kl/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.6988 - acc: 0.7590 - val_loss: 0.9004 - val_acc: 0.7292\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_071302-pij0x2kl/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_071302-pij0x2kl/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.5547 - acc: 0.8147 - val_loss: 1.0507 - val_acc: 0.6952\n",
      "Epoch 6/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.4591 - acc: 0.8407 - val_loss: 0.8665 - val_acc: 0.7563\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_071302-pij0x2kl/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_071302-pij0x2kl/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.4134 - acc: 0.8616 - val_loss: 0.9093 - val_acc: 0.7417\n",
      "Epoch 8/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.3382 - acc: 0.8867 - val_loss: 0.8379 - val_acc: 0.7748\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_071302-pij0x2kl/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_071302-pij0x2kl/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2945 - acc: 0.9071 - val_loss: 1.0454 - val_acc: 0.7377\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.2551 - acc: 0.9193 - val_loss: 0.8174 - val_acc: 0.7918\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_071302-pij0x2kl/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_071302-pij0x2kl/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2222 - acc: 0.9268 - val_loss: 0.8061 - val_acc: 0.7943\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_071302-pij0x2kl/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_071302-pij0x2kl/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.2163 - acc: 0.9302 - val_loss: 0.9067 - val_acc: 0.7698\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.1996 - acc: 0.9336 - val_loss: 0.7874 - val_acc: 0.7933\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_071302-pij0x2kl/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_071302-pij0x2kl/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.1481 - acc: 0.9516 - val_loss: 0.7414 - val_acc: 0.8233\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_071302-pij0x2kl/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_071302-pij0x2kl/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1528 - acc: 0.9496 - val_loss: 0.9361 - val_acc: 0.8118\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.1545 - acc: 0.9532 - val_loss: 0.9262 - val_acc: 0.7933\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1411 - acc: 0.9555 - val_loss: 1.0544 - val_acc: 0.7873\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.1163 - acc: 0.9624 - val_loss: 1.0267 - val_acc: 0.7738\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1395 - acc: 0.9551 - val_loss: 1.2956 - val_acc: 0.7663\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1247 - acc: 0.9644 - val_loss: 0.9051 - val_acc: 0.8138\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.1070 - acc: 0.9684 - val_loss: 0.9922 - val_acc: 0.7898\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1019 - acc: 0.9669 - val_loss: 1.1200 - val_acc: 0.7873\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.0962 - acc: 0.9709 - val_loss: 1.0225 - val_acc: 0.7918\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.0954 - acc: 0.9730 - val_loss: 1.0686 - val_acc: 0.7898\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.1051 - acc: 0.9680 - val_loss: 1.1927 - val_acc: 0.7573\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.1108 - acc: 0.9682 - val_loss: 1.1766 - val_acc: 0.7918\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 31s 153ms/step - loss: 0.0973 - acc: 0.9710 - val_loss: 0.9949 - val_acc: 0.7978\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.0926 - acc: 0.9729 - val_loss: 0.9978 - val_acc: 0.7968\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.0905 - acc: 0.9764 - val_loss: 1.1965 - val_acc: 0.8008\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 30s 152ms/step - loss: 0.0754 - acc: 0.9773 - val_loss: 1.2795 - val_acc: 0.7878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='45.704 MB of 45.707 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.9999…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▆▆▆▇▇▇▇▇▇█████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▅▄▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▆▇▆▇▇▇▇██▇████▇▇▇██▇██▇████▇</td></tr><tr><td>val_loss</td><td>█▄▂▂▂▁▂▁▂▁▁▂▁▁▂▂▂▂▃▂▂▂▂▂▃▃▂▂▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03946</td></tr><tr><td>acc</td><td>0.96965</td></tr><tr><td>best_epoch</td><td>13</td></tr><tr><td>best_val_loss</td><td>0.74141</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.10108</td></tr><tr><td>val_acc</td><td>0.78779</td></tr><tr><td>val_loss</td><td>1.27952</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">bumbling-sweep-29</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/pij0x2kl\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/pij0x2kl</a><br/>Synced 6 W&B file(s), 2 media file(s), 32 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_071302-pij0x2kl/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 1eytqcdz with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_072936-1eytqcdz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/1eytqcdz\" target=\"_blank\">northern-sweep-30</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                122944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 339,658\n",
      "Trainable params: 338,890\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 33s 161ms/step - loss: 2.0976 - acc: 0.3665 - val_loss: 2.7446 - val_acc: 0.3529\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_072936-1eytqcdz/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_072936-1eytqcdz/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 33s 166ms/step - loss: 1.2711 - acc: 0.5695 - val_loss: 1.1373 - val_acc: 0.6436\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_072936-1eytqcdz/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_072936-1eytqcdz/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 1.0182 - acc: 0.6483 - val_loss: 1.0733 - val_acc: 0.6652\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_072936-1eytqcdz/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_072936-1eytqcdz/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.7859 - acc: 0.7358 - val_loss: 1.0759 - val_acc: 0.6762\n",
      "Epoch 5/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.6702 - acc: 0.7614 - val_loss: 0.8505 - val_acc: 0.7327\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_072936-1eytqcdz/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_072936-1eytqcdz/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "200/200 [==============================] - 31s 154ms/step - loss: 0.5911 - acc: 0.7992 - val_loss: 1.0018 - val_acc: 0.7057\n",
      "Epoch 7/30\n",
      "200/200 [==============================] - 30s 148ms/step - loss: 0.5420 - acc: 0.8106 - val_loss: 0.9215 - val_acc: 0.7212\n",
      "Epoch 8/30\n",
      "200/200 [==============================] - 30s 152ms/step - loss: 0.4423 - acc: 0.8450 - val_loss: 0.8876 - val_acc: 0.7492\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 30s 149ms/step - loss: 0.4127 - acc: 0.8641 - val_loss: 0.8798 - val_acc: 0.7528\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - 30s 150ms/step - loss: 0.3465 - acc: 0.8818 - val_loss: 0.9533 - val_acc: 0.7417\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 30s 151ms/step - loss: 0.3368 - acc: 0.8858 - val_loss: 0.7527 - val_acc: 0.7768\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_072936-1eytqcdz/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_072936-1eytqcdz/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.2895 - acc: 0.8919 - val_loss: 0.8362 - val_acc: 0.7663\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 31s 155ms/step - loss: 0.2902 - acc: 0.9055 - val_loss: 0.6945 - val_acc: 0.8068\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_072936-1eytqcdz/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_072936-1eytqcdz/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2450 - acc: 0.9144 - val_loss: 0.7525 - val_acc: 0.8128\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.2261 - acc: 0.9245 - val_loss: 0.9140 - val_acc: 0.7853\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1928 - acc: 0.9426 - val_loss: 0.9725 - val_acc: 0.7793\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.1919 - acc: 0.9355 - val_loss: 0.7513 - val_acc: 0.7993\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 33s 165ms/step - loss: 0.1856 - acc: 0.9364 - val_loss: 0.7634 - val_acc: 0.8138\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.1594 - acc: 0.9482 - val_loss: 0.9035 - val_acc: 0.8003\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1569 - acc: 0.9516 - val_loss: 0.8884 - val_acc: 0.7913\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 0.1485 - acc: 0.9529 - val_loss: 1.0048 - val_acc: 0.7808\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1791 - acc: 0.9420 - val_loss: 0.9966 - val_acc: 0.7918\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.1625 - acc: 0.9457 - val_loss: 0.9473 - val_acc: 0.8098\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.1317 - acc: 0.9595 - val_loss: 0.7533 - val_acc: 0.8328\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1612 - acc: 0.9466 - val_loss: 0.9103 - val_acc: 0.7948\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1412 - acc: 0.9545 - val_loss: 0.8803 - val_acc: 0.8013\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1178 - acc: 0.9629 - val_loss: 0.9692 - val_acc: 0.8323\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.1238 - acc: 0.9613 - val_loss: 1.4513 - val_acc: 0.7177\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1356 - acc: 0.9591 - val_loss: 1.0993 - val_acc: 0.8063\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.1151 - acc: 0.9647 - val_loss: 0.9254 - val_acc: 0.8168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='22.763 MB of 22.765 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.9998…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇▇▇███████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▅▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▅▆▆▇▆▆▇▇▇▇▇██▇▇███▇▇▇██▇██▆██</td></tr><tr><td>val_loss</td><td>█▃▂▂▂▂▂▂▂▂▁▁▁▁▂▂▁▁▂▂▂▂▂▁▂▂▂▄▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03933</td></tr><tr><td>acc</td><td>0.96308</td></tr><tr><td>best_epoch</td><td>12</td></tr><tr><td>best_val_loss</td><td>0.69448</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.12501</td></tr><tr><td>val_acc</td><td>0.81682</td></tr><tr><td>val_loss</td><td>0.92541</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">northern-sweep-30</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/1eytqcdz\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/1eytqcdz</a><br/>Synced 6 W&B file(s), 2 media file(s), 20 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_072936-1eytqcdz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 68b7t6z8 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_074614-68b7t6z8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/68b7t6z8\" target=\"_blank\">revived-sweep-31</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                122944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 339,658\n",
      "Trainable params: 338,890\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 35s 172ms/step - loss: 2.0129 - acc: 0.3770 - val_loss: 2.3933 - val_acc: 0.4795\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_074614-68b7t6z8/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_074614-68b7t6z8/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 33s 166ms/step - loss: 1.1798 - acc: 0.5968 - val_loss: 1.3154 - val_acc: 0.5531\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_074614-68b7t6z8/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_074614-68b7t6z8/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 31s 157ms/step - loss: 0.9315 - acc: 0.6748 - val_loss: 1.1160 - val_acc: 0.6326\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_074614-68b7t6z8/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_074614-68b7t6z8/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.7549 - acc: 0.7416 - val_loss: 1.0750 - val_acc: 0.6537\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_074614-68b7t6z8/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_074614-68b7t6z8/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "200/200 [==============================] - 31s 157ms/step - loss: 0.6161 - acc: 0.7863 - val_loss: 0.9065 - val_acc: 0.7187\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_074614-68b7t6z8/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_074614-68b7t6z8/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 0.5447 - acc: 0.8131 - val_loss: 0.7509 - val_acc: 0.7583\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_074614-68b7t6z8/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_074614-68b7t6z8/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "200/200 [==============================] - 44s 222ms/step - loss: 0.4261 - acc: 0.8467 - val_loss: 0.7851 - val_acc: 0.7843\n",
      "Epoch 8/30\n",
      "200/200 [==============================] - 33s 166ms/step - loss: 0.3629 - acc: 0.8687 - val_loss: 1.2047 - val_acc: 0.6702\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 33s 167ms/step - loss: 0.3500 - acc: 0.8725 - val_loss: 0.7242 - val_acc: 0.7853\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_074614-68b7t6z8/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_074614-68b7t6z8/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "200/200 [==============================] - 34s 171ms/step - loss: 0.3025 - acc: 0.8999 - val_loss: 1.0068 - val_acc: 0.7528\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 0.2688 - acc: 0.9049 - val_loss: 0.7661 - val_acc: 0.7798\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 39s 197ms/step - loss: 0.2478 - acc: 0.9143 - val_loss: 0.7996 - val_acc: 0.7863\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 33s 165ms/step - loss: 0.2071 - acc: 0.9261 - val_loss: 0.9622 - val_acc: 0.7442\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 0.1958 - acc: 0.9361 - val_loss: 0.7149 - val_acc: 0.8088\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_074614-68b7t6z8/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_074614-68b7t6z8/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30\n",
      "200/200 [==============================] - 33s 166ms/step - loss: 0.1785 - acc: 0.9375 - val_loss: 0.9361 - val_acc: 0.7553\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 0.1593 - acc: 0.9425 - val_loss: 0.9544 - val_acc: 0.7663\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 0.1524 - acc: 0.9465 - val_loss: 0.8369 - val_acc: 0.7913\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 48s 242ms/step - loss: 0.1398 - acc: 0.9543 - val_loss: 0.8654 - val_acc: 0.8083\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 42s 211ms/step - loss: 0.1423 - acc: 0.9556 - val_loss: 0.9001 - val_acc: 0.8053\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 0.1302 - acc: 0.9555 - val_loss: 0.8091 - val_acc: 0.8048\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 0.1158 - acc: 0.9621 - val_loss: 0.9647 - val_acc: 0.8123\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 0.1156 - acc: 0.9622 - val_loss: 1.0852 - val_acc: 0.7788\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 36s 182ms/step - loss: 0.1161 - acc: 0.9609 - val_loss: 1.0887 - val_acc: 0.7943\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 49s 245ms/step - loss: 0.1266 - acc: 0.9607 - val_loss: 0.9763 - val_acc: 0.8128\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 0.0987 - acc: 0.9686 - val_loss: 0.9506 - val_acc: 0.8213\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 34s 170ms/step - loss: 0.1002 - acc: 0.9662 - val_loss: 0.9148 - val_acc: 0.8208\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 34s 169ms/step - loss: 0.1127 - acc: 0.9663 - val_loss: 1.0215 - val_acc: 0.7888\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 33s 166ms/step - loss: 0.1100 - acc: 0.9639 - val_loss: 1.4695 - val_acc: 0.7487\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 0.1067 - acc: 0.9633 - val_loss: 0.9284 - val_acc: 0.8128\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 0.0900 - acc: 0.9715 - val_loss: 1.2025 - val_acc: 0.7953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='28.577 MB of 28.580 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.9999…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▆▆▆▇▇▇▇▇▇▇▇███████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▅▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▄▅▆▇▇▅▇▇▇▇▆█▇▇▇████▇▇███▇▇█▇</td></tr><tr><td>val_loss</td><td>█▄▃▃▂▁▁▃▁▂▁▁▂▁▂▂▂▂▂▁▂▃▃▂▂▂▂▄▂▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03933</td></tr><tr><td>acc</td><td>0.96684</td></tr><tr><td>best_epoch</td><td>13</td></tr><tr><td>best_val_loss</td><td>0.71489</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.10495</td></tr><tr><td>val_acc</td><td>0.7953</td></tr><tr><td>val_loss</td><td>1.20253</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">revived-sweep-31</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/68b7t6z8\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/68b7t6z8</a><br/>Synced 6 W&B file(s), 2 media file(s), 26 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_074614-68b7t6z8/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Job received.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4fxc7fmc with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_080610-4fxc7fmc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/4fxc7fmc\" target=\"_blank\">olive-sweep-32</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                122944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 339,658\n",
      "Trainable params: 338,890\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 46s 227ms/step - loss: 2.0946 - acc: 0.3839 - val_loss: 2.5062 - val_acc: 0.4104\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_080610-4fxc7fmc/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_080610-4fxc7fmc/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 1.2737 - acc: 0.5794 - val_loss: 1.1982 - val_acc: 0.6171\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_080610-4fxc7fmc/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_080610-4fxc7fmc/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 0.9808 - acc: 0.6638 - val_loss: 1.0680 - val_acc: 0.6346\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_080610-4fxc7fmc/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_080610-4fxc7fmc/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "200/200 [==============================] - 34s 171ms/step - loss: 0.8214 - acc: 0.7239 - val_loss: 1.1187 - val_acc: 0.6632\n",
      "Epoch 5/30\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 0.6405 - acc: 0.7716 - val_loss: 0.8680 - val_acc: 0.7197\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_080610-4fxc7fmc/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_080610-4fxc7fmc/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 0.6213 - acc: 0.7863 - val_loss: 0.8640 - val_acc: 0.7272\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_080610-4fxc7fmc/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_080610-4fxc7fmc/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "200/200 [==============================] - 43s 217ms/step - loss: 0.5108 - acc: 0.8261 - val_loss: 0.8386 - val_acc: 0.7543\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_080610-4fxc7fmc/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_080610-4fxc7fmc/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 0.4564 - acc: 0.8438 - val_loss: 0.7739 - val_acc: 0.7563\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_080610-4fxc7fmc/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_080610-4fxc7fmc/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 0.4261 - acc: 0.8545 - val_loss: 0.7534 - val_acc: 0.7748\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_080610-4fxc7fmc/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_080610-4fxc7fmc/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "200/200 [==============================] - 40s 203ms/step - loss: 0.3866 - acc: 0.8664 - val_loss: 0.9886 - val_acc: 0.7397\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 41s 207ms/step - loss: 0.3322 - acc: 0.8908 - val_loss: 1.0524 - val_acc: 0.7287\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 45s 223ms/step - loss: 0.2958 - acc: 0.8969 - val_loss: 0.7628 - val_acc: 0.7788\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 0.2758 - acc: 0.9063 - val_loss: 0.7721 - val_acc: 0.7873\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 0.2641 - acc: 0.9085 - val_loss: 0.8372 - val_acc: 0.7653\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 35s 177ms/step - loss: 0.2442 - acc: 0.9171 - val_loss: 0.7794 - val_acc: 0.7838\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 49s 247ms/step - loss: 0.2077 - acc: 0.9311 - val_loss: 0.8120 - val_acc: 0.7813\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 0.1922 - acc: 0.9337 - val_loss: 0.9705 - val_acc: 0.7743\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 0.1779 - acc: 0.9462 - val_loss: 0.8324 - val_acc: 0.7923\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 43s 217ms/step - loss: 0.1844 - acc: 0.9403 - val_loss: 0.8018 - val_acc: 0.7948\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 0.1614 - acc: 0.9457 - val_loss: 0.9291 - val_acc: 0.7853\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 0.1844 - acc: 0.9400 - val_loss: 1.1952 - val_acc: 0.7482\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 0.1628 - acc: 0.9456 - val_loss: 1.0695 - val_acc: 0.7793\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 43s 217ms/step - loss: 0.1712 - acc: 0.9460 - val_loss: 0.9660 - val_acc: 0.7968\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 46s 230ms/step - loss: 0.1308 - acc: 0.9574 - val_loss: 0.8535 - val_acc: 0.8008\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 41s 207ms/step - loss: 0.1333 - acc: 0.9537 - val_loss: 1.2401 - val_acc: 0.7668\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 0.1307 - acc: 0.9600 - val_loss: 1.0341 - val_acc: 0.7763\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 45s 225ms/step - loss: 0.1401 - acc: 0.9582 - val_loss: 0.8536 - val_acc: 0.8063\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 40s 202ms/step - loss: 0.1200 - acc: 0.9587 - val_loss: 0.8304 - val_acc: 0.8203\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 0.1416 - acc: 0.9554 - val_loss: 0.9873 - val_acc: 0.8068\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 0.1346 - acc: 0.9611 - val_loss: 0.8607 - val_acc: 0.8183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='28.580 MB of 28.580 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▅▆▆▆▆▇▇▇▇▇▇▇██████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▅▄▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▅▅▅▆▆▇▇▇▇▆▇▇▇▇▇▇██▇▇▇██▇▇████</td></tr><tr><td>val_loss</td><td>█▃▂▂▁▁▁▁▁▂▂▁▁▁▁▁▂▁▁▂▃▂▂▁▃▂▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03933</td></tr><tr><td>acc</td><td>0.96027</td></tr><tr><td>best_epoch</td><td>8</td></tr><tr><td>best_val_loss</td><td>0.75337</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.13568</td></tr><tr><td>val_acc</td><td>0.81832</td></tr><tr><td>val_loss</td><td>0.86072</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">olive-sweep-32</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/4fxc7fmc\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/4fxc7fmc</a><br/>Synced 6 W&B file(s), 2 media file(s), 26 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_080610-4fxc7fmc/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4yi1xjzb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_082732-4yi1xjzb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/4yi1xjzb\" target=\"_blank\">devout-sweep-33</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                122944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 339,658\n",
      "Trainable params: 338,890\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 40s 196ms/step - loss: 2.0422 - acc: 0.3760 - val_loss: 3.1144 - val_acc: 0.4489\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_082732-4yi1xjzb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_082732-4yi1xjzb/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 1.2528 - acc: 0.5803 - val_loss: 1.1515 - val_acc: 0.6366\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_082732-4yi1xjzb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_082732-4yi1xjzb/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 35s 173ms/step - loss: 0.9680 - acc: 0.6711 - val_loss: 1.0784 - val_acc: 0.6682\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_082732-4yi1xjzb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_082732-4yi1xjzb/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "200/200 [==============================] - 34s 171ms/step - loss: 0.7807 - acc: 0.7274 - val_loss: 0.9233 - val_acc: 0.7122\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_082732-4yi1xjzb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_082732-4yi1xjzb/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 0.6683 - acc: 0.7707 - val_loss: 0.9060 - val_acc: 0.7067\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_082732-4yi1xjzb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_082732-4yi1xjzb/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 0.5777 - acc: 0.8096 - val_loss: 0.7632 - val_acc: 0.7312\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_082732-4yi1xjzb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_082732-4yi1xjzb/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "200/200 [==============================] - 38s 189ms/step - loss: 0.4806 - acc: 0.8333 - val_loss: 0.7815 - val_acc: 0.7553\n",
      "Epoch 8/30\n",
      "200/200 [==============================] - 34s 170ms/step - loss: 0.4432 - acc: 0.8497 - val_loss: 0.8823 - val_acc: 0.7513\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 0.3804 - acc: 0.8717 - val_loss: 0.9322 - val_acc: 0.7267\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - 58s 290ms/step - loss: 0.3490 - acc: 0.8839 - val_loss: 0.9598 - val_acc: 0.7252\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 0.3447 - acc: 0.8782 - val_loss: 0.7477 - val_acc: 0.7803\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_082732-4yi1xjzb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_082732-4yi1xjzb/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 0.2743 - acc: 0.9063 - val_loss: 0.7456 - val_acc: 0.7833\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_082732-4yi1xjzb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_082732-4yi1xjzb/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 0.2752 - acc: 0.9003 - val_loss: 0.7175 - val_acc: 0.8008\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_082732-4yi1xjzb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_082732-4yi1xjzb/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "200/200 [==============================] - 38s 192ms/step - loss: 0.2290 - acc: 0.9274 - val_loss: 0.8550 - val_acc: 0.7808\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 0.2121 - acc: 0.9309 - val_loss: 0.7065 - val_acc: 0.8073\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_082732-4yi1xjzb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_082732-4yi1xjzb/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30\n",
      "200/200 [==============================] - 34s 169ms/step - loss: 0.2321 - acc: 0.9237 - val_loss: 0.7802 - val_acc: 0.7893\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 0.2170 - acc: 0.9275 - val_loss: 0.8611 - val_acc: 0.7823\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 36s 182ms/step - loss: 0.1956 - acc: 0.9362 - val_loss: 0.7878 - val_acc: 0.8173\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 0.1818 - acc: 0.9408 - val_loss: 0.8475 - val_acc: 0.7798\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 36s 182ms/step - loss: 0.1475 - acc: 0.9524 - val_loss: 0.7123 - val_acc: 0.8188\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 0.1533 - acc: 0.9520 - val_loss: 1.1349 - val_acc: 0.7683\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 0.1790 - acc: 0.9408 - val_loss: 0.9401 - val_acc: 0.7908\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 0.1187 - acc: 0.9623 - val_loss: 0.9732 - val_acc: 0.7968\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 36s 183ms/step - loss: 0.1487 - acc: 0.9518 - val_loss: 0.7826 - val_acc: 0.8243\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 0.1438 - acc: 0.9535 - val_loss: 0.8257 - val_acc: 0.8098\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 0.1434 - acc: 0.9529 - val_loss: 0.9587 - val_acc: 0.7978\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 46s 232ms/step - loss: 0.1239 - acc: 0.9581 - val_loss: 1.0231 - val_acc: 0.7908\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 0.1260 - acc: 0.9576 - val_loss: 1.0937 - val_acc: 0.7928ss: 0.1260 - \n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 36s 182ms/step - loss: 0.1235 - acc: 0.9634 - val_loss: 1.0328 - val_acc: 0.8113\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 36s 182ms/step - loss: 0.1347 - acc: 0.9607 - val_loss: 0.8183 - val_acc: 0.8193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='34.390 MB of 34.393 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.9999…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▅▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▅▆▆▆▇▇▆▆▇▇█▇█▇▇█▇█▇▇▇███▇▇██</td></tr><tr><td>val_loss</td><td>█▂▂▂▂▁▁▂▂▂▁▁▁▁▁▁▁▁▁▁▂▂▂▁▁▂▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03933</td></tr><tr><td>acc</td><td>0.9623</td></tr><tr><td>best_epoch</td><td>14</td></tr><tr><td>best_val_loss</td><td>0.70652</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.1245</td></tr><tr><td>val_acc</td><td>0.81932</td></tr><tr><td>val_loss</td><td>0.81833</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">devout-sweep-33</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/4yi1xjzb\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/4yi1xjzb</a><br/>Synced 6 W&B file(s), 2 media file(s), 32 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_082732-4yi1xjzb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mt1iy7s7 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_084814-mt1iy7s7</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/mt1iy7s7\" target=\"_blank\">lively-sweep-34</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               245888    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 463,242\n",
      "Trainable params: 462,474\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 37s 181ms/step - loss: 2.1371 - acc: 0.3934 - val_loss: 2.6322 - val_acc: 0.4219\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_084814-mt1iy7s7/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_084814-mt1iy7s7/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 35s 173ms/step - loss: 1.2891 - acc: 0.5805 - val_loss: 1.7024 - val_acc: 0.5586\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_084814-mt1iy7s7/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_084814-mt1iy7s7/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 1.0041 - acc: 0.6599 - val_loss: 1.1082 - val_acc: 0.6587\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_084814-mt1iy7s7/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_084814-mt1iy7s7/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "200/200 [==============================] - 34s 168ms/step - loss: 0.7542 - acc: 0.7455 - val_loss: 1.1399 - val_acc: 0.6702\n",
      "Epoch 5/30\n",
      "200/200 [==============================] - 34s 168ms/step - loss: 0.6954 - acc: 0.7682 - val_loss: 1.0547 - val_acc: 0.6662\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_084814-mt1iy7s7/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_084814-mt1iy7s7/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "200/200 [==============================] - 33s 167ms/step - loss: 0.5642 - acc: 0.8108 - val_loss: 1.2236 - val_acc: 0.6517\n",
      "Epoch 7/30\n",
      "200/200 [==============================] - 34s 169ms/step - loss: 0.4884 - acc: 0.8310 - val_loss: 0.9940 - val_acc: 0.6782\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_084814-mt1iy7s7/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_084814-mt1iy7s7/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "200/200 [==============================] - 38s 190ms/step - loss: 0.4251 - acc: 0.8627 - val_loss: 0.8238 - val_acc: 0.7728\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_084814-mt1iy7s7/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_084814-mt1iy7s7/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 0.3718 - acc: 0.8695 - val_loss: 0.7551 - val_acc: 0.7763\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_084814-mt1iy7s7/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_084814-mt1iy7s7/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "200/200 [==============================] - 35s 177ms/step - loss: 0.3294 - acc: 0.8898 - val_loss: 0.7985 - val_acc: 0.7643\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 0.3056 - acc: 0.8973 - val_loss: 1.0610 - val_acc: 0.7317\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 0.2688 - acc: 0.9050 - val_loss: 0.8982 - val_acc: 0.7718\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 33s 165ms/step - loss: 0.2507 - acc: 0.9186 - val_loss: 1.0789 - val_acc: 0.7508\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 34s 172ms/step - loss: 0.2073 - acc: 0.9319 - val_loss: 0.8376 - val_acc: 0.7853\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 0.1954 - acc: 0.9354 - val_loss: 0.8474 - val_acc: 0.7748\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 0.1994 - acc: 0.9389 - val_loss: 1.0778 - val_acc: 0.7482\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 0.1744 - acc: 0.9443 - val_loss: 0.9713 - val_acc: 0.7873\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 35s 178ms/step - loss: 0.1779 - acc: 0.9451 - val_loss: 0.7636 - val_acc: 0.8143\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 34s 172ms/step - loss: 0.1802 - acc: 0.9450 - val_loss: 0.8640 - val_acc: 0.8063\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 0.1562 - acc: 0.9533 - val_loss: 1.0197 - val_acc: 0.7943\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 0.1494 - acc: 0.9513 - val_loss: 0.8417 - val_acc: 0.8108\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 0.1607 - acc: 0.9516 - val_loss: 0.9306 - val_acc: 0.7788\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 34s 172ms/step - loss: 0.1167 - acc: 0.9590 - val_loss: 0.8379 - val_acc: 0.8178\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 0.1360 - acc: 0.9591 - val_loss: 1.0709 - val_acc: 0.8028\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 46s 229ms/step - loss: 0.1074 - acc: 0.9630 - val_loss: 0.8882 - val_acc: 0.8083\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 0.1279 - acc: 0.9610 - val_loss: 1.1290 - val_acc: 0.7578\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 35s 177ms/step - loss: 0.1353 - acc: 0.9581 - val_loss: 0.8612 - val_acc: 0.8268\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 35s 177ms/step - loss: 0.1102 - acc: 0.9649 - val_loss: 1.3418 - val_acc: 0.7928\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 0.0966 - acc: 0.9710 - val_loss: 0.9532 - val_acc: 0.8098\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 35s 177ms/step - loss: 0.0920 - acc: 0.9683 - val_loss: 0.9453 - val_acc: 0.8273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='34.156 MB of 34.159 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.9999…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇▇▇▇██████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▅▄▃▃▃▂▂▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▅▅▅▅▅▇▇▇▆▇▇▇▇▇▇██▇█▇███▇█▇██</td></tr><tr><td>val_loss</td><td>█▅▂▂▂▃▂▁▁▁▂▂▂▁▁▂▂▁▁▂▁▂▁▂▁▂▁▃▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03946</td></tr><tr><td>acc</td><td>0.96621</td></tr><tr><td>best_epoch</td><td>8</td></tr><tr><td>best_val_loss</td><td>0.75511</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.10329</td></tr><tr><td>val_acc</td><td>0.82733</td></tr><tr><td>val_loss</td><td>0.9453</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">lively-sweep-34</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/mt1iy7s7\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/mt1iy7s7</a><br/>Synced 6 W&B file(s), 2 media file(s), 23 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_084814-mt1iy7s7/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: u72hq8e6 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_090700-u72hq8e6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/u72hq8e6\" target=\"_blank\">generous-sweep-35</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                122944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 339,658\n",
      "Trainable params: 338,890\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 2.0508 - acc: 0.3848 - val_loss: 3.2642 - val_acc: 0.3724\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_090700-u72hq8e6/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_090700-u72hq8e6/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 1.2792 - acc: 0.5608 - val_loss: 1.1612 - val_acc: 0.5871\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_090700-u72hq8e6/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_090700-u72hq8e6/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 34s 169ms/step - loss: 1.0143 - acc: 0.6458 - val_loss: 0.9115 - val_acc: 0.6967\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_090700-u72hq8e6/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_090700-u72hq8e6/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "200/200 [==============================] - 34s 172ms/step - loss: 0.8667 - acc: 0.7075 - val_loss: 1.1051 - val_acc: 0.6677\n",
      "Epoch 5/30\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 0.6958 - acc: 0.7630 - val_loss: 0.9696 - val_acc: 0.6957\n",
      "Epoch 6/30\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 0.6122 - acc: 0.7832 - val_loss: 0.9193 - val_acc: 0.7022\n",
      "Epoch 7/30\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 0.5776 - acc: 0.8145 - val_loss: 0.7692 - val_acc: 0.7603\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_090700-u72hq8e6/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_090700-u72hq8e6/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 0.5086 - acc: 0.8239 - val_loss: 0.8939 - val_acc: 0.7472\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 0.4349 - acc: 0.8499 - val_loss: 0.7531 - val_acc: 0.7492\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_090700-u72hq8e6/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_090700-u72hq8e6/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 0.3944 - acc: 0.8600 - val_loss: 0.8464 - val_acc: 0.7482\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 33s 165ms/step - loss: 0.3657 - acc: 0.8769 - val_loss: 0.9220 - val_acc: 0.7362\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 0.3170 - acc: 0.8917 - val_loss: 0.8248 - val_acc: 0.7793\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 37s 187ms/step - loss: 0.3090 - acc: 0.8959 - val_loss: 0.6988 - val_acc: 0.8058\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_090700-u72hq8e6/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_090700-u72hq8e6/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 0.2499 - acc: 0.9149 - val_loss: 1.0604 - val_acc: 0.7417\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 0.2510 - acc: 0.9114 - val_loss: 0.8047 - val_acc: 0.7603\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 0.2531 - acc: 0.9126 - val_loss: 0.7532 - val_acc: 0.7788\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 0.2020 - acc: 0.9325 - val_loss: 1.2144 - val_acc: 0.7127\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 0.2281 - acc: 0.9279 - val_loss: 0.8397 - val_acc: 0.7843\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 0.1864 - acc: 0.9358 - val_loss: 0.7548 - val_acc: 0.8073\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 0.1676 - acc: 0.9386 - val_loss: 0.7284 - val_acc: 0.8173\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 0.1745 - acc: 0.9440 - val_loss: 0.9210 - val_acc: 0.7848\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 0.1589 - acc: 0.9455 - val_loss: 0.9182 - val_acc: 0.7738\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 0.1557 - acc: 0.9473 - val_loss: 0.8467 - val_acc: 0.7903\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 0.1547 - acc: 0.9553 - val_loss: 0.7852 - val_acc: 0.8043\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 34s 170ms/step - loss: 0.1656 - acc: 0.9471 - val_loss: 0.8698 - val_acc: 0.7773\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 0.1457 - acc: 0.9546 - val_loss: 0.7747 - val_acc: 0.8133\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 36s 182ms/step - loss: 0.1744 - acc: 0.9410 - val_loss: 0.9097 - val_acc: 0.7858\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 38s 188ms/step - loss: 0.1375 - acc: 0.9545 - val_loss: 0.8937 - val_acc: 0.8113\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 0.1308 - acc: 0.9553 - val_loss: 0.9087 - val_acc: 0.8098\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 0.1243 - acc: 0.9586 - val_loss: 0.9501 - val_acc: 0.7973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='22.764 MB of 22.767 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.9998…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▅▆▆▆▆▇▇▇▇▇▇▇██████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▅▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▆▆▆▆▇▇▇▇▇▇█▇▇▇▆▇██▇▇██▇█████</td></tr><tr><td>val_loss</td><td>█▂▂▂▂▂▁▂▁▁▂▁▁▂▁▁▂▁▁▁▂▂▁▁▁▁▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03933</td></tr><tr><td>acc</td><td>0.95558</td></tr><tr><td>best_epoch</td><td>12</td></tr><tr><td>best_val_loss</td><td>0.69881</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.14328</td></tr><tr><td>val_acc</td><td>0.7973</td></tr><tr><td>val_loss</td><td>0.95011</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">generous-sweep-35</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/u72hq8e6\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/u72hq8e6</a><br/>Synced 6 W&B file(s), 2 media file(s), 20 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_090700-u72hq8e6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: ebw8rm2s with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_092541-ebw8rm2s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/ebw8rm2s\" target=\"_blank\">gallant-sweep-36</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                122944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 339,658\n",
      "Trainable params: 338,890\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 38s 184ms/step - loss: 1.9610 - acc: 0.4006 - val_loss: 2.5486 - val_acc: 0.3859\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_092541-ebw8rm2s/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_092541-ebw8rm2s/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 1.2704 - acc: 0.5774 - val_loss: 1.2996 - val_acc: 0.6191\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_092541-ebw8rm2s/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_092541-ebw8rm2s/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 0.9442 - acc: 0.6786 - val_loss: 1.2541 - val_acc: 0.6166\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_092541-ebw8rm2s/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_092541-ebw8rm2s/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "200/200 [==============================] - 34s 172ms/step - loss: 0.7940 - acc: 0.7246 - val_loss: 0.9251 - val_acc: 0.6932\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_092541-ebw8rm2s/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_092541-ebw8rm2s/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "200/200 [==============================] - 33s 165ms/step - loss: 0.6949 - acc: 0.7728 - val_loss: 0.8134 - val_acc: 0.7297\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_092541-ebw8rm2s/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_092541-ebw8rm2s/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "200/200 [==============================] - 46s 233ms/step - loss: 0.5590 - acc: 0.8124 - val_loss: 1.0795 - val_acc: 0.6582\n",
      "Epoch 7/30\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 0.5034 - acc: 0.8224 - val_loss: 0.8447 - val_acc: 0.7392\n",
      "Epoch 8/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.4795 - acc: 0.8400 - val_loss: 0.8086 - val_acc: 0.7673\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_092541-ebw8rm2s/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_092541-ebw8rm2s/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 0.3984 - acc: 0.8610 - val_loss: 0.9984 - val_acc: 0.7377\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 0.3715 - acc: 0.8665 - val_loss: 0.9399 - val_acc: 0.7497\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 0.3365 - acc: 0.8858 - val_loss: 0.8823 - val_acc: 0.7523\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 0.2961 - acc: 0.8948 - val_loss: 0.9639 - val_acc: 0.7708\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 0.2996 - acc: 0.9001 - val_loss: 0.7053 - val_acc: 0.8068\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_092541-ebw8rm2s/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_092541-ebw8rm2s/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30\n",
      "200/200 [==============================] - 34s 168ms/step - loss: 0.2435 - acc: 0.9174 - val_loss: 0.8973 - val_acc: 0.7758\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.2263 - acc: 0.9269 - val_loss: 0.7210 - val_acc: 0.8033\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.2335 - acc: 0.9209 - val_loss: 0.7501 - val_acc: 0.7958\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 34s 168ms/step - loss: 0.2130 - acc: 0.9262 - val_loss: 0.7164 - val_acc: 0.8188\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.2127 - acc: 0.9286 - val_loss: 0.8478 - val_acc: 0.7783\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 0.1918 - acc: 0.9341 - val_loss: 0.8284 - val_acc: 0.8048\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 33s 167ms/step - loss: 0.1612 - acc: 0.9457 - val_loss: 0.9461 - val_acc: 0.7848\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 32s 160ms/step - loss: 0.1803 - acc: 0.9417 - val_loss: 0.7862 - val_acc: 0.8313\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 34s 172ms/step - loss: 0.1448 - acc: 0.9534 - val_loss: 0.7729 - val_acc: 0.8223\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 0.1692 - acc: 0.9436 - val_loss: 0.8263 - val_acc: 0.8108\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 0.1608 - acc: 0.9495 - val_loss: 0.7596 - val_acc: 0.8193\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 0.1409 - acc: 0.9551 - val_loss: 0.8208 - val_acc: 0.7923\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 34s 171ms/step - loss: 0.1231 - acc: 0.9604 - val_loss: 0.9295 - val_acc: 0.8078\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 32s 163ms/step - loss: 0.1113 - acc: 0.9629 - val_loss: 0.9789 - val_acc: 0.8013\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 32s 163ms/step - loss: 0.1273 - acc: 0.9599 - val_loss: 0.9263 - val_acc: 0.8208\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 35s 173ms/step - loss: 0.1228 - acc: 0.9570 - val_loss: 0.9345 - val_acc: 0.8133\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 0.1146 - acc: 0.9620 - val_loss: 0.9465 - val_acc: 0.8278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='25.673 MB of 25.673 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇▇▇▇▇█████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▅▄▄▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▅▅▆▆▅▇▇▇▇▇▇█▇█▇█▇█▇████▇█████</td></tr><tr><td>val_loss</td><td>█▃▃▂▁▂▂▁▂▂▂▂▁▂▁▁▁▂▁▂▁▁▁▁▁▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03933</td></tr><tr><td>acc</td><td>0.95964</td></tr><tr><td>best_epoch</td><td>12</td></tr><tr><td>best_val_loss</td><td>0.7053</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.12438</td></tr><tr><td>val_acc</td><td>0.82783</td></tr><tr><td>val_loss</td><td>0.9465</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">gallant-sweep-36</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/ebw8rm2s\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/ebw8rm2s</a><br/>Synced 6 W&B file(s), 2 media file(s), 23 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_092541-ebw8rm2s/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 3pdyz4mb with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_094415-3pdyz4mb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/3pdyz4mb\" target=\"_blank\">valiant-sweep-37</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                122944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 339,658\n",
      "Trainable params: 338,890\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 34s 165ms/step - loss: 1.9529 - acc: 0.3981 - val_loss: 1.9150 - val_acc: 0.4920\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_094415-3pdyz4mb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_094415-3pdyz4mb/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 1.1665 - acc: 0.6068 - val_loss: 1.4684 - val_acc: 0.5465\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_094415-3pdyz4mb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_094415-3pdyz4mb/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 0.8750 - acc: 0.6985 - val_loss: 1.0729 - val_acc: 0.6827\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_094415-3pdyz4mb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_094415-3pdyz4mb/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 0.7209 - acc: 0.7565 - val_loss: 1.0386 - val_acc: 0.6767\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_094415-3pdyz4mb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_094415-3pdyz4mb/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "200/200 [==============================] - 33s 166ms/step - loss: 0.6054 - acc: 0.7929 - val_loss: 1.1386 - val_acc: 0.6271\n",
      "Epoch 6/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.5008 - acc: 0.8312 - val_loss: 0.8266 - val_acc: 0.7618\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_094415-3pdyz4mb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_094415-3pdyz4mb/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.4198 - acc: 0.8549 - val_loss: 0.7724 - val_acc: 0.7508\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_094415-3pdyz4mb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_094415-3pdyz4mb/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.3577 - acc: 0.8822 - val_loss: 1.0674 - val_acc: 0.7122\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 33s 166ms/step - loss: 0.3110 - acc: 0.8926 - val_loss: 0.8778 - val_acc: 0.7623\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 0.2819 - acc: 0.9055 - val_loss: 0.8874 - val_acc: 0.7618\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 35s 173ms/step - loss: 0.2426 - acc: 0.9175 - val_loss: 0.9027 - val_acc: 0.7568\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 34s 170ms/step - loss: 0.2160 - acc: 0.9264 - val_loss: 1.1163 - val_acc: 0.7282\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 35s 177ms/step - loss: 0.2040 - acc: 0.9306 - val_loss: 0.8222 - val_acc: 0.7763\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 0.1961 - acc: 0.9380 - val_loss: 0.7409 - val_acc: 0.8053\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_094415-3pdyz4mb/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_094415-3pdyz4mb/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 0.1766 - acc: 0.9418 - val_loss: 0.7570 - val_acc: 0.8038\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 35s 173ms/step - loss: 0.1638 - acc: 0.9424 - val_loss: 0.7804 - val_acc: 0.8208\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 34s 168ms/step - loss: 0.1538 - acc: 0.9483 - val_loss: 0.8549 - val_acc: 0.7993\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 33s 162ms/step - loss: 0.1339 - acc: 0.9561 - val_loss: 0.8545 - val_acc: 0.8133\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.1230 - acc: 0.9576 - val_loss: 0.7872 - val_acc: 0.8293\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 0.1412 - acc: 0.9544 - val_loss: 0.7590 - val_acc: 0.8218\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 33s 166ms/step - loss: 0.1465 - acc: 0.9559 - val_loss: 0.9164 - val_acc: 0.8058\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 0.1155 - acc: 0.9614 - val_loss: 0.8409 - val_acc: 0.8043\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 34s 169ms/step - loss: 0.1142 - acc: 0.9640 - val_loss: 0.9819 - val_acc: 0.7858\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 0.1144 - acc: 0.9640 - val_loss: 0.9587 - val_acc: 0.8053\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 36s 180ms/step - loss: 0.0969 - acc: 0.9663 - val_loss: 0.8438 - val_acc: 0.8253\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 33s 165ms/step - loss: 0.0916 - acc: 0.9682 - val_loss: 1.1136 - val_acc: 0.7898\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 33s 166ms/step - loss: 0.1322 - acc: 0.9614 - val_loss: 0.8974 - val_acc: 0.8283\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 0.1167 - acc: 0.9647 - val_loss: 0.8270 - val_acc: 0.8283\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 0.1204 - acc: 0.9651 - val_loss: 0.8595 - val_acc: 0.8258\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 35s 177ms/step - loss: 0.0870 - acc: 0.9717 - val_loss: 0.9737 - val_acc: 0.8088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='25.673 MB of 25.673 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▆▆▆▇▇▇▇▇▇▇████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▅▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▂▅▅▄▇▆▆▇▇▆▆▇█▇█▇████▇▇██▇████</td></tr><tr><td>val_loss</td><td>█▅▃▃▃▂▁▃▂▂▂▃▁▁▁▁▂▂▁▁▂▂▂▂▂▃▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03933</td></tr><tr><td>acc</td><td>0.96793</td></tr><tr><td>best_epoch</td><td>13</td></tr><tr><td>best_val_loss</td><td>0.74089</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.09322</td></tr><tr><td>val_acc</td><td>0.80881</td></tr><tr><td>val_loss</td><td>0.97372</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">valiant-sweep-37</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/3pdyz4mb\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/3pdyz4mb</a><br/>Synced 6 W&B file(s), 2 media file(s), 23 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_094415-3pdyz4mb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: diatrurv with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_100212-diatrurv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/diatrurv\" target=\"_blank\">clear-sweep-38</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                122944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 339,658\n",
      "Trainable params: 338,890\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 35s 170ms/step - loss: 1.9389 - acc: 0.4120 - val_loss: 1.7807 - val_acc: 0.5040\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_100212-diatrurv/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_100212-diatrurv/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 33s 165ms/step - loss: 1.1664 - acc: 0.6006 - val_loss: 1.6467 - val_acc: 0.5836\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_100212-diatrurv/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_100212-diatrurv/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 34s 172ms/step - loss: 0.9258 - acc: 0.6779 - val_loss: 1.0968 - val_acc: 0.6557\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_100212-diatrurv/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_100212-diatrurv/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 0.7358 - acc: 0.7465 - val_loss: 0.8510 - val_acc: 0.7222\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_100212-diatrurv/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_100212-diatrurv/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "200/200 [==============================] - 34s 169ms/step - loss: 0.6049 - acc: 0.7878 - val_loss: 0.9605 - val_acc: 0.7247\n",
      "Epoch 6/30\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 0.5115 - acc: 0.8182 - val_loss: 0.8587 - val_acc: 0.7467\n",
      "Epoch 7/30\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 0.4323 - acc: 0.8511 - val_loss: 0.8309 - val_acc: 0.7513\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_100212-diatrurv/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_100212-diatrurv/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "200/200 [==============================] - 35s 177ms/step - loss: 0.3880 - acc: 0.8665 - val_loss: 1.1400 - val_acc: 0.6927\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 35s 173ms/step - loss: 0.3378 - acc: 0.8864 - val_loss: 0.6695 - val_acc: 0.7913\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_100212-diatrurv/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_100212-diatrurv/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 0.2853 - acc: 0.9060 - val_loss: 0.7743 - val_acc: 0.7718\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 0.2755 - acc: 0.9100 - val_loss: 0.8588 - val_acc: 0.7628\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 0.2339 - acc: 0.9220 - val_loss: 0.7279 - val_acc: 0.8043\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 34s 169ms/step - loss: 0.2122 - acc: 0.9228 - val_loss: 0.6996 - val_acc: 0.8033\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 35s 177ms/step - loss: 0.1915 - acc: 0.9346 - val_loss: 0.7847 - val_acc: 0.8028\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 43s 216ms/step - loss: 0.1910 - acc: 0.9356 - val_loss: 1.2181 - val_acc: 0.7052\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 48s 240ms/step - loss: 0.1839 - acc: 0.9425 - val_loss: 1.4029 - val_acc: 0.7347\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 47s 234ms/step - loss: 0.1853 - acc: 0.9386 - val_loss: 0.9208 - val_acc: 0.7718\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 35s 177ms/step - loss: 0.1549 - acc: 0.9486 - val_loss: 0.8713 - val_acc: 0.8073\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 40s 201ms/step - loss: 0.1439 - acc: 0.9543 - val_loss: 0.8884 - val_acc: 0.8008\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 0.1411 - acc: 0.9538 - val_loss: 0.9014 - val_acc: 0.7903 - lo\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 0.1292 - acc: 0.9612 - val_loss: 0.8579 - val_acc: 0.7963\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 43s 217ms/step - loss: 0.1452 - acc: 0.9565 - val_loss: 1.1750 - val_acc: 0.7968\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 0.1316 - acc: 0.9549 - val_loss: 1.1281 - val_acc: 0.7693\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 0.1218 - acc: 0.9603 - val_loss: 1.2252 - val_acc: 0.7573\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 0.1183 - acc: 0.9608 - val_loss: 0.8580 - val_acc: 0.8058\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 46s 231ms/step - loss: 0.1142 - acc: 0.9648 - val_loss: 1.0188 - val_acc: 0.7948\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 38s 192ms/step - loss: 0.1062 - acc: 0.9697 - val_loss: 0.8994 - val_acc: 0.8048\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 33s 165ms/step - loss: 0.1080 - acc: 0.9662 - val_loss: 1.1211 - val_acc: 0.7773\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 34s 171ms/step - loss: 0.1094 - acc: 0.9645 - val_loss: 0.9547 - val_acc: 0.7958\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 37s 185ms/step - loss: 0.0883 - acc: 0.9689 - val_loss: 0.8881 - val_acc: 0.8083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='22.767 MB of 22.767 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇▇████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▅▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▄▆▆▇▇▅█▇▇███▆▆▇█████▇▇███▇██</td></tr><tr><td>val_loss</td><td>█▇▄▂▃▂▂▄▁▂▂▁▁▂▄▆▃▂▂▂▂▄▄▅▂▃▂▄▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03933</td></tr><tr><td>acc</td><td>0.9634</td></tr><tr><td>best_epoch</td><td>8</td></tr><tr><td>best_val_loss</td><td>0.6695</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.10936</td></tr><tr><td>val_acc</td><td>0.80831</td></tr><tr><td>val_loss</td><td>0.88812</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">clear-sweep-38</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/diatrurv\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/diatrurv</a><br/>Synced 6 W&B file(s), 2 media file(s), 20 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_100212-diatrurv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7zpisqlg with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_102147-7zpisqlg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/7zpisqlg\" target=\"_blank\">happy-sweep-39</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               245888    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 463,242\n",
      "Trainable params: 462,474\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 35s 170ms/step - loss: 2.0754 - acc: 0.3989 - val_loss: 2.2629 - val_acc: 0.4104\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_102147-7zpisqlg/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_102147-7zpisqlg/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 39s 195ms/step - loss: 1.1995 - acc: 0.5950 - val_loss: 1.4875 - val_acc: 0.5716\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_102147-7zpisqlg/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_102147-7zpisqlg/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 0.9035 - acc: 0.6976 - val_loss: 0.9696 - val_acc: 0.7042\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_102147-7zpisqlg/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_102147-7zpisqlg/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "200/200 [==============================] - 34s 170ms/step - loss: 0.7307 - acc: 0.7440 - val_loss: 0.8647 - val_acc: 0.7097\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_102147-7zpisqlg/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_102147-7zpisqlg/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "200/200 [==============================] - 37s 184ms/step - loss: 0.5982 - acc: 0.7947 - val_loss: 0.9884 - val_acc: 0.7227\n",
      "Epoch 6/30\n",
      "200/200 [==============================] - 39s 197ms/step - loss: 0.4651 - acc: 0.8333 - val_loss: 1.2856 - val_acc: 0.6617\n",
      "Epoch 7/30\n",
      "200/200 [==============================] - 42s 208ms/step - loss: 0.4173 - acc: 0.8644 - val_loss: 0.7822 - val_acc: 0.7563\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_102147-7zpisqlg/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_102147-7zpisqlg/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30\n",
      "200/200 [==============================] - 39s 194ms/step - loss: 0.3428 - acc: 0.8838 - val_loss: 1.1161 - val_acc: 0.7332\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 0.2838 - acc: 0.9047 - val_loss: 0.8210 - val_acc: 0.7763\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - 34s 170ms/step - loss: 0.2573 - acc: 0.9173 - val_loss: 0.8793 - val_acc: 0.7738\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 39s 196ms/step - loss: 0.2384 - acc: 0.9196 - val_loss: 0.6803 - val_acc: 0.7913\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_102147-7zpisqlg/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_102147-7zpisqlg/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30\n",
      "200/200 [==============================] - 41s 207ms/step - loss: 0.1945 - acc: 0.9369 - val_loss: 0.9928 - val_acc: 0.7668\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 47s 235ms/step - loss: 0.1911 - acc: 0.9380 - val_loss: 0.9971 - val_acc: 0.7788\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 49s 244ms/step - loss: 0.1770 - acc: 0.9423 - val_loss: 1.0110 - val_acc: 0.7548\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 49s 247ms/step - loss: 0.1750 - acc: 0.9426 - val_loss: 0.8116 - val_acc: 0.7913\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 44s 221ms/step - loss: 0.1429 - acc: 0.9538 - val_loss: 0.9912 - val_acc: 0.7808\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 46s 232ms/step - loss: 0.1468 - acc: 0.9497 - val_loss: 0.9020 - val_acc: 0.7988\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 42s 209ms/step - loss: 0.1110 - acc: 0.9660 - val_loss: 0.8651 - val_acc: 0.7953\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 0.1364 - acc: 0.9578 - val_loss: 1.0083 - val_acc: 0.7728\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 0.1221 - acc: 0.9605 - val_loss: 0.8119 - val_acc: 0.8118\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 0.1086 - acc: 0.9652 - val_loss: 0.9435 - val_acc: 0.7948\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 0.1113 - acc: 0.9638 - val_loss: 1.0514 - val_acc: 0.7873\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 41s 206ms/step - loss: 0.1012 - acc: 0.9642 - val_loss: 1.0195 - val_acc: 0.8038\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 0.0956 - acc: 0.9690 - val_loss: 0.9468 - val_acc: 0.8198\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 45s 227ms/step - loss: 0.1162 - acc: 0.9612 - val_loss: 1.1616 - val_acc: 0.7863\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 42s 212ms/step - loss: 0.0868 - acc: 0.9733 - val_loss: 0.9515 - val_acc: 0.8048\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 0.0881 - acc: 0.9706 - val_loss: 1.0103 - val_acc: 0.7978\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 0.0843 - acc: 0.9743 - val_loss: 1.2638 - val_acc: 0.7753\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 0.0885 - acc: 0.9722 - val_loss: 1.0248 - val_acc: 0.8013\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 41s 204ms/step - loss: 0.0933 - acc: 0.9725 - val_loss: 0.9749 - val_acc: 0.8163\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='30.309 MB of 30.309 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, m…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▆▆▆▇▇▇▇▇▇█████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▄▄▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▆▆▆▅▇▇▇▇█▇▇▇█▇██▇██▇██▇██▇██</td></tr><tr><td>val_loss</td><td>█▅▂▂▂▄▁▃▂▂▁▂▂▂▂▂▂▂▂▂▂▃▃▂▃▂▂▄▃▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03946</td></tr><tr><td>acc</td><td>0.97263</td></tr><tr><td>best_epoch</td><td>10</td></tr><tr><td>best_val_loss</td><td>0.68031</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.08976</td></tr><tr><td>val_acc</td><td>0.81632</td></tr><tr><td>val_loss</td><td>0.97489</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">happy-sweep-39</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/7zpisqlg\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/7zpisqlg</a><br/>Synced 6 W&B file(s), 2 media file(s), 20 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_102147-7zpisqlg/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: zxtxq1iu with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_104319-zxtxq1iu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/zxtxq1iu\" target=\"_blank\">tough-sweep-40</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               245888    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 463,242\n",
      "Trainable params: 462,474\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 46s 225ms/step - loss: 2.1104 - acc: 0.3742 - val_loss: 2.1981 - val_acc: 0.3999\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_104319-zxtxq1iu/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_104319-zxtxq1iu/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 38s 192ms/step - loss: 1.2290 - acc: 0.5886 - val_loss: 1.5417 - val_acc: 0.5571\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_104319-zxtxq1iu/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_104319-zxtxq1iu/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 0.9882 - acc: 0.6633 - val_loss: 1.0660 - val_acc: 0.6567\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_104319-zxtxq1iu/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_104319-zxtxq1iu/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "200/200 [==============================] - 42s 210ms/step - loss: 0.7692 - acc: 0.7279 - val_loss: 1.0884 - val_acc: 0.6782\n",
      "Epoch 5/30\n",
      "200/200 [==============================] - 41s 205ms/step - loss: 0.6481 - acc: 0.7834 - val_loss: 1.1920 - val_acc: 0.6667\n",
      "Epoch 6/30\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 0.5583 - acc: 0.8114 - val_loss: 0.8154 - val_acc: 0.7472\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_104319-zxtxq1iu/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_104319-zxtxq1iu/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30\n",
      "200/200 [==============================] - 45s 227ms/step - loss: 0.4592 - acc: 0.8351 - val_loss: 1.0284 - val_acc: 0.6952\n",
      "Epoch 8/30\n",
      "200/200 [==============================] - 47s 236ms/step - loss: 0.4385 - acc: 0.8468 - val_loss: 0.7589 - val_acc: 0.7823\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_104319-zxtxq1iu/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_104319-zxtxq1iu/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 0.3841 - acc: 0.8666 - val_loss: 0.9429 - val_acc: 0.7362\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 0.3052 - acc: 0.8965 - val_loss: 0.9245 - val_acc: 0.7563\n",
      "Epoch 11/30\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 0.2893 - acc: 0.9011 - val_loss: 0.9138 - val_acc: 0.7608\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 0.2483 - acc: 0.9184 - val_loss: 0.8763 - val_acc: 0.7738\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 0.2420 - acc: 0.9191 - val_loss: 0.9762 - val_acc: 0.7337\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 40s 199ms/step - loss: 0.2268 - acc: 0.9246 - val_loss: 0.8411 - val_acc: 0.7888\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 47s 237ms/step - loss: 0.1962 - acc: 0.9373 - val_loss: 0.7828 - val_acc: 0.8123\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 44s 219ms/step - loss: 0.1970 - acc: 0.9366 - val_loss: 0.8159 - val_acc: 0.8058\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 0.1582 - acc: 0.9477 - val_loss: 1.0837 - val_acc: 0.7503\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 35s 175ms/step - loss: 0.1593 - acc: 0.9439 - val_loss: 1.0503 - val_acc: 0.7973\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 0.1626 - acc: 0.9476 - val_loss: 1.2714 - val_acc: 0.7703\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 41s 203ms/step - loss: 0.1575 - acc: 0.9505 - val_loss: 1.0756 - val_acc: 0.7788\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 46s 228ms/step - loss: 0.1582 - acc: 0.9524 - val_loss: 0.8437 - val_acc: 0.8108\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 37s 183ms/step - loss: 0.1470 - acc: 0.9511 - val_loss: 0.8765 - val_acc: 0.7803\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 38s 192ms/step - loss: 0.1732 - acc: 0.9479 - val_loss: 0.7566 - val_acc: 0.8193\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_104319-zxtxq1iu/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_104319-zxtxq1iu/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30\n",
      "200/200 [==============================] - 36s 181ms/step - loss: 0.1312 - acc: 0.9582 - val_loss: 1.0606 - val_acc: 0.7823\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 38s 192ms/step - loss: 0.1425 - acc: 0.9562 - val_loss: 0.7791 - val_acc: 0.8233\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 0.1113 - acc: 0.9680 - val_loss: 0.8158 - val_acc: 0.8213\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 36s 179ms/step - loss: 0.1083 - acc: 0.9685 - val_loss: 1.0219 - val_acc: 0.8078\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 37s 186ms/step - loss: 0.1058 - acc: 0.9652 - val_loss: 1.1457 - val_acc: 0.7973\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 36s 182ms/step - loss: 0.1062 - acc: 0.9673 - val_loss: 0.9881 - val_acc: 0.7948\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 36s 182ms/step - loss: 0.1014 - acc: 0.9691 - val_loss: 1.0637 - val_acc: 0.8033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='30.307 MB of 30.309 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.9999…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇▇▇███████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▅▄▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▅▆▅▇▆▇▇▇▇▇▇▇██▇█▇▇█▇█▇██████</td></tr><tr><td>val_loss</td><td>█▅▃▃▃▁▂▁▂▂▂▂▂▁▁▁▃▂▄▃▁▂▁▂▁▁▂▃▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03946</td></tr><tr><td>acc</td><td>0.96684</td></tr><tr><td>best_epoch</td><td>22</td></tr><tr><td>best_val_loss</td><td>0.75661</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.1117</td></tr><tr><td>val_acc</td><td>0.8033</td></tr><tr><td>val_loss</td><td>1.0637</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">tough-sweep-40</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/zxtxq1iu\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/zxtxq1iu</a><br/>Synced 6 W&B file(s), 2 media file(s), 20 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_104319-zxtxq1iu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: mitmn8vd with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tconv_layer_size: 128\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.001\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_110419-mitmn8vd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/mitmn8vd\" target=\"_blank\">colorful-sweep-41</a></strong> to <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/sweeps/auytih7y</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 123, 11, 128)      1280      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 62, 6, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 62, 6, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 60, 4, 128)        147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 2, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 30, 2, 128)        512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 29, 1, 128)        65664     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 15, 1, 128)        512       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 15, 1, 128)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                122944    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 339,658\n",
      "Trainable params: 338,890\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "200/200 [==============================] - 48s 234ms/step - loss: 1.9987 - acc: 0.3864 - val_loss: 2.0666 - val_acc: 0.4334\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_110419-mitmn8vd/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_110419-mitmn8vd/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30\n",
      "200/200 [==============================] - 43s 214ms/step - loss: 1.2049 - acc: 0.5810 - val_loss: 1.3950 - val_acc: 0.5996\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_110419-mitmn8vd/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_110419-mitmn8vd/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30\n",
      "200/200 [==============================] - 44s 218ms/step - loss: 0.9129 - acc: 0.6937 - val_loss: 1.1566 - val_acc: 0.6371\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_110419-mitmn8vd/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_110419-mitmn8vd/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30\n",
      "200/200 [==============================] - 43s 217ms/step - loss: 0.7336 - acc: 0.7485 - val_loss: 0.8922 - val_acc: 0.7082\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_110419-mitmn8vd/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_110419-mitmn8vd/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30\n",
      "200/200 [==============================] - 44s 220ms/step - loss: 0.6073 - acc: 0.7965 - val_loss: 0.8076 - val_acc: 0.7492\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_110419-mitmn8vd/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_110419-mitmn8vd/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 0.5538 - acc: 0.8092 - val_loss: 1.1603 - val_acc: 0.6947\n",
      "Epoch 7/30\n",
      "200/200 [==============================] - 46s 232ms/step - loss: 0.4515 - acc: 0.8428 - val_loss: 1.2029 - val_acc: 0.6587\n",
      "Epoch 8/30\n",
      "200/200 [==============================] - 43s 217ms/step - loss: 0.4019 - acc: 0.8624 - val_loss: 1.1612 - val_acc: 0.7067\n",
      "Epoch 9/30\n",
      "200/200 [==============================] - 50s 249ms/step - loss: 0.3515 - acc: 0.8800 - val_loss: 0.9995 - val_acc: 0.7382\n",
      "Epoch 10/30\n",
      "200/200 [==============================] - 43s 215ms/step - loss: 0.3116 - acc: 0.8927 - val_loss: 0.7070 - val_acc: 0.7998\n",
      "INFO:tensorflow:Assets written to: /Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_110419-mitmn8vd/files/model-best/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/Users/msf/GitHub/TensorFlow_MusicGenre_Classifier/wandb/run-20220902_110419-mitmn8vd/files/model-best)... Done. 0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 0.2629 - acc: 0.9083 - val_loss: 0.7736 - val_acc: 0.7938\n",
      "Epoch 12/30\n",
      "200/200 [==============================] - 35s 176ms/step - loss: 0.2175 - acc: 0.9286 - val_loss: 0.7576 - val_acc: 0.7818\n",
      "Epoch 13/30\n",
      "200/200 [==============================] - 35s 174ms/step - loss: 0.2115 - acc: 0.9285 - val_loss: 0.8051 - val_acc: 0.7873\n",
      "Epoch 14/30\n",
      "200/200 [==============================] - 40s 202ms/step - loss: 0.1919 - acc: 0.9384 - val_loss: 0.8065 - val_acc: 0.7828\n",
      "Epoch 15/30\n",
      "200/200 [==============================] - 48s 239ms/step - loss: 0.1844 - acc: 0.9423 - val_loss: 0.8353 - val_acc: 0.7833\n",
      "Epoch 16/30\n",
      "200/200 [==============================] - 59s 296ms/step - loss: 0.1634 - acc: 0.9479 - val_loss: 0.7788 - val_acc: 0.8043\n",
      "Epoch 17/30\n",
      "200/200 [==============================] - 40s 200ms/step - loss: 0.1534 - acc: 0.9482 - val_loss: 0.9502 - val_acc: 0.7753\n",
      "Epoch 18/30\n",
      "200/200 [==============================] - 39s 193ms/step - loss: 0.1596 - acc: 0.9459 - val_loss: 1.0625 - val_acc: 0.7728\n",
      "Epoch 19/30\n",
      "200/200 [==============================] - 40s 198ms/step - loss: 0.1552 - acc: 0.9486 - val_loss: 1.0017 - val_acc: 0.7778\n",
      "Epoch 20/30\n",
      "200/200 [==============================] - 38s 191ms/step - loss: 0.1468 - acc: 0.9534 - val_loss: 0.7990 - val_acc: 0.8098\n",
      "Epoch 21/30\n",
      "200/200 [==============================] - 38s 187ms/step - loss: 0.1204 - acc: 0.9579 - val_loss: 0.9055 - val_acc: 0.7983\n",
      "Epoch 22/30\n",
      "200/200 [==============================] - 58s 293ms/step - loss: 0.1232 - acc: 0.9652 - val_loss: 1.3168 - val_acc: 0.7472\n",
      "Epoch 23/30\n",
      "200/200 [==============================] - 48s 238ms/step - loss: 0.1156 - acc: 0.9610 - val_loss: 1.1067 - val_acc: 0.7888\n",
      "Epoch 24/30\n",
      "200/200 [==============================] - 36s 178ms/step - loss: 0.1132 - acc: 0.9625 - val_loss: 0.9454 - val_acc: 0.8083\n",
      "Epoch 25/30\n",
      "200/200 [==============================] - 34s 168ms/step - loss: 0.1060 - acc: 0.9647 - val_loss: 0.8594 - val_acc: 0.8088\n",
      "Epoch 26/30\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 0.1155 - acc: 0.9623 - val_loss: 1.6992 - val_acc: 0.7217\n",
      "Epoch 27/30\n",
      "200/200 [==============================] - 34s 170ms/step - loss: 0.1062 - acc: 0.9682 - val_loss: 1.1931 - val_acc: 0.7648\n",
      "Epoch 28/30\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 0.1068 - acc: 0.9648 - val_loss: 0.8718 - val_acc: 0.8193\n",
      "Epoch 29/30\n",
      "200/200 [==============================] - 34s 169ms/step - loss: 0.1142 - acc: 0.9677 - val_loss: 0.8285 - val_acc: 0.8293\n",
      "Epoch 30/30\n",
      "200/200 [==============================] - 33s 163ms/step - loss: 0.1088 - acc: 0.9671 - val_loss: 0.9770 - val_acc: 0.8178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (./Model)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='22.764 MB of 22.767 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.9998…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>acc</td><td>▁▃▄▅▅▆▆▆▇▇▇▇▇▇████████████████</td></tr><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▅▄▃▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▄▅▆▇▆▅▆▆▇▇▇▇▇▇█▇▇▇█▇▇▇██▆▇███</td></tr><tr><td>val_loss</td><td>█▅▃▂▂▃▄▃▃▁▁▁▂▂▂▁▂▃▃▁▂▄▃▂▂▆▄▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>GFLOPs</td><td>0.03933</td></tr><tr><td>acc</td><td>0.96653</td></tr><tr><td>best_epoch</td><td>9</td></tr><tr><td>best_val_loss</td><td>0.70696</td></tr><tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.11268</td></tr><tr><td>val_acc</td><td>0.81782</td></tr><tr><td>val_loss</td><td>0.97699</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">colorful-sweep-41</strong>: <a href=\"https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/mitmn8vd\" target=\"_blank\">https://wandb.ai/msaintfelix/Genre-Classifier-Optimization/runs/mitmn8vd</a><br/>Synced 6 W&B file(s), 2 media file(s), 20 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220902_110419-mitmn8vd/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Waiting for job.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Sweep Agent: Exiting.\n"
     ]
    }
   ],
   "source": [
    "wandb.agent(sweep_id, train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
